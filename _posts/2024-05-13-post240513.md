---
title: kube-prometheus-stack 모니터링 시스템 구축
date: 2024-05-13 19:00 +0900
lastmod: 2024-05-13 19:00 +0900
categories: [Kubernetes]
tags: [Kubernetes]
mermaid: true
math: true
---

> 본 글은 ‘Hyper-v 환경에서 k8s 클러스터 구축’ 포스팅 이후 진행함
>

# 배경

운영의 효율성, 시스템 확장성, 자동화, 고가용성을 위해 기존 Bare-metal 환경에 직접 설치된 모니터링 스택들을 쿠버네티스 클러스터 위에 구축

# Prerequisite

1. Helm v3.14.4
2. kubectl v1.28.2

# Helm Chart

- Chart Name:
    - [https://artifacthub.io/packages/helm/prometheus-community/kube-prometheus-stack](https://artifacthub.io/packages/helm/prometheus-community/kube-prometheus-stack)
- Chart Version: v58.2.1
- App Version(Prometheus-Operator): v0.73.2

# kube-prometheus-stack Helm Chart에 사용되는 프로젝트

1. Prometheus Operator
    - [prometheus-operator/prometheus-operator](https://github.com/prometheus-operator/prometheus-operator)
    - 쿠버네티스 네이티브하게 프로메테우스를 배포하고 관리할 수 있는 기능을 제공합니다.
2. kube-prometheus
    - [prometheus-operator/kube-prometheus](https://github.com/prometheus-operator/kube-prometheus)
    - Prometheus Operator를 포함하여, Grafana, Prometheus Rule 등 모니터링 스택에 필요한 여러 컴포넌트가 종합되어 있습니다.
3. helm charts
    - [prometheus-community/kube-prometheus-stack](https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack)
    - Prometheus Community에 의해 관리되며, kube-prometheus 프로젝트를 기반으로 하여 거의 유사한 기능을 Helm Chart로 관리하고 배포할 수 있도록 하는 프로젝트로 볼 수 있습니다.

즉, kube-prometheus 프로젝트를 구성하는 컴포넌트 중 하나가 Prometheus Operator 이며, Prometheus Community에서는 kube-prometheus를 기반으로 Helm Chart를 만들어서 Artifact Hub에 등록한 것으로 볼 수 있습니다.

kube-prometheus-stack 배포시 설치 되는 컴포넌트는 다음과 같습니다.

- The Prometheus Operator
- Highly available Prometheus
- Highly available Alertmanager
- Prometheus node-exporter
- Prometheus Adapter for Kubernetes Metrics APIs
- kube-state-metrics
- Grafana

# Install Helm

> [https://helm.sh/ko/docs/intro/install/](https://helm.sh/ko/docs/intro/install/)
>

```bash
curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3
chmod 700 get_helm.sh
./get_helm.sh
```

# PV, PVC의 동적 프로비저닝을 위한 NFS StorageClass 구성

 [K8S PV, PVC의 동적 프로비저닝을 위한 NFS StorageClass 구성 포스팅 참고](https://woobni.github.io/posts/post240515/)

# Get prometheus-community Helm Repository

> [https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack](https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack)
>

```bash
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts

helm repo update
```

# Helm Pull

```bash
helm pull prometheus-community/kube-prometheus-stack
```

- helm install 명령으로 바로 설치할 수도 있지만 values.yaml 파일을 직접 수정해서 배포하기 위해 pull을 사용
- main 버전 외에 다른 버전을 사용하려면 --version 옵션을 사용

```bash
tar xvfz kube-prometheus-stack-58.3.3.tgz
```

# kube-prometheus-stack Helm 차트 구성

- kube-prometheus-stack을 포함한 대부분의 Helm 배포 패키지는 비슷한 구성으로 이루어져 있습니다.
    - charts: Helm 차트의 종속 차트를 포함하는 위치입니다. 이 패키지의 경우 grafana, kube-state-metrics, prometheus-node-exporter가 존재합니다.
    - templates: Helm 차트의 템플릿 파일들을 포함합니다. 템플릿은 Kubernetes 리소스의 정의를 작성하는 데 사용되며, 이를 통해 애플리케이션의 배포, 서비스, 구성 등을 관리할 수 있습니다
    - crds: Custom Resource Definitions(CRDs) 파일을 포함할 수 있는 위치입니다. CRD는 Kubernetes API에 사용자 정의 리소스와 그에 대한 스키마를 추가하는 데 사용됩니다.
    - Chart.yaml: Helm 차트의 메타 정보를 정의합니다. 메타 정보에는 차트의 이름, 버전, 유형, 유지 보수자 정보 등이 포함됩니다. 또한 종속 차트, 애플리케이션의 버전 제약 조건 등을 지정할 수도 있습니다.
    - values.yaml: Helm 차트의 기본 구성 값을 정의합니다. 애플리케이션의 설정 옵션, 환경 변수, 리소스 크기 등을 설정할 수 있습니다. values.yaml 파일에 정의된 값은 템플릿 파일 내에서 사용될 수 있으며, 차트를 배포할 때 사용자 지정 값으로 오버라이드할 수도 있습니다.

# Create monitoring namespace

```bash
kubectl create ns monitoring
```

# Chart values.yaml 수정

- Controller Manager, ETCD, Scheduler, KubeProxy 각 구성요소에 대한 메트릭 수집을 Disable
- 메트릭 수집 주기와 보존기간, 그리고 메트릭을 저장할 PV의 사이즈와 리소스 제한량은 최대한 적게 사용함으로써 불필요한 비용을 낭비하지 않음
- 사전 준비 단계에서 생성한 StorageClass를 사용하도록 프로메테우스 서버의 스토리지 설정을 변경
- 각 컴포넌트의 리소스 요쳥량과 제한값을 동일하게 설정해서 QoS를 Guaranteed 가 되도록하여 안정성을 높임
- 각 컴포넌트(grafana/prometheus/alert manager)의 서비스를 NodePort 타입으로 설정해서 별도의 서비스를 추가로 배포하지 않고 서비스에 접속할 수 있도록 수정 (추후 LoadBalancer 등으로의 변경 필요)
- 프로메테우스는 기본적으로 같은 네임스페이스의 PodMonitor로 서비스를 디스커버리 하기 때문에 이 기본 동작을 Disable하고 다른 네임스페이스의 ServiceMonitor를 탐색할 수 있도록 설정

```yaml
# -------------------Global-------------------
global:
  # 프라이빗 레지스트리 사용 시 활용
  imageRegistry: ""
  imagePullSecrets: []

# -------------------Global-Disable-------------------
# ETCD / Controller Manager / Scheduler -> 직접 설치한 컴포넌트
# Kube-Proxy
kubeControllerManager:
  enabled: false
kubeEtcd:
  enabled: false
kubeScheduler:
  enabled: false
kubeProxy:
  enabled: false

# -------------------Alertmanager-------------------
alertmanager:
  # PDB 설정
  podDisruptionBudget:
    enabled: false
    minAvailable: 1
    maxUnavailable: ""
  # 서비스 설정
  service:
    port: 9093
    targetPort: 9093
    type: NodePort # LoadBalancer
    nodePort: 30903
  # 파드 스펙 설정
  alertmanagerSpec:
    # 파드개수
    replicas: 1

    # 리소스 설정 - Guaranteed
    resources:
      limits:
        memory: 1Gi
      requests:
        memory: 1Gi

    # 스토리지 설정
    storageSpec:
      volumeClaimTemplate:
        spec:
          storageClassName: nfs-client # 미리 만들어둔 스토리지 클래스
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 10Gi

# -------------------Grafana-------------------
grafana:
  # 대시보드 타임존
  defaultDashboardsTimezone: kst
  # 어드민 암호
  adminPassword: admin
  service:
    portName: http-web
    type: NodePort # LoadBalancer
    port: 3000
    targetPort: 3000
    nodePort: 30001

# -------------------PrometheusOperator-------------------
prometheusOperator:
  resources:
    limits:
      memory: 1Gi
    requests:
      memory: 1Gi

# -------------------Promtetheus-------------------
prometheus:
  # 서비스 설정
  service:
    port: 9090
    targetPort: 9090
    type: NodePort # LoadBalancer
    nodePort: 30090
  # PDB 설정
  podDisruptionBudget:
    enabled: false
    minAvailable: 1
    maxUnavailable: ""
  # 파드 스펙 설정
  prometheusSpec:
    # 서비스모니터 설정 -> 다른 네임스페이스에 있는 Service Monitor 사용을 위해 설정
    # By default, Prometheus only discovers PodMonitors within its own namespace.
    # This should be disabled by setting podMonitorSelectorNilUsesHelmValues to false
    podMonitorSelectorNilUsesHelmValues: false
    serviceMonitorSelectorNilUsesHelmValues: false

    # 추가적인 스크래핑 구성
    additionalScrapeConfigs: []

    # 메트릭 스크랩
    scrapeInterval: "10s"
    scrapeTimeout: "10s"
    evaluationInterval: "16s"

    # 토폴로지 & 스케쥴링 옵션
    tolerations: []
    topologySpreadConstraints: []
    nodeSelector: {}
    podAntiAffinity: ""
    podAntiAffinityTopologyKey: kubernetes.io/hostname
    affinity: {}

    # 메트릭 보존 기간
    retention: 7d

    # 메트릭 최대 사이즈
    retentionSize: "5GiB"

    # 파드 개수
    replicas: 1

    # 리소스 설정 - Guaranteed
    resources:
      limits:
        memory: 1Gi
      requests:
        memory: 1Gi

    # 스토리지 설정
    storageSpec:
      volumeClaimTemplate:
        spec:
          storageClassName: nfs-client # 미리 만들어둔 스토리지 클래스
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 10Gi
```

# 클러스터에 Chart 배포

```bash
helm install -f custom-values.yaml kube-prometheus-stack prometheus-community/kube-prometheus-stack -n monitoring
```

# 배포 확인

```bash
helm list -n monitoring

NAME                    NAMESPACE       REVISION        UPDATED                                 STATUS          CHART                           APP VERSION
kube-prometheus-stack   monitoring      3               2024-05-03 16:49:24.436905839 +0900 KST deployed        kube-prometheus-stack-58.3.3    v0.73.2
```

```bash
kubectl get all -n monitoring
```

![Untitled](/assets/img/2024-05-13-post240513/Untitled.png)

![Untitled](/assets/img/2024-05-13-post240513/Untitled%201.png)

- 배포 업데이트

    ```bash
    helm upgrade -f custom-values.yaml kube-prometheus-stack prometheus-community/kube-prometheus-stack -n monitoring
    ```

- 배포 삭제

    ```bash
    helm uninstall kube-prometheus-stack --namespace monitoring
    ```

    ```bash
    kubectl delete crd alertmanagerconfigs.monitoring.coreos.com \
    alertmanagers.monitoring.coreos.com \
    podmonitors.monitoring.coreos.com \
    probes.monitoring.coreos.com \
    prometheusagents.monitoring.coreos.com \
    prometheuses.monitoring.coreos.com \
    prometheusrules.monitoring.coreos.com \
    scrapeconfigs.monitoring.coreos.com \
    servicemonitors.monitoring.coreos.com \
    thanosrulers.monitoring.coreos.com
    ```

    ```bash
    kubectl edit pv (pv name)

    Find the following in the manifest file

    finalizers:
      -  kubernetes.io/pv-protection
    ... and delete it.

    kubectl delete pv [pv name] --grace-period=0 --force
    ```
