[ { "title": "(kube-prometheus-stack) Prometheus 기반 모니터링 스택 Thanos 연동", "url": "/posts/post240524/", "categories": "Kubernetes", "tags": "Kubernetes, Prometheus, Thanos", "date": "2024-05-24 19:00:00 +0900", "snippet": " 본 글은 ‘(kube-prometheus-stack) Prometheus 기반 모니터링 스택 구축’ 포스팅 이후 진행됨Background K8S 클러스터에 구성된 Prometheus 기반 모니터링 스택의 Prometheus HA, 메트릭 장기 저장, global view를 구현하기 위해 Thanos 스택 연동 각 Thanos 컴포넌트에 ServiceMonitor를 생성하여 Thanos 컴포넌트 메트릭 추가 수집Prerequisite Helm v3.14.4 kubectl v1.28.2 Monitoring Stack Setup kube-prometheus-stack helm chart v58.2.1 Object StoragePrerequisite Helm v3.14.4 kubectl v1.28.2 kube-prometheus-stack helm chart v58.2.1 S3 BucketThanos SidecarCreate Object Storage Secret https://thanos.io/tip/thanos/storage.md/#s3type: S3config: bucket: &quot;kubenetes-thanos&quot; endpoint: &quot;s3.ap-northeast-2.amazonaws.com&quot; region: &quot;ap-northeast-2&quot; aws_sdk_auth: false access_key: &quot;&quot; insecure: false signature_version2: false secret_key: &quot;&quot; session_token: &quot;&quot; put_user_metadata: {} http_config: idle_conn_timeout: 1m30s response_header_timeout: 2m insecure_skip_verify: false tls_handshake_timeout: 10s expect_continue_timeout: 1s max_idle_conns: 100 max_idle_conns_per_host: 100 max_conns_per_host: 0 tls_config: ca_file: &quot;&quot; cert_file: &quot;&quot; key_file: &quot;&quot; server_name: &quot;&quot; insecure_skip_verify: false disable_compression: false trace: enable: false list_objects_version: &quot;&quot; bucket_lookup_type: auto send_content_md5: true part_size: 67108864 sse_config: type: &quot;&quot; kms_key_id: &quot;&quot; kms_encryption_context: {} encryption_key: &quot;&quot; sts_endpoint: &quot;&quot;prefix: &quot;&quot;kubectl create secret generic thanos-objstore --from-file=thanos-objstore.yaml --namespace monitoring S3의 access_key, secret_key 설정Customizing the Chart values.yaml# -------------------Promtetheus-------------------prometheus: prometheusSpec: # Prometheus의 데이터 압축을 비활성화 # Thanos compactor가 작업할 때 업로드된 데이터가 손상되지 않도록 하는 데 필요 # true로 설정하면 --storage.tsdb.max-block-duration=2h 옵션을 Prometheus에 전달 # thanos 설정 시 자동으로 true로 설정됨 disableCompaction: true # Object Storage Secret 설정 thanos: objectStorageConfig: existingSecret: key: thanos-objstore.yaml name: thanos-objstore # Thanos Sidecar에서 Thanos 서비스 발견을 위한 서비스 # 활성화하면 Thanos Query가 --store=dnssrv+_grpc._tcp.${kube-prometheus-stack.fullname}-thanos-discovery.${namespace}.svc.cluster.local를 사용하여 Prometheus 노드에서 Thanos 사이드카를 발견할 수 있음 thanosService: enabled: true clusterIP: &quot;&quot; type: ClusterIP portName: grpc port: 10901 targetPort: &quot;grpc&quot; httpPortName: http httpPort: 10902 targetHttpPort: &quot;http&quot; clusterIP: &quot;&quot; # None에서 변경 nodePort: 30901 httpNodePort: 30902 # Thanos Sidecar의 메트릭을 수집하기 위한 서비스 모니터 설정 thanosServiceMonitor: enabled: true# Thanos 이미지 버전 설정prometheusOperator: prometheusConfigReloader: thanosImage: registry: quay.io repository: thanos/thanos tag: v0.34.1helm upgrade -f custom-values.yaml kube-prometheus-stack prometheus-community/kube-prometheus-stack -n monitoringThanos Sidecar 확인kubectl get pod prometheus-kube-prometheus-stack-prometheus-0 -n monitoring -o yaml...status: containerStatuses: - containerID: containerd://4d837c419903774587ef0dfc35c5869782f61ed9d5413e11996c7ef9ab0292ac image: quay.io/thanos/thanos:v0.34.1 imageID: quay.io/thanos/thanos@sha256:567346c3f6ff2927c2c6c0daad977b2213f62d45eca54d48afd19e6deb902181 lastState: {} name: thanos-sidecar ready: true restartCount: 0 started: true state: running: startedAt: &quot;2024-05-17T06:10:07Z&quot; hostIP: 192.168.25.221 hostIPs: - ip: 192.168.25.221...prometheus pod에 statefulset으로 Thanos Sidecar가 배포된 것을 확인할 수 있음kubectl get svc -n monitoringNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkube-prometheus-stack-thanos-discovery ClusterIP 10.97.125.31 &amp;lt;none&amp;gt; 10901/TCP,10902/TCP 54mThanos Sidecar 엔드포인트를 위한 service도 생성됨을 확인kubectl describe pod prometheus-kube-prometheus-stack-prometheus-0 -n monitoring...thanos-sidecar: State: Running Started: Fri, 17 May 2024 17:33:12 +0900 Ready: True Restart Count: 0 Environment: OBJSTORE_CONFIG: &amp;lt;set to the key &#39;thanos-objstore.yaml&#39; in secret &#39;thanos-objstore&#39;&amp;gt;...Environment에 OBJSTORE_CONFIG 가 설정되어 있는지 확인S3 확인2시간 이후부터 메트릭이 적재됨. 2시간 동안의 메트릭은 Prometheus에 존재참고) Secret config 변경kubectl delete secret thanos-objstore -n monitoringkubectl create secret generic thanos-objstore --from-file=thanos-objstore.yaml -n monitoringkubectl rollout restart statefulset prometheus-kube-prometheus-stack-prometheus -n monitoringThanos Querier https://thanos.io/tip/thanos/quick-tutorial.md/#querierqueryThanos Querier는 Prometheus 쿼리를 실행하고 여러 데이터 소스에서 데이터를 집계하여 제공하는 API 게이트웨이ServiceAccountapiVersion: v1kind: ServiceAccountmetadata: annotations: {} labels: app.kubernetes.io/component: query-layer app.kubernetes.io/instance: thanos-query app.kubernetes.io/name: thanos-query app.kubernetes.io/version: v0.34.1 name: thanos-query namespace: monitoring Kubernetes에서는 RBAC(Role-Based Access Control)를 사용하여 클러스터 내의 리소스에 대한 접근 권한을 관리. ServiceAccount는 Pod가 클러스터 내에서 특정 리소스에 접근할 수 있도록 권한을 부여하는 데 사용. 서로 다른 Thanos 컴포넌트(thanos-compact, thanos-query, …)에 대해 개별적인 ServiceAccount를 사용하여 서비스 간의 역할을 분리하고, 각 서비스가 필요한 권한만 부여받도록 하고자 함ServiceapiVersion: v1kind: Servicemetadata: labels: app.kubernetes.io/component: query-layer app.kubernetes.io/instance: thanos-query app.kubernetes.io/name: thanos-query app.kubernetes.io/version: v0.34.1 name: thanos-query namespace: monitoringspec: ports: - name: grpc port: 10901 targetPort: 10901 - name: http port: 9090 targetPort: 9090 nodePort: 32090 selector: app.kubernetes.io/component: query-layer app.kubernetes.io/instance: thanos-query app.kubernetes.io/name: thanos-query type: NodePortDeploymentapiVersion: apps/v1kind: Deploymentmetadata: labels: app.kubernetes.io/component: query-layer app.kubernetes.io/instance: thanos-query app.kubernetes.io/name: thanos-query app.kubernetes.io/version: v0.34.1 name: thanos-query namespace: monitoringspec: replicas: 1 selector: matchLabels: app.kubernetes.io/component: query-layer app.kubernetes.io/instance: thanos-query app.kubernetes.io/name: thanos-query template: metadata: labels: app.kubernetes.io/component: query-layer app.kubernetes.io/instance: thanos-query app.kubernetes.io/name: thanos-query app.kubernetes.io/version: v0.34.1 spec: affinity: podAntiAffinity: preferredDuringSchedulingIgnoredDuringExecution: - podAffinityTerm: labelSelector: matchExpressions: - key: app.kubernetes.io/name operator: In values: - thanos-query namespaces: - monitoring topologyKey: kubernetes.io/hostname weight: 100 containers: - args: - query - --grpc-address=0.0.0.0:10901 - --http-address=0.0.0.0:9090 - --log.level=debug - --log.format=logfmt - --query.replica-label=prometheus_replica - --endpoint=dnssrv+_grpc._tcp.kube-prometheus-stack-thanos-discovery.monitoring.svc.cluster.local - --query.timeout=5m - --query.lookback-delta=15m - |- --tracing.config=&quot;config&quot;: &quot;sampler_param&quot;: 2 &quot;sampler_type&quot;: &quot;ratelimiting&quot; &quot;service_name&quot;: &quot;thanos-query&quot; &quot;type&quot;: &quot;JAEGER&quot; - --query.auto-downsampling - --web.external-prefix=/thanos/query #- --web.route-prefix=/thanos/query env: - name: HOST_IP_ADDRESS valueFrom: fieldRef: fieldPath: status.hostIP image: quay.io/thanos/thanos:v0.34.1 imagePullPolicy: IfNotPresent livenessProbe: failureThreshold: 4 httpGet: path: /-/healthy port: 9090 scheme: HTTP periodSeconds: 30 name: thanos-query ports: - containerPort: 10901 name: grpc - containerPort: 9090 name: http readinessProbe: failureThreshold: 20 httpGet: path: /-/ready port: 9090 scheme: HTTP periodSeconds: 5 resources: {} securityContext: allowPrivilegeEscalation: false capabilities: drop: - ALL readOnlyRootFilesystem: true runAsGroup: 65532 runAsNonRoot: true runAsUser: 65534 seccompProfile: type: RuntimeDefault terminationMessagePolicy: FallbackToLogsOnError nodeSelector: kubernetes.io/os: linux securityContext: fsGroup: 65534 runAsGroup: 65532 runAsNonRoot: true runAsUser: 65534 seccompProfile: type: RuntimeDefault serviceAccountName: thanos-query terminationGracePeriodSeconds: 120 --endpoint=dnssrv+_grpc._tcp.kube-prometheus-stack-thanos-discovery.monitoring.svc.cluster.local: thanos-sidecar의 svc 지정ServiceMonitorapiVersion: monitoring.coreos.com/v1kind: ServiceMonitormetadata: labels: app.kubernetes.io/component: query-layer app.kubernetes.io/instance: thanos-query app.kubernetes.io/name: thanos-query app.kubernetes.io/version: v0.34.1 tenant: monitoring name: thanos-query namespace: monitoringspec: endpoints: - port: http relabelings: - action: replace separator: / sourceLabels: - namespace - pod targetLabel: instance selector: matchLabels: app.kubernetes.io/component: query-layer app.kubernetes.io/instance: thanos-query app.kubernetes.io/name: thanos-querykubectl apply -f thanos-query-serviceAccount.yaml -f thanos-query-service.yaml -f thanos-query-deployment.yaml -f thanos-query-serviceMonitor.yaml확인NodePort로 Thanos Query에 접속 후 위와 같이 sidecar가 store 설정 되어 있음을 확인Thanos Query의 ServiceMonitor도 Target에 설정 되어 있음을 확인Thanos Compactor https://thanos.io/tip/components/compact.mdThanos Compactor는 Prometheus TSDB(시계열 데이터베이스) 블록을 관리하고 최적화하는 구성 요소. 다음과 같은 작업을 수행: 블록 컴팩션 여러 개의 작은 블록을 큰 블록으로 병합하여 디스크 사용량을 줄이고 쿼리 성능을 향상시킴. 컴팩션 과정에서 데이터가 삭제될 수도 있으므로 데이터 무결성을 유지해야 합니다. 다운샘플링 장기 저장소의 데이터 크기를 줄이기 위해 시간 시계열 데이터를 다운샘플링하여 저장. 이를 통해 장기 저장된 데이터에 대한 쿼리 성능을 개선. 블록 삭제 오래된 블록을 삭제하여 디스크 공간을 확보. 특정 보존 정책에 따라 데이터를 관리. ServiceAccountapiVersion: v1kind: ServiceAccountmetadata: annotations: {} labels: app.kubernetes.io/component: database-compactor app.kubernetes.io/instance: thanos-compact app.kubernetes.io/name: thanos-compact app.kubernetes.io/version: v0.34.1 name: thanos-compact namespace: monitoringServiceapiVersion: v1kind: Servicemetadata: labels: app.kubernetes.io/component: database-compactor app.kubernetes.io/instance: thanos-compact app.kubernetes.io/name: thanos-compact app.kubernetes.io/version: v0.34.1 name: thanos-compact namespace: monitoringspec: ports: - name: http port: 10902 targetPort: 10902 nodePort: 32091 selector: app.kubernetes.io/component: database-compactor app.kubernetes.io/instance: thanos-compact app.kubernetes.io/name: thanos-compact type: NodePortStatefultSet Compactor는 TSDB 블록 압축을 수행하기 위해 데이터를 저장하고 버킷 상태 캐시를 유지하기 위한 로컬 디스크 공간이 필요함. 디스크에 있는 데이터는 컴팩터가 재시작 사이에 버킷 상태 캐시를 효과적으로 사용하기 위해 지속적인 디스크를 제공하는 것이 권장됨. 따라서 StatefulSet으로 배포하여 안정적인 스토리지를 보장apiVersion: apps/v1kind: StatefulSetmetadata: labels: app.kubernetes.io/component: database-compactor app.kubernetes.io/instance: thanos-compact app.kubernetes.io/name: thanos-compact app.kubernetes.io/version: v0.34.1 name: thanos-compact namespace: monitoringspec: replicas: 1 selector: matchLabels: app.kubernetes.io/component: database-compactor app.kubernetes.io/instance: thanos-compact app.kubernetes.io/name: thanos-compact serviceName: thanos-compact template: metadata: labels: app.kubernetes.io/component: database-compactor app.kubernetes.io/instance: thanos-compact app.kubernetes.io/name: thanos-compact app.kubernetes.io/version: v0.35.1 spec: affinity: podAntiAffinity: preferredDuringSchedulingIgnoredDuringExecution: - podAffinityTerm: labelSelector: matchExpressions: - key: app.kubernetes.io/name operator: In values: - thanos-compact - key: app.kubernetes.io/instance operator: In values: - thanos-compact namespaces: - monitoring topologyKey: kubernetes.io/hostname weight: 100 containers: - args: - compact - --web.disable - --web.disable-cors - --wait - --log.level=warn - --log.format=logfmt - --objstore.config=$(OBJSTORE_CONFIG) - --data-dir=/var/thanos/compact - --debug.accept-malformed-index - --retention.resolution-raw=0d - --retention.resolution-5m=0d - --retention.resolution-1h=0d - --delete-delay=12h - --compact.concurrency=1 - --downsample.concurrency=1 - --downsampling.disable - --deduplication.replica-label=prometheus_replica - --deduplication.replica-label=rule_replica - |- --tracing.config=&quot;config&quot;: &quot;sampler_param&quot;: 2 &quot;sampler_type&quot;: &quot;ratelimiting&quot; &quot;service_name&quot;: &quot;thanos-compact&quot; &quot;type&quot;: &quot;JAEGER&quot; env: - name: OBJSTORE_CONFIG valueFrom: secretKeyRef: key: thanos-objstore.yaml name: thanos-objstore - name: HOST_IP_ADDRESS valueFrom: fieldRef: fieldPath: status.hostIP image: quay.io/thanos/thanos:v0.34.1 imagePullPolicy: IfNotPresent livenessProbe: failureThreshold: 4 httpGet: path: /-/healthy port: 10902 scheme: HTTP periodSeconds: 30 name: thanos-compact ports: - containerPort: 10902 name: http readinessProbe: failureThreshold: 20 httpGet: path: /-/ready port: 10902 scheme: HTTP periodSeconds: 5 terminationMessagePolicy: FallbackToLogsOnError volumeMounts: - mountPath: /var/thanos/compact name: data readOnly: false nodeSelector: kubernetes.io/os: linux securityContext: fsGroup: 65534 runAsGroup: 65532 runAsNonRoot: true runAsUser: 65534 seccompProfile: type: RuntimeDefault serviceAccountName: thanos-compact terminationGracePeriodSeconds: 120 volumes: [] volumeClaimTemplates: - metadata: labels: app.kubernetes.io/component: database-compactor app.kubernetes.io/instance: thanos-compact app.kubernetes.io/name: thanos-compact name: data spec: storageClassName: &quot;nfs-client&quot; accessModes: - ReadWriteOnce resources: requests: storage: 10Gi 사전에 구성된 Object Storage Secret 설정```yaml name: OBJSTORE_CONFIGvalueFrom: secretKeyRef: key: thanos-objstore.yaml name: thanos-objstore``` ServiceMonitorapiVersion: monitoring.coreos.com/v1kind: ServiceMonitormetadata: labels: app.kubernetes.io/component: database-compactor app.kubernetes.io/instance: thanos-compact app.kubernetes.io/name: thanos-compact app.kubernetes.io/version: v0.34.1 tenant: monitoring name: thanos-compact namespace: monitoringspec: endpoints: - port: http relabelings: - action: replace separator: / sourceLabels: - namespace - pod targetLabel: instance selector: matchLabels: app.kubernetes.io/component: database-compactor app.kubernetes.io/instance: thanos-compact app.kubernetes.io/name: thanos-compactkubectl apply -f thanos-compact-serviceAccount.yaml -f thanos-compact-service.yaml -f thanos-compact-statefulSet.yaml -f thanos-compact-serviceMonitor.yamlPrometheus Target 확인Thanos Compactor의 ServiceMonitor도 Target에 설정 되어 있음을 확인Grafana에서 Thanos Query를 통해 메트릭 조인Grafana에 접속하여 Thanos Querier를 데이터소스로 추가. Connection 섹션의 URL 필드에 다음 URL을 입력http://thanos-query.monitoring:9090/thanos-query.monitoring: 네임스페이스는 monitoring이고 서비스 이름은 thanos-queryPrometheus type을 Thanos로 설정Thanos Querier를 데이터소스로 하여 메트릭 조회. 아래와 같은 과정을 Thanos가 수행: 2시간 내 메트릭은 Prometheus에서 조회 Prometheus의 보존 기간(일반적으로 2시간)보다 오래된 모든 메트릭이 Object Storage에서 조회일반적인 설정에서는 Prometheus 서버가 짧은 보존 기간(예: 2시간)으로 구성됨. 이 보존 기간보다 오래된 모든 데이터는 더 큰 블록으로 압축되어 Thanos Sidecar에 의해 Object Storage로 업로드됨. 히스토리 데이터를 요청할 때 Object Storage에 있는 이러한 블록을 조회.Thanos Bucket Web https://thanos.io/tip/components/tools.md/#bucket-webThanos Bucket Web은 웹 UI를 통해 Thanos 스토리지 버킷의 상태를 검사하고 주어진 갱신 주기로 뷰를 주기적으로 업데이트ServiceAccountapiVersion: v1kind: ServiceAccountmetadata: annotations: {} labels: app.kubernetes.io/component: object-store-bucket-debugging app.kubernetes.io/instance: thanos-bucket app.kubernetes.io/name: thanos-bucket app.kubernetes.io/version: v0.34.1 name: thanos-bucket namespace: monitoringServiceapiVersion: v1kind: Servicemetadata: labels: app.kubernetes.io/component: object-store-bucket-debugging app.kubernetes.io/instance: thanos-bucket app.kubernetes.io/name: thanos-bucket app.kubernetes.io/version: v0.34.1 name: thanos-bucket namespace: monitoringspec: ports: - name: http port: 10902 targetPort: 10902 selector: app.kubernetes.io/component: object-store-bucket-debugging app.kubernetes.io/instance: thanos-bucket app.kubernetes.io/name: thanos-bucket type: NodePortDeploymentapiVersion: apps/v1kind: Deploymentmetadata: labels: app.kubernetes.io/component: object-store-bucket-debugging app.kubernetes.io/instance: thanos-bucket app.kubernetes.io/name: thanos-bucket app.kubernetes.io/version: v0.34.1 name: thanos-bucket namespace: monitoringspec: replicas: 1 selector: matchLabels: app.kubernetes.io/component: object-store-bucket-debugging app.kubernetes.io/instance: thanos-bucket app.kubernetes.io/name: thanos-bucket template: metadata: labels: app.kubernetes.io/component: object-store-bucket-debugging app.kubernetes.io/instance: thanos-bucket app.kubernetes.io/name: thanos-bucket app.kubernetes.io/version: v0.34.1 spec: containers: - args: - tools - bucket - web - --log.level=warn - --log.format=logfmt - --objstore.config=$(OBJSTORE_CONFIG) - --web.external-prefix=/thanos/bucket - --web.route-prefix=/thanos/bucket - |- --tracing.config=&quot;config&quot;: &quot;sampler_param&quot;: 2 &quot;sampler_type&quot;: &quot;ratelimiting&quot; &quot;service_name&quot;: &quot;thanos-bucket&quot; &quot;type&quot;: &quot;JAEGER&quot; - --label=cluster_name - --refresh=5m env: - name: OBJSTORE_CONFIG valueFrom: secretKeyRef: key: thanos-objstore.yaml name: thanos-objstore - name: HOST_IP_ADDRESS valueFrom: fieldRef: fieldPath: status.hostIP image: quay.io/thanos/thanos:v0.34.1 imagePullPolicy: IfNotPresent livenessProbe: failureThreshold: 4 httpGet: path: /-/healthy port: 10902 scheme: HTTP periodSeconds: 30 name: thanos-bucket ports: - containerPort: 10902 name: http readinessProbe: failureThreshold: 20 httpGet: path: /-/ready port: 10902 scheme: HTTP periodSeconds: 5 resources: limits: cpu: 0.42 memory: 420Mi requests: cpu: 0.123 memory: 123Mi securityContext: allowPrivilegeEscalation: false capabilities: drop: - ALL readOnlyRootFilesystem: true runAsGroup: 65532 runAsNonRoot: true runAsUser: 65534 seccompProfile: type: RuntimeDefault terminationMessagePolicy: FallbackToLogsOnError volumeMounts: [] nodeSelector: kubernetes.io/os: linux securityContext: fsGroup: 65534 runAsGroup: 65532 runAsNonRoot: true runAsUser: 65534 seccompProfile: type: RuntimeDefault serviceAccountName: thanos-bucket terminationGracePeriodSeconds: 120 volumes: [] 사전에 구성된 Object Storage Secret 설정```yaml name: OBJSTORE_CONFIGvalueFrom: secretKeyRef: key: thanos-objstore.yaml name: thanos-objstore``` kubectl apply -f thanos-bucket-serviceAccount.yaml -f thanos-bucket-service.yaml -f thanos-bucket-deployment.yamlBucket Web 접속 확인Reference https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/thanos.md https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#thanosspec https://github.com/thanos-io/kube-thanos/tree/main/manifests https://github.com/thanos-io/kube-thanos/tree/main/examples/all/manifests" }, { "title": "(kube-prometheus-stack) Prometheus 기반 모니터링 스택 구축", "url": "/posts/post240516/", "categories": "Kubernetes", "tags": "Kubernetes, Prometheus", "date": "2024-05-16 19:00:00 +0900", "snippet": " 본 글은 ‘Hyper-v 환경에서 k8s 클러스터 구축’ 포스팅 이후 진행함Background SaaS 제품을 사용하는 테넌트가 추가됨에 따른 환경 배포 및 관리가 불편해져 기존의 베어메탈 환경에서 쿠버네티스로 전환 기존 Bare-metal 환경에 직접 설치된 모니터링 스택들을 쿠버네티스 클러스터 위에 구축 K8S 클러스터의 테넌트별 시스템 리소스 및 애플리케이션 사용량 모니터링을 가능하게 함 → 플랫폼의 가용성과 신뢰성을 보장Prerequisite Helm v3.14.4+ kubectl v1.28.2+ StorageClass에서 사용될 CSI 드라이버 ProvisionerHelm Chart Chart Name: https://artifacthub.io/packages/helm/prometheus-community/kube-prometheus-stack Chart Version: v58.2.1 App Version(Prometheus-Operator): v0.73.2kube-prometheus-stack Helm Chart에 사용되는 프로젝트 Prometheus Operator prometheus-operator/prometheus-operator 쿠버네티스 네이티브하게 프로메테우스를 배포하고 관리할 수 있는 기능을 제공합니다. kube-prometheus prometheus-operator/kube-prometheus Prometheus Operator를 포함하여, Grafana, Prometheus Rule 등 모니터링 스택에 필요한 여러 컴포넌트가 종합되어 있습니다. helm charts prometheus-community/kube-prometheus-stack Prometheus Community에 의해 관리되며, kube-prometheus 프로젝트를 기반으로 하여 거의 유사한 기능을 Helm Chart로 관리하고 배포할 수 있도록 하는 프로젝트로 볼 수 있습니다. 즉, kube-prometheus 프로젝트를 구성하는 컴포넌트 중 하나가 Prometheus Operator 이며, Prometheus Community에서는 kube-prometheus를 기반으로 Helm Chart를 만들어서 Artifact Hub에 등록한 것으로 볼 수 있습니다.kube-prometheus-stack 배포시 설치 되는 컴포넌트는 다음과 같습니다. The Prometheus Operator Highly available Prometheus Highly available Alertmanager Prometheus node-exporter Prometheus Adapter for Kubernetes Metrics APIs kube-state-metrics GrafanaInstall Helm https://helm.sh/ko/docs/intro/install/curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3chmod 700 get_helm.sh./get_helm.shPV, PVC의 동적 프로비저닝을 위한 NFS CSI 드라이버 구성PV, PVC의 동적 프로비저닝을 위한 NFS CSI 드라이버 구성 포스팅 참고Get prometheus-community Helm Repository https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stackhelm repo add prometheus-community https://prometheus-community.github.io/helm-chartshelm repo updateHelm Pullhelm pull prometheus-community/kube-prometheus-stack helm install 명령으로 바로 설치할 수도 있지만 values.yaml 파일을 직접 수정해서 배포하기 위해 pull을 사용 main 버전 외에 다른 버전을 사용하려면 –version 옵션을 사용tar xvfz kube-prometheus-stack-58.3.3.tgzkube-prometheus-stack Helm 차트 구성 kube-prometheus-stack을 포함한 대부분의 Helm 배포 패키지는 비슷한 구성으로 이루어져 있습니다. charts: Helm 차트의 종속 차트를 포함하는 위치입니다. 이 패키지의 경우 grafana, kube-state-metrics, prometheus-node-exporter가 존재합니다. templates: Helm 차트의 템플릿 파일들을 포함합니다. 템플릿은 Kubernetes 리소스의 정의를 작성하는 데 사용되며, 이를 통해 애플리케이션의 배포, 서비스, 구성 등을 관리할 수 있습니다 crds: Custom Resource Definitions(CRDs) 파일을 포함할 수 있는 위치입니다. CRD는 Kubernetes API에 사용자 정의 리소스와 그에 대한 스키마를 추가하는 데 사용됩니다. Chart.yaml: Helm 차트의 메타 정보를 정의합니다. 메타 정보에는 차트의 이름, 버전, 유형, 유지 보수자 정보 등이 포함됩니다. 또한 종속 차트, 애플리케이션의 버전 제약 조건 등을 지정할 수도 있습니다. values.yaml: Helm 차트의 기본 구성 값을 정의합니다. 애플리케이션의 설정 옵션, 환경 변수, 리소스 크기 등을 설정할 수 있습니다. values.yaml 파일에 정의된 값은 템플릿 파일 내에서 사용될 수 있으며, 차트를 배포할 때 사용자 지정 값으로 오버라이드할 수도 있습니다. Create monitoring namespaceapiVersion: v1kind: Namespacemetadata: name: monitoringkubectl apply -f monitoring-namespace.yamlCustomizing the Chart values.yaml 메트릭 수집 주기와 보존기간, 그리고 메트릭을 저장할 PV의 사이즈와 리소스 제한량은 최대한 적게 사용함으로써 불필요한 비용을 낭비하지 않음 사전 준비 단계에서 생성한 StorageClass를 사용 각 컴포넌트의 리소스 요쳥량과 제한값을 동일하게 설정해서 QoS를 Guaranteed가 되도록하여 안정성을 높임 Prometheus가 기본적으로 같은 네임스페이스의 ServiceMonitor로 서비스를 디스커버리 하도록 설정되어 있기 때문에 이것을 Disable하고 다른 네임스페이스의 ServiceMonitor를 탐색할 수 있도록 설정 추후 테넌트별 리소스/애플리케이션 메트릭 구분을 위해 라벨링# -------------------Global-------------------global: # 프라이빗 레지스트리 사용 시 활용 imageRegistry: &quot;&quot; imagePullSecrets: []commonLabels: cluster: hyper-v-dev tenant: monitoring# -------------------Global-Disable-------------------kubeControllerManager: enabled: falsekubeEtcd: enabled: falsekubeScheduler: enabled: falsekubeProxy: enabled: false# -------------------kubelet-------------------kubelet: enabled: true namespace: kube-system serviceMonitor: additionalLabels: cluster: hyper-v-dev tenant: monitoring# -------------------kubeStateMetrics-------------------kubeStateMetrics: enabled: true# Configuration for kube-state-metrics subchartkube-state-metrics: prometheus: monitor: enabled: true additionalLabels: cluster: hyper-v-dev tenant: monitoring# -------------------Alertmanager-------------------alertmanager: # PDB 설정 podDisruptionBudget: enabled: false minAvailable: 1 maxUnavailable: &quot;&quot; # 서비스 설정 service: port: 9093 targetPort: 9093 type: NodePort nodePort: 30903 # 파드 스펙 설정 alertmanagerSpec: # 파드개수 replicas: 1 resources: limits: cpu: 200m memory: 1Gi requests: cpu: 200m memory: 1Gi # 스토리지 설정 storage: volumeClaimTemplate: spec: storageClassName: nfs-client accessModes: [&quot;ReadWriteOnce&quot;] resources: requests: storage: 10Gi# -------------------Grafana-------------------grafana: enabled: true # 대시보드 타임존 defaultDashboardsTimezone: kst # 어드민 암호 adminPassword: admin service: portName: http-web type: NodePort port: 3000 targetPort: 3000 nodePort: 30001 persistence: enabled: true type: sts storageClassName: &quot;nfs-client&quot; accessModes: - ReadWriteOnce size: 5Gi finalizers: - kubernetes.io/pvc-protection# -------------------PrometheusOperator-------------------prometheusOperator: resources: limits: cpu: 200m memory: 1Gi requests: cpu: 200m memory: 1Gi # Prometheus Operator와 Kubernetes apiserver 간의 상호작용을 특정 네임스페이스로 제한 # 다른 네임스페이스에 있는 모든 CRDs 관리하려면 {}으로 설정 namespaces: {}# -------------------Promtetheus-------------------prometheus: # 서비스 설정 service: port: 9090 targetPort: 9090 type: NodePort nodePort: 30090 # PDB 설정 podDisruptionBudget: enabled: false minAvailable: 1 maxUnavailable: &quot;&quot; # 파드 스펙 설정 prometheusSpec: # 서비스모니터 설정 -&amp;gt; 다른 네임스페이스에 있는 Service Monitor 사용을 위해 설정 # By default, Prometheus only discovers PodMonitors within its own namespace. # This should be disabled by setting podMonitorSelectorNilUsesHelmValues to false podMonitorSelectorNilUsesHelmValues: false serviceMonitorSelector: matchLabels: tenant: monitoring serviceMonitorSelectorNilUsesHelmValues: false podMonitorSelector: matchLabels: tenant: monitoring # 추가적인 스크래핑 구성 additionalScrapeConfigs: [] # 메트릭 스크랩 scrapeInterval: &quot;30s&quot; scrapeTimeout: &quot;&quot; evaluationInterval: &quot;&quot; # 토폴로지 &amp;amp; 스케쥴링 옵션 tolerations: [] topologySpreadConstraints: [] nodeSelector: {} podAntiAffinity: &quot;&quot; podAntiAffinityTopologyKey: kubernetes.io/hostname affinity: {} externalLabels: cluster: hyper-v-dev tenant: monitoring # 메트릭 보존 기간 retention: 12h # 메트릭 최대 사이즈 retentionSize: &quot;5GiB&quot; # 파드 개수 replicas: 1 resources: limits: cpu: 400m memory: 2Gi requests: cpu: 400m memory: 2Gi # 스토리지 설정 storageSpec: volumeClaimTemplate: spec: storageClassName: nfs-client accessModes: [&quot;ReadWriteOnce&quot;] resources: requests: storage: 10GiInstall Helm Charthelm install -f custom-values.yaml kube-prometheus-stack prometheus-community/kube-prometheus-stack -n monitoring배포 확인helm list -n monitoringNAME NAMESPACE REVISION UPDATED STATUS CHART APP VERSIONkube-prometheus-stack monitoring 3 2024-05-03 16:49:24.436905839 +0900 KST deployed kube-prometheus-stack-58.3.3 v0.73.2kubectl get all -n monitoring참고) 배포 업데이트/삭제 배포 업데이트 helm upgrade -f custom-values.yaml kube-prometheus-stack prometheus-community/kube-prometheus-stack -n monitoring 배포 삭제 helm uninstall kube-prometheus-stack -n monitoring kubectl delete crd alertmanagerconfigs.monitoring.coreos.com \\ alertmanagers.monitoring.coreos.com \\ podmonitors.monitoring.coreos.com \\ probes.monitoring.coreos.com \\ prometheusagents.monitoring.coreos.com \\ prometheuses.monitoring.coreos.com \\ prometheusrules.monitoring.coreos.com \\ scrapeconfigs.monitoring.coreos.com \\ servicemonitors.monitoring.coreos.com \\ thanosrulers.monitoring.coreos.com kubectl delete pv [pv name] --grace-period=0 --force kubectl edit pv (pv name) Find the following in the manifest file finalizers: - kubernetes.io/pv-protection ... and delete it. kubectl delete pvc [pvc name] --grace-period=0 --force kubectl edit pvc (pv name) Find the following in the manifest file finalizers: - kubernetes.io/pv-protection ... and delete it. GrafanaNodePort로 Grafana에 접속하여 연결된 Grafana 데이터소스 확인kube-prometheus-stack을 통해 자동 생성된 대시보드 확인" }, { "title": "PV, PVC의 동적 프로비저닝을 위한 NFS CSI 드라이버 구성", "url": "/posts/post240515/", "categories": "Kubernetes", "tags": "Kubernetes", "date": "2024-05-15 19:00:00 +0900", "snippet": "Prerequisite NFS 서버/클라이언트 설정nfs-provisioner 구성helm repo add nfs-subdir-external-provisioner https://kubernetes-sigs.github.io/nfs-subdir-external-provisioner/helm repo updatekubectl create ns nfs-provisionerhelm install nfs-subdir-external-provisioner nfs-subdir-external-provisioner/nfs-subdir-external-provisioner \\ --namespace nfs-provisioner \\ --set nfs.server=woobin-vm1 \\ --set nfs.path=/mnt/repokubectl get storageclassNAME PROVISIONER RECLAIMPOLICY VOLUMEBINDINGMODE ALLOWVOLUMEEXPANSION AGEnfs-client cluster.local/nfs-subdir-external-provisioner Delete Immediate true 42mStorage Class 테스트# nfs-pvc.yamlapiVersion: v1kind: PersistentVolumeClaimmetadata: name: nfsspec: accessModes: - ReadWriteMany storageClassName: &quot;nfs-client&quot; resources: requests: storage: 4Gikubectl apply -f nfs-pvc.yamlkubectl get pv,pvcNAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGEpersistentvolume/pvc-9d5d042b-bb50-4087-98c0-d8fdb7f0d70e 4Gi RWX Delete Bound default/nfs nfs-client 62sNAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGEpersistentvolumeclaim/nfs Bound pvc-9d5d042b-bb50-4087-98c0-d8fdb7f0d70e 4Gi RWX nfs-client 63s위와 같이 PVC만 생성하여도 PV가 정상적으로 생성ls -al /mnt/repo/total 0drwxrwxrwx 3 root root 66 May 3 09:12 .drwxr-xr-x. 3 root root 18 May 2 15:21 ..drwxrwxrwx 2 root root 6 May 3 09:12 default-nfs-pvc-9d5d042b-bb50-4087-98c0-d8fdb7f0d70e위와 같이 NFS 서버에서도 확인kubectl delete pvc nfs테스트 후 pvc 삭제참고) pvc 생성 시 access denied 이슈pvc를 생성하는 Pod가 계속 Init stuck 상태 발생. 아래와 같은 describe 확인.Output: mount.nfs: access denied by server while mounting woobin-vm1:/mnt/repo/monitoring-prometheus-kube-prometheus-stack-prometheus-db-prometheus-kube-prometheus-stack-prometheus-0-pvc-ba3f5202-a49f-42fe-83a5-026dbdac7046/etc/exports에 nfs server도 설정되어 있어야 함. 안되어 있으면 해당 노드 pvc 생성 시 위와 같은 에러 발생/mnt/repo woobin-vm1(rw,sync,no_root_squash,no_subtree_check)/mnt/repo woobin-vm2(rw,sync,no_root_squash,no_subtree_check)/mnt/repo woobin-vm3(rw,sync,no_root_squash,no_subtree_check)Reference https://kubernetes.io/ko/docs/concepts/storage/persistent-volumes/ https://kubernetes.io/ko/docs/concepts/storage/storage-classes/#nfs https://github.com/kubernetes-sigs/nfs-subdir-external-provisioner/blob/master/charts/nfs-subdir-external-provisioner/README.md" }, { "title": "NFS 서버/클라이언트 설정", "url": "/posts/post240514/", "categories": "Linux", "tags": "Linux", "date": "2024-05-14 19:00:00 +0900", "snippet": " NFS 서버에서는 ‘sync’ 옵션을 사용하여 데이터의 일관성을 보장하는 반면, NFS 클라이언트에서는 ‘async’ 옵션을 사용하여 성능을 향상 시키기 위해 입출력 작업을 비동기적으로 처리NFS Server (DB Server)# 1. 디렉터리 생성sudo mkdir -p /fsnfs/share /fsnfs/userln -s /fsnfs /mnt/repo# 2. NFS 서버 서비스 기동sudo dnf install -y nfs-utilssudo systemctl start nfs-serversudo systemctl enable nfs-server# 3. exports 파일 설정sudo vi /etc/exports/mnt/repo/share [NFS 클라이언트 호스트 아이피 혹은 도메인](rw,sync,no_root_squash)/mnt/repo/user [NFS 클라이언트 호스트 아이피 혹은 도메인](rw,sync,no_root_squash)# 4. 수정 내용 반영sudo exportfs -r# 5. 공유 디렉토리 확인sudo exportfs -v# 참고) 방화벽이 내려가 있어야함sudo systemctl stop firewalldsudo systemctl disable firewalld 공유 옵션 ro → 읽기 권한만 부여 rw → 읽기 쓰기 권한 부여 root_squash  → 클라이언트에서 root를 서버상의 nobody 계정으로 매핑 no_root_squash  → 클라이언트 및 서버의 root를 동일하게 사용 no_root_squash vs. root_squash (more) no_root_squash는 NFS 서버의 보안 설정 중 하나로, 클라이언트에서 NFS 공유 디렉터리에 루트 사용자(root)로 접근할 때 루트 사용자의 UID와 GID를 변경하지 않는 옵션입니다. 이 옵션을 사용하면 클라이언트의 루트 사용자가 공유된 디렉터리에 대해 루트 권한을 가진 채로 작업할 수 있습니다. 기본적으로 NFS 서버에서는 root_squash라는 옵션이 활성화되어 있습니다. 이 옵션은 클라이언트의 루트 사용자가 NFS 공유 디렉터리에 접근할 때, 루트 사용자의 UID와 GID를 일반 사용자의 UID와 GID로 매핑하여 보안을 강화하는 것을 의미합니다. 이로써 클라이언트의 루트 사용자가 공유 디렉터리에서 잠재적으로 위험한 작업을 수행하는 것을 제한합니다. no_root_squash를 사용하면 루트 사용자의 UID와 GID가 변경되지 않으므로, 클라이언트의 루트 사용자는 NFS 공유 디렉터리에 대해 전체적인 권한을 가질 수 있습니다. exportfs -r 모든 공유 디렉터리를 다시 내보내고, /var/lib/nfs/etab과 /etc/exports 파일, 그리고 /etc/exports.d 디렉터리 밑의 모든 파일들에 대한 동기화 한다. NFS Client (ML Server)# 1. 디렉터리 생성sudo mkdir -p /mnt/repo/share /mnt/repo/user# 2. NFS 유틸 설치sudo dnf install -y nfs-utils# 3. fstab 등록sudo vi /etc/fstab[NFS 서버 호스트 아이피]:/mnt/repo/share /mnt/repo/share nfs nolock,noacl,async,noatime,_netdev 0 0[NFS 서버 호스트 아이피]:/mnt/repo/user /mnt/repo/user nfs nolock,noacl,async,noatime,_netdev 0 0# 4. fstab 적용sudo mount -a# 5. nfs 서버 내보내기된 목록 확인showmount -e [NFS 서버 호스트 아이피]# 6. 확인df -h" }, { "title": "자바스크립트 런타임", "url": "/posts/post240402/", "categories": "Javascript", "tags": "Javascript", "date": "2024-04-02 19:00:00 +0900", "snippet": "1. 자바스크립트 엔진과 자바스크립트 런타임1) 웹 브라우저크롬 웹 브라우저는 V8 엔진이 탑재된 자바스크립트 런타임이다.자바스크립트란? 자바스크립트는 프로그래밍 언어이다.자바스크립트 런타임이란? 런타임이란 프로그래밍 언어가 구동되는 환경 자바스크립트 런타임이란 자바스크립트가 구동되는 환경을 말한다. 이러한 자바스크립트 런타임의 종류로는 웹 브라우저(크롬, 파이어폭스, 익스플로러 등)프로그램과 Node.js 라는 프로그램이 있다. 이러한 프로그램들에서 자바스크립트가 구동되기 때문에 자바스크립트 런타임이라고 한다.V8 엔진이란? V8은 오픈 소스 자바스크립트 엔진 중 하나이다. 자바스크립트 엔진은 자바스크립트 코드를 실행하는 소프트웨어이다. V8 엔진은 자바스크립트와 함께 웹어셈블리(WebAssembly) 엔진도 포함한다. 크롬 웹 브라우저와 Node.js 등에서 사용되고 있다. V8은 자바스크립트를 바이트코드로 컴파일하고 실행하는 방식을 사용한다.웹어셈블리란? 웹어셈블리(WebAssembly)란 C나 C++와 같은 프로그래밍 언어를 컴파일해서 어느 브라우저에서나 빠르게 실행되는 형식으로 바꿔주는 기술을 뜻한다. 보통 웹 애플리케이션 개발시에는 JavaScript 프로그래밍 언어를 사용해 동적인 부분을 개발하는데 C나 C++ 언어들에 비해서는 느리다. 게임이나 동영상 편집 등과 같은 고성능 웹 애플리케이션을 개발할 때 브라우저의 동작을 빠르게 하기 위해서 C나 C++와 같은 언어로 개발 할 수 있게 하는 것이다. 고성능 웹 애플리케이션 개발 시 자바스크립트와 같이 사용되고, 자바스크립트를 대체하는 것이 아니라 보완하는 기술이다.2) V8 엔진과 웹 브라우저자바스크립트 자체 즉, 자바스크립트 엔진(V8)과 자바스크립트 런타임(웹 브라우저)에서 제공하는 API 메서드로 프로그래밍을 하는 것이다.자바스크립트 엔진 V8의 구성 자바스크립트는 전통적으로 싱글 스레드이다. 이러한 싱글 스레드는 하나의 힙 영역과 하나의 콜 스택을 가진다. 그래서 자바스크립트 V8 엔진 소스 안에는 하나의 힙과 하나의 콜 스택만 있다. 하나의 콜 스택을 가진다는 의미는 한 번에 한 가지 일 밖에 못한다는 의미이다. 싱글 스레드는 일을 동기적으로 처리한다. setTimeout, DOM, AJAX(HTTP 요청)등과 같은 비동기 메소드가 없다.function SignThreadTest() { console.log(1); for( let i=0; i&amp;lt;10000; i++ ) { console.log(&#39;자바스크립트는 싱글 스레드 프로그래밍 언어이다.&#39;); } console.log(2);}// &#39;자바스크립트는 싱글 스레드 프로그래밍 언어이다.&#39;가 10,000번 실행이 완료 될 때까지// 콘솔 창에 &#39;3&#39; 이 찍히는 것을 기다려야한다.SignThreadTest();자바스크립트 런타임 웹 브라우저의 Web APIs 이벤트 루프와 콜백 큐를 가지고 있다. Web API는 자바스크립트가 실행되는 런타임 환경에 존재하는 별도의 API 이다. (V8 소스코드에는 존재하지 않는다.) setTimeout, DOM, AJAX(HTTP 요청)등이 있다.웹 브라우저의 Web APIs는 비동기로 처리한다. 위에서 웹 브라우저에 Web APIs 에는 setTimeout, DOM, AJAX(HTTP 요청) 등이 있다고 했다. 그리고 이벤트 루프와 콜백 큐를 가지고 있다. 자바스크립트 자체는 비동기적으로 요청을 처리할 수 없다. 자바스크립트 런타임 안에 지원하는 API로 비동기로 요청을 처리할 수 있게 하는 것이다. 콜백 큐는 Web API 결과값을 쌓아두는 큐이다. 예를 들어 자바스크립트에서 setTimeout(cd, 5000)을 호출하게 되면 Web API는 타이머를 동작시켜 5초 후에 콜백 큐에 cd를 쌓는다. 예) 큐에 쌓일 비동기식 콜백 function asyncForEach(arr, fnc) { arr.forEach((i) =&amp;gt; { setTimeout(() =&amp;gt; fnc(i), 1000); });}asyncForEach([1,2,3,4], (i) =&amp;gt; console.log(i)); 2. 자바스크립트 런타임에서 비동기 처리 방법 자바스크립트 런타임에서 제공하는 비동기 콜백을 만드는 것은 이벤트 루프이다. 웹 브라우저와 같은 자바스크립트 런타임에서는 비동기 콜백으로 자바스크립트라는 싱글 스레드 프로그래밍 언어에서의 블로킹을 해결한다. (느린 동작이 스택에 남아 있는 것을 보통 블로킹) 이벤트 루프 이벤트 루프의 역할은 콜 스택과 콜백 큐를 주시하는 것이다. 이벤트 루프는 콜 스택이 비어질 때까지 기다린 후 콜백 큐에 있는 콜백을 콜 스택에 넣어주는 역할을 한다. Web API의 콜백이 완료되었다면 콜백은 큐에 쌓이게 되고, 이벤트 루프에 의해서 실행된다. 이 과정은 비동기 함수가 호출되는 방식이다.AJAX AJAX는 Asynchronous JavaScript and XML의 약자로, 웹 페이지에서 비동기적으로 서버와 데이터를 주고받는 기술이다. AJAX Ruquest는 URL로 호출할 때 콜백을 함께 실행하게 된다. AJAX 요청을 보낼 때, 해당 요청에 대한 응답이 도착했을 때 실행될 콜백 함수를 함께 등록할 수 있다. 콜백 함수는 서버 응답을 처리하거나, 요청이 완료되었을 때 필요한 후속 작업을 수행하는 등의 역할을 할 수 있다. 이렇게 AJAX 요청을 보낼 때 콜백을 함께 실행하게 되므로, 비동기적으로 서버와의 통신을 처리하고 응답을 처리할 수 있게 된다." }, { "title": "(Python)(백준_12891) DNA 비밀번호", "url": "/posts/post231224/", "categories": "CodingTest", "tags": "CodingTest", "date": "2023-12-24 19:30:00 +0900", "snippet": "&#39;&#39;&#39;https://www.acmicpc.net/problem/12891특정 배열에서 크기가 고정인 부분 배열을 빠르게 처리해야하기 때문에 sliding window 사용(sliding window의 시간복잡도 = O(n))&#39;&#39;&#39;import sysinput = sys.stdin.readlineS, P = map(int, input().split()) # 4 2input_string = list(input().strip()) # GATAA, C, G, T = map(int, input().split()) # 1 0 0 1substring = input_string[:P-1]dic = {&#39;A&#39;: 0, &#39;C&#39;: 0, &#39;G&#39;: 0, &#39;T&#39;: 0}cnt = 0for i in substring: dic[i] += 1# 부분 문자열 슬라이딩 윈도우 이용하여 전체 문자열 확인for i in range(P-1, S): # i = 1 2 3 dic[input_string[i]] += 1 # 윈도우 오른쪽 끝 문자 추가 # 현재 윈도우가 조건을 만족하는지 확인 if dic[&#39;A&#39;] &amp;gt;= A and dic[&#39;C&#39;] &amp;gt;= C and dic[&#39;G&#39;] &amp;gt;= G and dic[&#39;T&#39;] &amp;gt;= T: cnt += 1 dic[input_string[i-P+1]] -= 1 # 윈도우 왼쪽 끝 문자 제거print(cnt)" }, { "title": "(Python)(백준_2589) 보물섬", "url": "/posts/post231218/", "categories": "CodingTest", "tags": "CodingTest", "date": "2023-12-18 19:30:00 +0900", "snippet": "2589번: 보물섬BFS를 이용한 풀이from collections import dequedef main(): rowSize, columnSize = map(int, input().split()) graph = [ list(input()) for _ in range(rowSize) ] result=0 for x in range(rowSize): for y in range(columnSize): if graph[x][y]==&#39;L&#39;: result = max(result, bfs(x, y, graph, rowSize, columnSize)) print(result)def bfs(x, y, graph, rowSize, columnSize): dx, dy = [-1, 1, 0, 0], [0, 0, -1, 1] queue=deque() queue.append((x,y)) visited = [ [0] * columnSize for _ in range(rowSize) ] visited[x][y] = 1 cnt = 0 while queue: x, y = queue.popleft() for i in range(len(dx)): nx, ny = x + dx[i], y + dy[i] if 0 &amp;lt;= nx &amp;lt; rowSize and 0 &amp;lt;= ny &amp;lt; columnSize and graph[nx][ny] == &#39;L&#39; and visited[nx][ny] == 0: visited[nx][ny] = visited[x][y] + 1 cnt = max(cnt, visited[nx][ny]) queue.append([nx, ny]) return cnt-1if __name__== &quot;__main__&quot;: main()" }, { "title": "(Java) IoC", "url": "/posts/post231129/", "categories": "Java", "tags": "Java", "date": "2023-11-29 19:00:00 +0900", "snippet": "**IoC**Inverse of Control는 제어권을 개발자가 아닌 제 3자(프레임워크)가 가지게 하는 것이다.그렇다면 우리는 왜 제어권을 3자에게 위임해야 하는가?이에 대한 답을 찾기전에 과거로 돌아가보자. 과거 많은 형태의 오픈소스들이 나오고 있었고, 이들의 공통적인 이슈는 서로 다른 객체를 어떻게 연결할 것인지에 대한 문제였다. 이를 해결할 한 가지 방법으로 IoC가 제시되었다.즉, IoC의 주된 목적은 Application의 Dependency를 제거해서 느슨한 결합을 제공하는 것이다. Dependency 코드에서 두 모듈 간의 연결. 객체지향언어에서는 두 클래스 간의 관계 public class MemberService { public String parseString(ObjectMapper objectMapper, Member member) throws JsonProcessingException { return objectMapper.writeValueAsString(member); }}위 코드는 Jackson 라이브러리의 ObjectMapper를 이용하여 특정 객체를 Json String으로 변환작업을 하는 로직이다. MemberService는 ObjectMapper의 기능을 사용하고 있기 때문에 의존하고 있다고 할 수 있다.ObjectMapper.writeValueAsString()의 구현부가 변하게 되면 MemberService.parseString() 또한 변하게 된다.위의 MemberService는 클래스간의 강하게 결합을 하고 있다.왜냐하면 몇몇은 JSON 변환 작업을 ObjectMapper를 사용해서 그대로 재사용하면 되지만 다른 몇몇은 Gson을 사용하기 때문에 코드에 전반적인 수정이 필요하다.이러한 강한 결합을 Interface의 도움을 받아 느슨하게 할 수 있다.public interface JsonParser { &amp;lt;T&amp;gt; T parseObject(String s, Class&amp;lt;T&amp;gt; clazz); &amp;lt;T&amp;gt; String parseString(T obj);}public class MemberService { public String parseString(JsonParser jsonParser, Member member) { return this.jsonParser.parseString(member); }}이전 코드에서는 MemberService 클래스안에 ObjectMapper가 직접적으로 들어가 있었지만, 이번 코드에서는 MemberService는 Interface인 JsonParser만을 알고 있다. 이로 인해 사용자는 원하는 JsonParser 구현체를 입맛에 맞게 사용할 수 있다.또 다른 사례를 알아보자.public class CalendarReader { public List readCalendarEvents(File calendarEventFile){ //open InputStream from File and read calendar events. }}위의 코드는 XML Local file을 통해서 이벤트 목록을 읽어오는 메소드다.본인만 쓴다면 문제가 없겠지만, 이 소스를 다수의 사람들이 사용을 해야한다. 그런데 그들 중 일부는 XML을 통해 이벤트를 관리하지만, 다른 몇몇은 DB, Network 등을 통해서 관리를 한다.즉, 다른 리소스로 관리를 하는 사람은 해당코드를 재사용할 수가 없게 된다.이를 좀 더 포괄적인 InputStream을 사용하면서 결합을 좀 더 느슨하게 유도 할 수 있다.public class CalendarReader { public List readCalendarEvents(InputStream calendarEventFile){ //read calendar events from InputStream }}이렇듯 느슨한 결합을 통하여 클래스의 재사용성을 높일 수 있다. 또한 재사용성을 높인 다는 말은 비슷한 류의 중복 코드가 제거될 수 있음을 의미하기도 한다.다시 처음으로 돌아가보자. IoC의 주된 목적은 Application의 Dependency를 제거하는 것이라고 하였다. IoC 방식에는 아래 사진 외에도 여러가지가 있다 그러나 우리는 몇 가지 핵심적인 방식들을 살펴보도록 하자.**Dependency Injection** (Java) 의존관계 주입 (Dependency Injection) 포스트 참고IoC 방식 중 가장 대표적인 방식으로 보인다. Interface의 느슨한 결합을 이용하여 Compile 시점에서 Dependency를 가지지 않고, Runtime 시점으로 미룰 수 있다.이를 좀 더 쉽게 표현하자면, 코드상에서 구현체가 존재하지 않고 단지 Inteface만 존재한다. 이로 인해 구현부가 변경되더라도 해당 코드를 수정하는 것이 아닌 Dependency만 변경해 주면 된다.public class Member { private String name; private int age; private String address;}public class MemberService { private final ObjectMapper objectMapper = new ObjectMapper(); public String parseString(Member member) throws JsonProcessingException { return this.objectMapper.writeValueAsString(member); } public Member parseObject(String member) throws IOException { return this.objectMapper.readValue(member, Member.class); }}위의 코드는 Member 객체를 JSON 형태의 String으로, JSON형태의 String을 Member객체로 변환하는 코드이다.그런데 특정한 이슈(Library 지원 종료, 속도 문제, 회사 정책 등)로 인하여 JSON 변환 Library 인 ObjectMapper를 Gson이나 다른 라이브러리로 교체하고 싶으면 어떻게 될까?public class MemberService { private final Gson gson = new Gson(); public String parseString(Member member) { return this.gson.toJson(member); } public Member parseObject(String member) { return this.gson.fromJson(member, Member.class) }}아예 새로운 코드가 되어버렸다. 클래스와 메소드 이름만 같지 모든 구현부가 바뀌어버렸다.개인이 혼자 쓰는 프로젝트라면 상관이 없을 것이다. 그러나 오픈소스 또는 여러 기업에 팔아야되는 입장인데 위처럼 구현부가 변할때마다 코드를 수정해서 줘야 한다면 큰 문제가 있다.이를 우리가 사용자 입맛에 맞게 일일이 변경해서 주는 것이 아니라, 가이드를 제공해줌으로써 사용자가 알아서 입맛에 맞게 수정하도록 변경해보자.앞서 말한 Interface의 도움을 받아 사용자에게 가이드를 줌과 동시에 객체간에 느슨한 결합을 맺어주자.public interface JsonParser { &amp;lt;T&amp;gt; T parseObject(String s, Class&amp;lt;T&amp;gt; clazz); &amp;lt;T&amp;gt; String parseString(T obj);}public class MemberService { private JsonParser jsonParser; public String parseString(Member member) { return this.jsonParser.parseString(member); } public Object parseObject(String member) { return this.jsonParser.parseObject(member, Member.class); }}우리는 위처럼 코드를 작성 후 오픈소스로 공개를 하거나, 다른 기업에 팔면 된다.그럼 ObjectMapper를 사용하는 기업은 어떻게 자기 입맛에 맞게 구현을 할까?public class JacksonParser implements JsonParser { private final ObjectMapper objectMapper; public JacksonParser() { this.objectMapper = new ObjectMapper(); } @Override public &amp;lt;T&amp;gt; T parseObject(String s, Class&amp;lt;T&amp;gt; clazz) { try { return this.objectMapper.readValue(s, clazz); } catch (IOException e) { throw new JsonParseException(e); } } @Override public &amp;lt;T&amp;gt; String parseString(T obj) { try { return this.objectMapper.writeValueAsString(obj); } catch (JsonProcessingException e) { throw new JsonParseException(e); } }}다음은 Gson의 구현체이다.public class GsonParser implements JsonParser { private final Gson gson; public GsonParser() { this.gson = new Gson(); } @Override public &amp;lt;T&amp;gt; T parseObject(String s, Class&amp;lt;T&amp;gt; clazz) { return this.gson.fromJson(s, clazz); } @Override public &amp;lt;T&amp;gt; String parseString(T obj) { return this.gson.toJson(obj); }자 그럼 MemberService를 실행시켜보자. NullPointerException이 떨어질 것이다. 왜냐하면 전역변수(jsonParser)로 선언만 해놓았지 구현체를 할당하지 않았기 때문이다.주로 우리는 다음과 같이 인스턴스를 할당한다.public class MemberService { private final JsonParser jsonParser; public MemberSservice() { this.jsonParser = new JacksonParser(); }}위의 코드의 문제점은 무엇일까?우리는 지금까지 코드 레벨에서 특정 구현 객체(JacksonParser)를 보이지 않게 숨기려고 했는데, 다시 드러났다. 결국 허사가 된 것이다.이를 다시 숨기려면 어떻게 해야 될까?객체 생성을 사용자에게 전가시키고 그 객체를 주입을 받는 것이다. 좀 더 정확하게 말하자면 의존성을(Dependency)을 사용자에 의해 주입(Injection)받는 것이다.Constructor Injection주로 필수적인 Dependency에 사용된다.public class MemberService { private final JsonParser jsonParser; public MemberService(JsonParser jsonParser) { this.jsonParser = jsonParser; }}Setter Injection주로 부수적인 Dependency에 사용된다.public class MemberService { private JsonParser jsonParser; public void setJsonParser(JsonParser jsonParser) { this.jsonParser = jsonParser; }}위와 같이 구현을 했으면, 사용자는 다음과 같이 사용하면 된다.public static void main(String [] args) { JsonParser parser = new JacksonParser(); //Constructor Injection MemberService memberService = new MemberService(parser); //Setter Injection memberService = new MemberService(); memberService.setParser(parser); memberService.parseObject(...); memberService.parseString(...);}유닛 테스트를 좀 더 쉽게 할 수 있는 장점이 있다.유닛 테스트는 일반적으로 외부의 의존성을 제외하고, 해당클래스에 집중을 하는 테스트 기법이다.MemberService의 경우에는 사실 비즈니스 로직이 없이 의존성을 가진 인스턴스의 기능을 사용하는 것 뿐이지만, 로직이 있다고 가정을 하고 작성을 해보자. JsonParser의 구현체들이 직접 실행되는 것이 아닌 Mock, Stub의 개념을 조금 넣어보자. 해당코드는 아래와 같다.public class MockJsonParser implements JsonParser { @Override public &amp;lt;T&amp;gt; T parseObject(String s, Class&amp;lt;T&amp;gt; clazz) { return new Member(&quot;김민수&quot;, 26, &quot;수원시&quot;); } @Override public &amp;lt;T&amp;gt; String parseString(T obj) { return &quot;{\\&quot;name\\&quot; : \\&quot;김민수\\&quot;, \\&quot;age\\&quot; : 26, \\&quot;address\\&quot; : \\&quot;수원시\\&quot;}&quot;; }}public static void main(String [] args) { JsonParser parser = new MockJsonParser(); //Constructor Injection MemberService memberService = new MemberService(parser); memberService.parseObject(...); memberService.parseString(...);}이처럼 주입을 시켜주면 간단하게 테스트를 할 수가 있다.사실 이 상황에서는 강력함이 보이지 않지만, 만약 이것이 JSON 변환 작업이 아닌 DB나 Network와 연결이 된 작업이라면 직접 해당 리소스와 연결되지 않고 Interface를 구현한 Mock객체로 간단하게 테스트를 해볼 수가 있다.우리는 지금까지 사용자에게 Dependency Injection을 하게끔 유도함으로 유연하고 재활용 가능한 클래스를 만들었다.**Service Locator**Service Locator에 관한 핵심만 말하자면 이를 이용해서도 제어를 역전(IoC)시킬 수 있다. 이 패턴 또한 목적은 Dependency를 제거하는 것이다.public class MemberService { private final JsonParser jsonParser; public MemberService() { this.jsonParser = ServiceLocator.jsonParser(); } public String parseString(Member member) { return this.jsonParser.parseString(member); }}public class ServiceLocator { public static JsonParser jsonParser() { return new JacksonParser(); }}위에 작성한 Constructor Injection의 실행 코드를 보면 main() 메소드에서 사용자가 직접 new 키워드를 통해 인스턴스를 생성 후 주입을 해준다. 다시 말하면 런타임 시에 수동적으로 의존성이 연결이 된다.그러나 Service Locator는 ServiceLocator.jsonParser()에 원하는 인스턴스를 생성해두면 MemberService가 생성이 될 때 직접 ServiceLocator.jsonParser()를 호출하여 능동적으로 의존성을 맺는다.능동적이란 단어가 좀 긍정적여 보이긴 하지만, 위에서 처럼 테스트코드로 디펜던시를 바꿔야되는 상황을 한번 가정해보자.public class ServiceLocator { public static JsonParser jsonParser() { //경우에 따라 Singleton이나 다른 Scope로 구현을 하기도 한다. return new MockJsonParser(); }}그럼 ServiceLocator는 테스트할 때와 서비스를할 때의 상황에 따라 코드를 바꿔줘야되는 이슈가 생긴다." }, { "title": "(Java) Null Pointer Exception (NPE)", "url": "/posts/post231127/", "categories": "Java", "tags": "Java", "date": "2023-11-27 19:00:00 +0900", "snippet": "null로 인해 발생된 에러는 시간이 지날수록, 자신이 개발한 소스가 아닌 경우 더욱 더 디버깅 하기 어려워 진다.null이 발생하는게 오류가 아닐 수 도 있고, 오히려 참 일수도 있고, null인경우 또다른 어떤 의미를 내포하고 있는지 판단하기 어렵다.즉, 처음부터 NPE를 발생시키지 않도록 코딩하면 자연스럽게 코드의 품질이 향상될 것 이다.문자열 비교 시 equlas 문자열을 먼저 위치 하자.(또는 Constants 사용하자)NPE를 발생할 수 있는 코딩 예시public static void main(String[] args) { String a = null; System.out.println(&quot;1번째============&quot;); if (a == &quot;god&quot;) { System.out.println(&quot;참&quot;); } else { System.out.println(&quot;거짓&quot;); //거짓 출력 } System.out.println(&quot;2번째============&quot;); if (a.equals(&quot;god&quot;)) { // NPE 발생! System.out.println(&quot;equals =&amp;gt; 참&quot;); } else { System.out.println(&quot;equals =&amp;gt; 거짓&quot;); }}/******* 결과 *******/1번째============Exception in thread &quot;main&quot;거짓2번째============java.lang.NullPointerExceptiona의 변수가 null인경우 “NPE”가 발생한다. null은 객체가 아니기 때문에 당연히 “equlas” 라는 메서드도 없기 때문이다.public static void main(String[] args) { String a = null; if (&quot;god&quot;.equals(a)) { // NPE 발생하지 않음 System.out.println(&quot;equals =&amp;gt; 참&quot;); } else { System.out.println(&quot;equals =&amp;gt; 거짓&quot;); }}/******* 결과 *******/equals =&amp;gt; 거짓“비교의 주체가 문자열”부터 주어진다면”NullPointException”이발생하지 않는다.결국 순서만 바꿨음에도 적어도”NullPointException”을피할 수 있게 된다.정리해보면 문자열 비교는”non-null String 기준으로 비교” 하는 것이 좋다.”비교의 주체가 문자열”이 오도록 하거나,”Constants 등을 활용” 하여 코딩 하는 것을 추천 한다. toString() 대신 =&amp;gt; valueOf() 사용public static void main(String[] args) { Integer a = 1; System.out.println(a.toString()); a = null; System.out.println(a.toString());}/******* 결과 *******/1Exception in thread &quot;main&quot; java.lang.NullPointerExceptionpublic static void main(String[] args) { Integer a = null; System.out.println(String.valueOf(a));}/******* 결과 *******/null" }, { "title": "(Python)(백준_17413) 단어 뒤집기 2", "url": "/posts/post231106/", "categories": "CodingTest", "tags": "CodingTest", "date": "2023-10-24 19:30:00 +0900", "snippet": "17413번: 단어 뒤집기 2풀이# &amp;lt;, &amp;gt; 안에 있는 문자열은 그대로 출력하고, 그 밖에 있는 문자들을 스택에 담는다. 공백이 있을 경우 스택에 담았던 문자열을 뒤집어 출력한다.# 연속하는 두 단어는 공백 하나로 구분함 -&amp;gt; 공백이 나오면 현재 스택에 있는 건 단어# 태그와 단어 사이에는 공백이 없음 -&amp;gt; 태그가 시작되면 현재 스택에 있는 건 단어 ans = &quot;&quot;tag = Falsestack = &quot;&quot;for i in input(): if i == &quot;&amp;lt;&quot;: tag = True ans += stack[::-1] stack = &quot;&quot; ans += i continue elif i == &quot;&amp;gt;&quot;: tag = False ans += i continue elif i == &quot; &quot;: ans += stack[::-1] + &quot; &quot; stack = &quot;&quot; continue if tag: ans += i else: stack += iprint(ans + stack[::-1])" }, { "title": "(Python)(백준_3020) 개똥벌레", "url": "/posts/post231102/", "categories": "CodingTest", "tags": "CodingTest", "date": "2023-10-24 19:30:00 +0900", "snippet": "3020번: 개똥벌레풀이# 높이 h부터 높이 1까지 누적 합을 계산하면 높이 i의 배열 값은 높이 i 이상의 모든 석순의 개수# 예를 들어, 높이가 6인 동굴에서 높이 5의 개똥벌레가 날아갈 때, # 높이 5 이상의 석순에 모두 부딪히기 때문에 배열 5의 값이 높이 5의 개똥벌레가 부딪히는 석순의 개수# 마찬가지로 종유석은 위에서부터 내려오기 때문에 h - i + 1의 식을 이용# 왜냐하면, 높이 6의 동굴에서 높이 2짜리 종유석은 높이 4 위로의 개똥벌레가 모두 부딪히기 때문# 장애물의 개수와 전체 높이n, h = map(int, input().split())# 석순 정보 저장down = [0] * (h+1)# 종유석 정보 저장up = [0] * (h+1)for i in range(n): height = int(input()) if (i % 2 == 0): # 석순의 높이에 따라 1 증가 down[height] += 1 else: # 종유석의 높이에 따라 1 증가 up[height] += 1# 인덱스를 역순으로 누적합을 계산for i in range(h-1, 0, -1): # h = 6 , 5 , 4 down[i] += down[i+1] up[i] += up[i+1]# 최소로 잘리는 장애물의 개수min_count = n# 동일한 개수로 잘리는 높이의 수same_height = 0# 전체 높이 i 기준, 높이에 따라 잘리는 석순과 종유석의 개수 파악for i in range(1, h+1): # 현재까지 최소로 잘린 개수보다 현재 높이에서 더 적은 수로 잘리는 경우 if (min_count &amp;gt; down[i] + up[h - i + 1]): min_count = down[i] + up[h - i + 1] same_height = 1 # 현재 높이에서 잘린 개수가 현재까지 최소로 잘린 개수와 동일하다면 elif (min_count == down[i] + up[h - i + 1]): same_height += 1print(min_count, same_height)" }, { "title": "(Python)(백준_10026)(DFS) 적록색약", "url": "/posts/post231024/", "categories": "CodingTest", "tags": "CodingTest", "date": "2023-10-24 19:30:00 +0900", "snippet": "10026번: 적록색약DFS 풀이# 적록색약인 경우 G를 R로 치환from typing import Listimport syssys.setrecursionlimit(10**5)input=sys.stdin.readlineN = int(input())graph = [list(input().rstrip()) for _ in range(N)]visited = [[False] * N for _ in range(N)]d = [(0,1), (0, -1), (1,0), (-1,0)]def dfs(x, y): visited[x][y] = True color = graph[x][y] for dx, dy in d: nx, ny = x + dx, y + dy if 0 &amp;lt;= nx &amp;lt; N and 0 &amp;lt;= ny &amp;lt; N and not visited[nx][ny] and graph[nx][ny] == color: dfs(nx, ny) cnt, cnt2 = 0, 0for y in range(N): for x in range(N): if visited[x][y] == False: dfs(x,y) cnt += 1for y in range(N): for x in range(N): if graph[x][y] == &#39;G&#39;: graph[x][y] = &#39;R&#39;visited = [[False] * N for _ in range(N)]for y in range(N): for x in range(N): if visited[x][y] == False: dfs(x,y) cnt2 += 1print(cnt, cnt2)" }, { "title": "도커 엔진", "url": "/posts/post230927/", "categories": "Docker", "tags": "Docker", "date": "2023-09-27 19:30:00 +0900", "snippet": " 컨테이너 런타임, CRI, OCI 개념은 ‘(Cloud) 컨테이너 런타임, CRI, OCI’ 글 참고 Docker는 Client-Server 모델을 구현한 애플리케이션입니다. Docker Engine은 Docker Components와 서비스를 제공하는 컨테이너를 구축하고 실행하는 기본 핵심 소프트웨어입니다. Docker Engine은 Docker Daemon, REST API, API를 통해 도커 데몬과 통신하는 CLI로 모듈식으로 구성되어있습니다. 개발자들이 Docker라고 할 때, 주로 Docker engine을 의미합니다. 컨테이너를 빌드, 실행, 배포하는 등의 무거운 작업은 Docker Daemon이 하며, Docker Client는 이러한 로컬 혹은 원격의 Docker Daemon과 통신합니다. 통신을 할 때에는 UNIX socket(/var/run/docker.sock) 또는 네트워크 인터페이스를 통한 REST API를 사용합니다.docker client Docker Client는 개발자들이 Docker를 사용하는 Docker CLI나 Docker Compose로, $ docker run 과 같은 명령어를 dockerd에게 REST API 형태로 전달합니다. 유저가 Docker CLI를 통해 아래와 같은 명령어를 입력합니다. (e.g. $ docker container run --name ctr1 -it alpine:latest sh ) Docker CLI에 입력하면 Docker client는 적절한 API Payload로 변환해서 Docker Daemon(이하 dockerd)에게 REST API로 POST 요청을 합니다. (e.g. POST /containers/create HTTP/1.1 ) dockerd 도커 데몬(dockerd)은 Docker API 요청을 수신 API는 Unix Socket을 통해 dockerd에게 전달됩니다. Linux에서 socket은 /var/run/docker.sock 새 컨테이너를 시작할 때, dockerd는 로컬 이미지가 있는지 확인하고 없다면 registry repository에서 해당하는 이름의 이미지를 가져옵니다. 또한 logging drivers와 volume이나 volume drivers를 설정하는 등 컨테이너에 필요한 대부분의 설정을 지정합니다. dockerd가 ‘새로운 container를 생성하라’는 명령을 수신하면, containerd를 호출합니다.이때, dockerd는 CRUD 스타일 API를 통해 gRPC로 containerd와 통신합니다. (e.g. client.NewContainer(context, ...) ) containerd containerd는 Docker Engine v1.11 이후 Docker 코어 컨테이너 런타임 입니다. runc 기반이며, 컨테이너 표준인 OCI (Open Container Initiative)을 준수하고 있습니다. https://www.docker.com/blog/docker-engine-1-11-runc/ containerd는 고수준 컨테이너 런타임으로 CRI API를 구현합니다. containerd는 socket을 통해 전달된 gRPC 요청을 처리합니다. containerd는 실제로 containers를 생성하지 못하고, runc를 통해 생성합니다. 레지스트리에서 Docker 이미지를 가져와서 컨테이너 구성을 적용하여 runc가 실행할 수 있는 OCI 번들로 변환합니다.runc runc는 OCI container-runtime-spec의 구현체입니다. OCI(Open Container Initiative)는 kernel의 container 관련 기술을 다루는 interface를 표준화시킨 기준입니다. 그래서 runc가 동작하는 계층을 OCI Layer라고 부르기도 합니다. runc는 OS 커널에 접속해서 컨테이너를 만드는 데 필요한 모든 구성 요소(네임스페이스, cgroup 등)를 하나로 묶습니다. runc는 새로운 container를 생성합니다. 최초 이름은 libcontainer이였는데 docker project에서 OCI에 기부되었고, 이후 이름이 runc가 되었습니다. 즉, runc는 libcontainer의 리팩토링 구현체입니다. 이후 docker에서 자체 개발한 libcontainer Go library를 사용하면서 host kernel의 namesapce, cgroups에 의존되지 않고 OS에서 독립되어 동작할 수 있습니다. libcontainer에서 cgroups 관리 모듈로는 cgroupfs 또는 systemd 둘 중 하나를 사용할 수 있지만모든 모듈이 systemd를 사용하는 쪽으로 update되고 있습니다.shim 그 다음 컨테이너를 시작하기 위해 docker-containerd-shim과 같은 shim을 실행합니다. 앞에서 containerd가 새로운 컨테이너를 만들기 위해 runc를 사용한다고 했는데, containerd는 생성되는 모든 container 당 runc의 새로운 인스턴스를 fork 합니다. 각 컨테이너가 생성되면, 상위 runc 프로세스가 종료됩니다. 생성된 container의 stdin/out/err 및 Init Process의 Exit Code를 담당하는 Process가 필요한데, containerd-shim 프로세스를 subreaper로 만들어서 생성된 container의 stdin/out/err 및 Init Process의 Exit Code를 담당하는 Process가 containerd-shim이 되도록 합니다. 즉, container와 containerd의 모든 통신은 containerd-shim을 통해서 이루어 집니. container가 생성된 후 containerd-shim을 통해 container를 관리하니 containerd가 종료되어도 container는 정상적으로 동작할 수 있고 runC가 종료되어도 container를 정상적으로 관리할 수 있게 됩니다.Docker Shim Deprecation (v1.24 ~)Docker Shim Docker shim의 동작 방식 kubelet과 CRI: kubelet은 Kubernetes 노드에서 실행되는 주요 에이전트로, 컨테이너를 실행하고 관리하는 역할을 합니다. kubelet은 CRI를 통해 컨테이너 런타임과 상호작용합니다. dockershim: Docker는 CRI를 직접 지원하지 않기 때문에, dockershim이 중개 역할을 합니다. dockershim은 Docker API를 호출하여 컨테이너를 관리하고, 이를 통해 kubelet이 Docker 컨테이너를 제어할 수 있게 합니다. Docker를 사용할 때의 구체적인 동작 Pod 생성: kubelet은 새로운 Pod을 생성할 때 dockershim을 통해 Docker를 사용하여 컨테이너를 시작합니다. 이미지 풀링: Docker는 필요한 컨테이너 이미지를 Docker Hub 또는 다른 레지스트리에서 가져옵니다. 컨테이너 관리: Docker는 컨테이너의 라이프사이클을 관리하며, kubelet은 Docker의 상태를 모니터링하고 필요한 작업을 수행합니다. 현재 K8S 클러스터의 Container Runtime 확인 kubectl get nodes -o wideNAME STATUS ROLES AGE VERSION INTERNAL-IP EXTERNAL-IP OS-IMAGE KERNEL-VERSION CONTAINER-RUNTIMEwoobin-vm1 Ready control-plane,master 461d v1.23.6 192.168.0.9 &amp;lt;none&amp;gt; Rocky Linux 8.6 (Green Obsidian) 4.18.0-372.32.1.el8_6.x86_64 docker://20.10.11 kubectl edit no woobin-vm1apiVersion: v1kind: Nodemetadata: annotations: kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock ... Kubernetes는 v1.24부터 Docker shim 지원을 공식적으로 종료했습니다.containerd 2017년 12월 CNCF에서 버전 1.0에 도달 한 containerd는 kubelet과 containerd사이에서 작동하려면 cri-containerd라는 데몬이 필요했습니다. Cri-containerd 는 Kubelet의 CRI (Container Runtime Interface) 서비스 요청을 처리하고 containerd를 사용하여 해당 컨테이너 및 컨테이너 이미지를 관리합니다. containerd1.1에서는 cri-containerd 데몬이 이제 containerd CRI 플러그인으로 리팩터링됩니다. CRI 플러그인은 containerd1.1에 내장되어 있으며 기본적으로 활성화되어 있습니다. cri-containerd와 달리 CRI 플러그인은 직접 함수 호출을 통해 containerd와 상호 작용합니다. 사용자는 이제 containerd1.1과 함께 Kubernetes를 직접 사용할 수 있습니다. cri-containerd 데몬은 더 이상 필요하지 않습니다." }, { "title": "컨테이너 런타임, CRI, OCI", "url": "/posts/post230925/", "categories": "Docker", "tags": "Docker", "date": "2023-09-25 19:30:00 +0900", "snippet": "컨테이너 런타임 OCI (Open Container Initiative)가 만들어질 당시 비공식적 표준 역할을 하던 도커는 컨테이너 런타임의 표준화를 위해 필요한 모든 단계가 아닌 세 번째 단계인 컨테이너의 실행 부분만 표준화하였습니다. 이로 인해 컨테이너의 런타임은 실제 컨테이너를 실행하는 저수준 컨테이너 런타임인 OCI 런타임과 컨테이너 이미지의 전송 및 관리, 이미지 압축 풀기 등을 실행하는 고수준 컨테이너 런타임으로 나뉘게 되었습니다.저수준 컨테이너 런타임(Low-Level Container Runtimes) 컨테이너는 Linux namespace와 cgroup을 사용하여 구현합니다. namespace는 각 컨테이너에 대해 파일 시스템이나 네트워킹과 같은 시스템 리소스를 가상화하고 cgroup은 각 컨테이너가 사용할 수 있는 CPU 및 메모리와 같은 리소스 양을 제한하는 역할을 합니다. 저수준 컨테이너 런타임은 이러한 namespace와 cgroup을 설정한 다음 해당 namespace 및 cgroup 내에서 명령을 실행합니다. OCI를 준수하는 저수준 컨테이너 런타임으로 가장 잘 알려진 것은 runC입니다. runC는 원래 도커에서 컨테이너를 실행하기 위해 개발되었으나, OCI 런타임 표준을 위해 독립적인 라이브러리로 사용되었습니다. 저수준 컨테이너 런타임은 컨테이너를 실제 실행하는 역할을 하지만 이미지로부터 컨테이너를 실행하려면 이미지와 관련된 API 같은 기능이 필요합니다. 이러한 기능은 고수준 컨테이너 런타임에서 제공됩니다.고수준 컨테이너 런타임(High-Level Container Runtimes) 일반적으로 고수준 컨테이너 런타임은 원격 애플리케이션이 컨테이너를 논리적으로 실행하고 모니터링 하는데 사용할 수 있는 데몬 및 API를 제공합니다. 또한 컨테이너를 실행하기 위해 저수준 런타임 위에 배치됩니다. 이처럼 컨테이너를 실행하려면 저수준 및 고수준 컨테이너 런타임이 필요하기 때문에 OCI 런타임과 함께 도커가 그 역할을 했습니다. 도커는 docker-containerd라는 가장 잘 알려진 고수준 컨테이너 런타임을 제공합니다. containerd도 runC와 마찬가지로 도커에서 컨테이너를 실행하기 위해 개발되었으나 나중에 독립적인 라이브러리로 추출되었습니다. CRI &amp;amp; OCI 기본적으로 도커 기반의 쿠버네티스는 다음과 같은 구조로 작동했습니다. Kubelet이 명령을 받으면, Docker 런타임을 통해 컨테이너를 생성하거나 삭제하는 등의 생명 주기를 관리하는 구조를 가졌습니다. 그러나 이후 여러 다양한 컨테이너 기술이 등장하면서, 쿠버네티스는 이러한 다양한 컨테이너 런타임을 지원해야 하는 요구가 생겼습니다. 이에 따라 각 컨테이너 런타임을 지원하려면 Kubelet의 코드를 수정해야 하는 문제가 발생했습니다. 이에 대한 대안으로 Kubelet의 코드 수정 없이도 다양한 컨테이너 런타임을 지원하기 위한 표준화된 인터페이스가 등장했는데, 이것이 “CRI (Container Runtime Interface)“입니다. CRI는 컨테이너의 생성, 삭제 등의 생명 주기를 관리하는 표준 스펙으로, gRPC 기반의 API 스펙을 사용하며, 새로운 컨테이너 런타임은 CRI 스펙에 맞춰 CRI 컴포넌트를 구현하면 됩니다. 쿠버네티스 컨테이너 런타임 인터페이스(CRI)는 클러스터 컴포넌트 kubelet과 container runtime 사이의 통신을 위한 주요 gRPC 프로토콜을 정의합니다. 이에 따라 컨테이너 런타임은 CRI 스펙을 준수하여 구현하면, 새로운 컨테이너 런타임을 Kubelet의 코드를 수정하지 않고도 플러그인 형태로 추가할 수 있게 되었습니다. 예를 들어, Docker의 경우 “docker shim”이라는 CRI 인터페이스를 준수하는 구현체를 제공하며, rkt 컨테이너의 경우 “rktlet”이라는 이름의 CRI 구현체를 제공합니다. 그러나 지원되는 컨테이너 종류가 계속 증가하면서 매번 새로운 CRI를 구현해야 하는 문제가 발생했습니다. 이에 대응하여 컨테이너 런타임 자체를 표준화하기 위한 노력이 진행되었는데, 그 결과 “OCI (Open Container Initiative)” 스펙이 만들어졌습니다. OCI 스펙을 준수하여 구현된 컨테이너 런타임은 별도의 CRI 구현이 필요하지 않고, OCI를 지원하는 CRI 구현체를 통해 관리할 수 있게 되었습니다. OCI 스펙을 따르는 컨테이너 런타임을 관리하는 CRI 컴포넌트로는 “CRI-O(Container Runtime Interface - Open Container Initiative)”가 있습니다. 이는 OCI 스펙을 준수한다면, CRI-O를 통해 Kubelet으로부터 명령을 받을 수 있는 구조로 작동하게 됩니다.CRI-O(Container Runtime Interface - Open Container Initiative) CRI-O 는 레드햇에서 주도적으로 개발하고 있는 오픈소스 프로젝트로 쿠버네티스에서 CRI 구현을 목적으로 만들었기 때문에 “쿠버네티스 전용 런타임”라고 부르기도 합니다. CRI-O는 CRI와 OCI에서 유래된 프로젝트로 컨테이너 런타임 및 이미지가 OCI와 호환되는 것에 중점을 두고 있습니다. CRI 표준 컴포넌트를 최소한의 런타임으로 구현하며 쿠버네티스에서 모든 OCI 호환 런타임 및 컨테이너 이미지를 지원합니다. CRI-O는 컨테이너의 실행을 목적으로 경량화했기 때문에 도커가 제공하는 컨테이너 생성 및 이미지 빌드와 같은 기능은 제공하지 않습니다. 즉, CRI-O 덕분에 쿠버네티스는 컨테이너를 실행할 때 도커가 필요없었으나, 컨테이너의 생성 및 이미지 빌드와 같은 과정에서는 여전히 도커를 필요로 했습니다. 이러한 이유로 CRI-O 개발팀은 도커를 대체할 수 있는 새로운 생태계를 만들기 위해 노력하였습니다.도커의 문제점1) High &amp;amp; Low Level Runtime ContainerDocker Runtime Container는 High Level &amp;amp; Row Level Runtime Container를 포함하는 완전한 형태를 갖고 있습니다. 이는 장점이라고도 볼 수 있지만, High Level Container 역할을 하는 Docker daemon(Docker Server)와 Row Level Container 역할을 하는 Docker CLI(Client) 간의 통신으로 구성되어 있어 둘 중 하나의 기능만을 원한 경우 또는 Client의 특정 기능(컨테이너 기동, 도커 이미지 빌드, 이미지 pull &amp;amp; push 등)만을 사용하고자 할 경우에도 전체를 구성하여 활용해야 한다는 단점이 존재합니다.2) SPOFDocker daemon(Docker Server)은 Daemon 하위에 여러 Container를 기동하고 관리합니다. 특히 Kubernetes의 Master / Worker 노드에 구성된 Docker Daemon에 장애가 발생할 경우 Kubernetes 전체로 장애가 전파 될 수 있습니다. 이는 Single Point Of Failure를 대표하는 장애 포인트가 될 수 있습니다.3) AuditLinux Kernel에는 Audit이라는 기능이 존재합니다. 이를 통해 관리자는 시스템의 보안 이벤트를 감시하고 외부로부터의 침입을 감시하는 역할을 수행합니다. 이는 로그인 UID 추적 기능을 통해 감시할 수 있습니다./proc/self/loginuid에 저장되는 loginuid 필드는 시스템의 모든 프로세스에 대한 proc 구조체의 일부이다. 이 필드는 한 번만 설정할 수 있다. 설정된 후에는 커널이 프로세스를 재설정하는 것을 허용하지 않는다. 개인의 uid는 다음과 같이 확인할 수 있다.iduid=1000(woobin) gid=1000(woobin) groups=1000(woobin)cat /proc/self/loginuid1000sudo su -Last login: Tue Jun 20 12:39:20 KST 2023 on tty1cat /proc/self/loginuid1000su - woobinLast login: Thu Sep 21 20:14:41 KST 2023 on pts/0cat /proc/self/loginuid1000위와 같이 uid(1000)가 발급되고, 발급된 uid는 계정이 변경되어도 그대로 유지된다. (woobin &amp;gt; root &amp;gt; woobin) 이는 초기 로그인 프로세스에서 분기되고 실행되는 모든 프로세스는 자동으로 loginuid를 상속하여, 커널이 로그인 한 사람을 알게 하는 감시 방법이다.이제 확인하고자 하는 내용은 이 audit을 방해하는 docker에 대한 내용에 대해 알아보고자 한다.sudo docker run fedora cat /proc/self/loginuid4294967295sudo podman run fedora cat /proc/self/loginuid1000위는 docker와 podman으로 각각 기동 후 loginuid를 확인하는 과정이다.Docker는 클라이언트/서버 모델을 사용한다. 내가 실행한 docker 명령은 Docker 클라이언트 도구이며 클라이언트/서버 작업을 통해 Docker 데몬과 통신한다. 그런 다음 Docker 데몬은 컨테이너를 만들고 Docker 클라이언트 도구에 대한 stdin / stdout 통신을 다시 처리한다. Podman은 컨테이너에 대해 전통적인 fork / exec 모델을 사용하므로 컨테이너 프로세스는 Podman 프로세스의 Child이다.프로세스의 기본 loginuid (loginuid가 설정되기 전)는 4294967295이다. 컨테이너는 Docker daemon의 child이고 Docker daemon은 init 시스템의 child이므로 systemd, Docker daemon 및 컨테이너가 모두 동일한 loginuid로 처리하는 것을 볼 수 있다. 이는 감사 대상에서 제외됨을 알 수 있다.이는 Docker Container를 관리하는 주체가 누구인지? Docker를 다운하거나, 악의적으로 Container를 조작하는 등의 일이 발생해도 audit.log를 통해 확인할 수 있는 방법이 없다는 것을 의미한다. Podman의 경우 전통적인 fork / exec 모델을 사용하여 audit.log가 정상적으로 기록된다.CRI-O 구성 요소 Buildah, Podman, Skopeo Buildah, Podman, Skopeo는 세분화된 Low Level Container 컴포넌트로, 별도의 데몬 없이 전통적인 fork / exec 모델을 사용하며 사용자 네임 스페이스를 이용해 컨테이너를 실행함으로써 단일실패점, audit 보안 기능 사용 및 루트 권한 문제를 해결하였습니다. 도커의 서버가 너무 많은 기능을 가지고 있는 단점은 각 툴 별로 다음과 같이 기능을 나누어 제공하는 방식으로 보완하였습니다. Buildah CRI-O에서 이미지를 빌드할 때 도커의 종속성을 제거하기 위해 개발되었고 Dockerfile 없이 다른 스크립트 언어를 사용해 컨테이너 이미지를 빌드하는 것을 목표로 합니다. Podman pull 및 tag 지정과 같은 OCI 컨테이너 이미지를 유지관리하고 수정하는데 도움이 되는 모든 명령 및 기능을 제공합니다. 또한 컨테이너 작성, 실행 및 유지보수도 할 수 있습니다. 즉, Docker CLI에서 수행할 수 있는 명령은 Podman CLI에서도 동일하게 수행 할 수 있습니다. Buildah와 Podman은 일부 겹치는 기능이 있는데 Buildah는 OCI 이미지를 생성하는 효율적인 도구로, Podman은 그러한 이미지와 이미지를 통해 생성한 컨테이너를 유지하고 관리하는 도구로 이해하면 됩니다. 기술적으로 buildah run은 Dockerfile RUN을 에뮬레이트하며 podman run은 docker run을 에뮬레이트 합니다. Skopeo 이미지 저장소에서 다양한 작업을 수행하는 명령줄 도구입니다. 기존 도커가 다른 레지스트리에 이미지를 복사하기 위해 pull, tag, push를 사용했다면 Skopeo는 간단하게 copy 명령으로 해당 기능을 제공합니다. 추가로 저장소에 있는 이미지 이름에 대해 로우 레벨 정보를 제공해줍니다. Reference https://www.samsungsds.com/kr/insights/docker.html https://waspro.tistory.com/679" }, { "title": "(Python)[백준] 유턴싫어_2823", "url": "/posts/post230921/", "categories": "CodingTest", "tags": "CodingTest", "date": "2023-09-21 19:30:00 +0900", "snippet": "2823번: 유턴 싫어풀이# 막다른 곳은 인접한 길이 1개 또는 0개. 막다른 길이 아니기 위해서는 인접한 길이 적어도 2개 이상이어야 함import sysinput = sys.stdin.readlinedx, dy = [-1, 1, 0, 0], [0, 0, -1, 1]n, m = map(int, input().split())graph = [list(input().strip()) for _ in range(n)]def has_uturn(x, y): cnt = 0 for d in range(4): nx, ny = x + dx[d], y + dy[d] if 0 &amp;lt;= nx &amp;lt; n and 0 &amp;lt;= ny &amp;lt; m and graph[nx][ny] == &#39;.&#39;: cnt += 1 return cnt &amp;lt;= 1found_uturn = any(graph[x][y] == &#39;.&#39; and has_uturn(x, y) for x in range(n) for y in range(m))if found_uturn: print(1)else: print(0)" }, { "title": "(Python)[백준] 토마토_7576", "url": "/posts/post230918/", "categories": "CodingTest", "tags": "CodingTest", "date": "2023-09-18 19:30:00 +0900", "snippet": "7576번: 토마토풀이# bfs -&amp;gt; queue# deque - 내부적으로 deque은 double-linked list로 구현되어 있음. 그래서 양 끝의 요소의 추가/삭제가 O(1)을 만족하게 됨# &amp;lt;-&amp;gt; 리스트 - 리스트의 마지막 원소를 삭제는 O(1)이지만, 첫번째 원소를 삭제하면 삭제 후 모든 원소를 앞으로 이동시키기 때문에 시간 복잡도가 O(n)from collections import deque# 방향 벡터 정의dx, dy = [-1, 1, 0, 0], [0, 0, -1, 1]# 입력 받기m, n = map(int, input().split())graph = [list(map(int, input().split())) for _ in range(n)]# 시작점 찾기와 BFS 함수 정의def find_starting_points(): queue = deque() for i in range(n): for j in range(m): if graph[i][j] == 1: queue.append([i, j]) return queuedef bfs(queue): while queue: x, y = queue.popleft() for i in range(len(dx)): nx, ny = x + dx[i], y + dy[i] if 0 &amp;lt;= nx &amp;lt; n and 0 &amp;lt;= ny &amp;lt; m and graph[nx][ny] == 0: graph[nx][ny] = graph[x][y] + 1 queue.append([nx, ny])# 시작점 찾기queue = find_starting_points()# BFS 수행bfs(queue)anw = 0for row in graph: for j in row: if j == 0: print(-1) exit(0) anw = max(anw, max(row))print(anw - 1) # 처음 시작을 1로 했으니 -1" }, { "title": "(Python)[백준] 누울 자리를 찾아라_1652", "url": "/posts/post230910/", "categories": "CodingTest", "tags": "CodingTest", "date": "2023-09-10 19:30:00 +0900", "snippet": "1652번: 누울 자리를 찾아라풀이# 연속으로 . 있는 걸 찾기import sysinput = sys.stdin.readlineN = int(input())graph = [input().strip() for _ in range(N)]row_cnt, col_cnt = 0, 0for i in range(N): tmp_row_cnt, tmp_col_cnt = 0, 0 for j in range(N): if graph[i][j] == &#39;.&#39;: tmp_row_cnt += 1 else : if tmp_row_cnt &amp;gt; 1: row_cnt += 1 tmp_row_cnt = 0 if graph[j][i] == &#39;.&#39;: tmp_col_cnt += 1 else : if tmp_col_cnt &amp;gt; 1: col_cnt += 1 tmp_col_cnt = 0 if tmp_row_cnt &amp;gt; 1: row_cnt += 1 if tmp_col_cnt &amp;gt; 1: col_cnt += 1 print(row_cnt, col_cnt)" }, { "title": "(Python)[백준] 탑_2493", "url": "/posts/post230907/", "categories": "CodingTest", "tags": "CodingTest", "date": "2023-09-07 19:30:00 +0900", "snippet": "2493번: 탑풀이# 스택을 오른쪽으로 눕혀서 생각 (왼쪽이 닫힘)# 가장 먼저 만나는 높이가 같거나 큰 탑에서 수신 가능# 가장 먼저 만나는 탑이 높이가 작다면 스택에서 비움 -&amp;gt; 신경쓰지 않아도 되기 때문 # 왜냐하면, 그 뒤에 들어오는 현재 탑의 전파보다 작은 모든 전파는 현재 탑에서 수신됨N = int(input())tops = list(map(int, input().split()))stack = []answer = []for i in range(N): # 6 9 5 7 4 while stack: if stack[-1][1] &amp;gt; tops[i]: # 수신 가능한 상황 answer.append(stack[-1][0] + 1) break else: stack.pop() if not stack: # 스택이 비면 수신할 탑이 없음 answer.append(0) stack.append((i, tops[i]))print(*answer)" }, { "title": "(Python)[백준] 비슷한 단어_1411", "url": "/posts/post230905/", "categories": "CodingTest", "tags": "CodingTest", "date": "2023-09-05 19:30:00 +0900", "snippet": "1411번: 비슷한 단어풀이# 단어들 중 두 개씩 선택하여 각각의 음절을 모두 비교하고자 함 -&amp;gt; 삼중 for-loop# 두 개의 다른 알파벳을 하나의 알파벳으로 바꿀 수 없다는 조건을 체크하기 위해,# 두 개의 각 단어와 매핑 되는 두 개의 리스트가 필요할듯(방문 처리). 리스트 크기는 알파벳 개수import sysinput=sys.stdin.readlineN = int(input())words = [input().strip() for _ in range(N)] # N: 0 ~ N-1, strip() : \\n 제거cnt = 0for i in range(N-1): # i: 0 ~ N-2 for j in range(i+1, N): # j : i+1 ~ N-1 word_1 = words[i] word_2 = words[j] flag = True visited_1 = [0] * (ord(&#39;z&#39;) - ord(&#39;a&#39;) + 1) visited_2 = [0] * (ord(&#39;z&#39;) - ord(&#39;a&#39;) + 1) for k in range(len(word_1)): idx_1 = ord(word_1[k]) - ord(&#39;a&#39;) # idx: 0~25 idx_2 = ord(word_2[k]) - ord(&#39;a&#39;) # idx: 0~25 if not visited_1[idx_1] and not visited_2[idx_2]: # visited[idx] = 1 로 하면 문자 비교가 안됨 visited_1[idx_1] = word_2[k] visited_2[idx_2] = word_1[k] elif word_1[k] != visited_2[idx_2]: flag = False break if flag: cnt += 1print(cnt)" }, { "title": "(Python)[백준] 친구비_16562", "url": "/posts/post230830/", "categories": "CodingTest", "tags": "CodingTest", "date": "2023-08-30 19:00:00 +0900", "snippet": "16562번: 친구비풀이import syssys.setrecursionlimit(10**9)# 학생 수 N (1 ≤ N ≤ 10,000), 친구관계 수 M (0 ≤ M ≤ 10,000), 가지고 있는 돈 k (1 ≤ k ≤ 10,000,000)n,m,k = map(int, sys.stdin.readline().split())money = list(map(int, sys.stdin.readline().split()))graph = [[] for _ in range(n)]ans = []for i in range(m): a,b = map(int, sys.stdin.readline().split()) graph[a - 1].append(b - 1) graph[b - 1].append(a - 1)visited = [False] * ndef dfs(x, g): visited[x] = True for i in graph[x]: if visited[i] == False: g.append(i) dfs(i, g) return gfor i in range(n): if visited[i] == False : # 정점 i가 False라면 다른 그룹에 있음 -&amp;gt; dfs group = dfs(i, [i]) min_money = 10000000 for j in group: if min_money &amp;gt; money[j]: min_money = money[j] ans.append(min_money)if sum(ans) &amp;lt;= k: print(sum(ans))else: print(&#39;Oh no&#39;)" }, { "title": "(Python)[백준] 임진왜란_3077", "url": "/posts/post230828/", "categories": "CodingTest", "tags": "CodingTest", "date": "2023-08-28 19:00:00 +0900", "snippet": "3077번: 임진왜란풀이import sysinput = sys.stdin.readlinen = int(input())correct_answer = dict(zip(input().split(), [i for i in range(n)]))to_check_answer = input().split()cnt = 0for i in range(n - 1): for j in range(i + 1, n): if correct_answer[to_check_answer[i]] &amp;lt; correct_answer[to_check_answer[j]]: cnt += 1print(cnt, &quot;/&quot;, n * (n - 1) // 2, sep=&quot;&quot;)" }, { "title": "(Java) 객체 지향 4가지 특징, 5가지 원칙", "url": "/posts/post230729/", "categories": "Java", "tags": "Java", "date": "2023-07-29 19:00:00 +0900", "snippet": "1. 객체지향 프로그래밍 (Object Oriented Programming, OOP)이란? 필요한 데이터를 추상화 시켜 상태와 행위를 가진 객체를 만들고 객체들 간의 유기적인 상호작용을 통해 로직을 구성하는 프로그래밍 방법 절차지향과 객체지향의 차이 객체지향 프로그래밍 장단점 장점 코드 재사용(Reusability): 클래스와 상속을 통해 코드를 재사용하기 용이하다. 이미 작성된 클래스를 기반으로 새로운 클래스를 작성하거나 기존 클래스를 확장하여 새로운 기능을 추가할 수 있다. 이로 인해 개발 시간을 단축하고 유지보수를 간편하게 만든다. 모듈화(Modularity): 객체지향 프로그래밍은 코드를 논리적으로 모듈화하여 개발할 수 있다. 각 객체는 독립적으로 작동하며, 다른 객체와 상호작용하도록 설계되어 코드의 가독성과 이해도를 높여준다. 유지보수성(Maintainability): 객체지향 프로그래밍은 코드를 클래스 단위로 나누고, 각 클래스는 독립적으로 작동하도록 설계되기 때문에 유지보수가 용이하다. 변경이 필요한 경우 해당 클래스만 수정하면 되므로 전체 코드에 영향을 미치는 범위가 줄어든다. 코드의 이해와 디버깅 용이성: 객체지향 프로그래밍은 현실 세계의 개념과 유사하게 코드를 구성하기 때문에 코드의 이해가 쉽고, 버그를 찾아내고 해결하는 데 용이하다. 데이터 은닉과 보안성: 객체지향 프로그래밍은 데이터 은닉(Encapsulation)을 통해 객체의 내부 구현을 외부로부터 숨기는 것을 지원한다. 이로 인해 객체의 상태를 직접 조작하는 것을 방지하여 데이터의 무결성과 보안성을 높인다. 확장성(Extensibility): 새로운 기능을 추가하거나 기존 기능을 수정할 때 해당 클래스만 수정하면 되므로 코드의 확장성이 높다. 상속과 다형성: 상속을 통해 기존 클래스를 재사용하고 기능을 확장할 수 있으며, 다형성을 통해 하나의 인터페이스로 여러 타입을 다룰 수 있다. 이는 코드의 유연성을 높이고 더 유용한 추상화를 가능하게 한다. 팀 작업 용이성: 객체지향 프로그래밍은 클래스 단위로 작업할 수 있으므로 다수의 개발자가 동시에 작업하기에 용이하다. 각자 담당한 클래스를 개발하고 통합할 수 있으며, 코드 간의 인터페이스를 명확하게 정의하여 팀 간의 협업을 쉽게 할 수 있다. 단점 복잡성과 추상화의 어려움: 객체지향 프로그래밍은 복잡한 시스템을 설계할 때 추상화와 객체간의 상호작용을 고려해야 함. 이로 인해 초기 단계에서 설계가 어려울 수 있으며, 비교적 간단한 문제를 해결하는 데에는 너무 많은 객체를 생성하거나 복잡하게 만들 수 있음 성능 저하: 객체지향 프로그래밍에서는 객체의 생성과 소멸, 메소드 호출 등에 대한 오버헤드가 발생할 수 있음. 절차지향 프로그래밍에 비해 실행 속도가 느릴 수 있음. 또한, 객체 간의 상호작용으로 인해 추가적인 메모리 사용이 필요할 수도 있음 설계의 어려움: 적절한 객체들을 식별하고 객체들 간의 관계를 정의하는 것은 쉽지 않을 수 있음. 잘못된 객체 구조를 만들면 유지보수가 어렵고 코드가 더 복잡해질 수 있음 2. OOP의 4가지 특징1) 캡슐화 데이터와 코드의 형태를 외부로부터 알 수 없게 하고, 데이터의 구조와 역할, 기능을 하나의 캡슐 형태로 만드는 방법 멤버 변수 앞에 접근 제어자 private를 붙인다. (private : 자기 클래스에서만 접근할 수 있는 것) 멤버 변수에 값을 넣고 꺼내 올 수 있는 메서드를 만든다. (접두어 set/get을 사용해 메서드를 만든다.) 2) 추상화 클래스들의 공통적인 특성(변수, 메소드)들을 묶어 표현하는 것 3) 상속화 부모 클래스에 정의된 변수 및 메서드를 자식 클래스에서 상속받아 사용하는 것 4) 다형화 메시지에 의해 객체가 연산을 수행하게 될 때, 하나의 메시지에 대해 각 객체가 가지고 있는 고유한 방법으로 응답할 수 있는 능력(다양한 형태로 표현이 가능한 구조) 다형화 지원 방법 오버로딩 (Overloading) 하나의 클래스 안에서 같은 이름의 메서드를 여러 개 정의하는 것 오버라이딩 (Overriding) 부모 클래스로부터 상속받은 메서드 내용을 변경하여 사용하는 것 매개변수와 리턴 타입이 같아야 함 3. OOP의 5가지 원칙 SOLID란 객체 지향 프로그래밍을 하면서 지켜야 하는 5대 원칙으로 각각 SRP(단일 책임 원칙), OCP(개방-폐쇄 원칙), LSP(리스코프 치환 원칙), DIP(의존 역전 원칙), ISP(인터페이스 분리 원칙)의 앞글자를 따서 만들어졌다. SOLID 원칙을 철저히 지키면 시간이 지나도 변경이 용이하고, 유지보수와 확장이 쉬운 소프트웨어를 개발하는데 도움이 되는 것으로 알려져 있다.1) 단일 책임 원칙 (SRP : Single Responsibility Principle)로버트 마틴은 SOLID 원칙 중에서 가장 의미가 전달되지 못한 것으로 단일 책임의 원칙(SRP, Single Responsibility Principle)을 뽑았는데, SRP는 하나의 모듈이 하나의 책임을 가져야 한다는 모호한 원칙으로 해석하면 안된다. 대신 모듈이 변경되는 이유가 한 가지여야 함으로 받아들여야 한다.여기서 변경의 이유가 한 가지라는 것은 해당 모듈이 여러 대상 또는 액터들에 대해 책임을 가져서는 안되고, 오직 하나의 액터에 대해서만 책임을 져야 한다는 것을 의미한다.만약 어떤 모듈이 여러 액터에 대해 책임을 가지고 있다면 여러 액터들로부터 변경에 대한 요구가 올 수 있으므로, 해당 모듈을 수정해야 하는 이유 역시 여러 개가 될 수 있다. 반면에 어떤 클래스가 단 하나의 책임 만을 갖고 있다면, 특정 액터로부터 변경을 특정할 수 있으므로 해당 클래스를 변경해야 하는 이유와 시점이 명확해진다.예를 들어 다음과 같이 입력으로 사용자의 정보를 받아서, 비밀번호를 암호화하여 데이터베이스에 저장하는 로직이 있다고 하자.@Service@RequiredArgsConstructorpublic class UserService { private final UserRepository userRepository; public void addUser(final String email, final String pw) { final StringBuilder sb = new StringBuilder(); for(byte b : pw.getBytes(StandardCharsets.UTF_8)) { sb.append(Integer.toString((b &amp;amp; 0xff) + 0x100, 16).substring(1)); } final String encryptedPassword = sb.toString(); final User user = User.builder() .email(email) .pw(encryptedPassword).build(); userRepository.save(user); }}위의 UserService의 사용자 추가 로직에는 다음과 같은 다양한 액터로부터 변경이 발생할 수 있다. 기획팀: 사용자를 추가할 때 역할(Role)에 대한 정의가 필요하다. 보안팀: 사용자의 비밀번호 암호화 방식에 개신이 필요하다. 기타 등등이러한 문제가 발생하는 이유는 UserService가 여러 액터로부터 단 하나의 책임을 갖고 있지 못하기 때문이며, 이를 위해서는 비밀번호 암호화에 대한 책임을 분리해야 한다.다음과 같이 비밀번호 암호화를 책임지는 별도의 클래스를 만들어 UserService로부터 이를 추상화하고, 해당 클래스를 합성하여 접근 및 사용하면 우리는 UserService로부터 비밀번호 암호화 방식을 개선해 달라는 변경을 분리할 수 있다.@Componentpublic class SimplePasswordEncoder { public void encryptPassword(final String pw) { final StringBuilder sb = new StringBuilder(); for(byte b : pw.getBytes(StandardCharsets.UTF_8)) { sb.append(Integer.toString((b &amp;amp; 0xff) + 0x100, 16).substring(1)); } return sb.toString(); }}@Service@RequiredArgsConstructorpublic class UserService { private final UserRepository userRepository; private final SimplePasswordEncoder passwordEncoder; public void addUser(final String email, final String pw) { final String encryptedPassword = passwordEncoder.encryptPassword(pw); final User user = User.builder() .email(email) .pw(encryptedPassword).build(); userRepository.save(user); }}// @RequiredArgsConstructor: `final`이 붙거나 `@NotNull` 이 붙은 필드의 생성자를 자동 생성해주는 lombok 어노테이션// @Component: 직접 작성한 클래스를 IoC 컨테이너에 등록 할 수 있다. 이때, IoC 컨테이너에 등록되어 IoC가 관리하는 객체를 Bean이라고 한다.// @Service: Service Component란 Client의 요청에 대한 비즈니스 로직을 수행하는 Component이다. Client의 요청 url에 따른 Controller가 호출되면, Controller는 해당 비즈니스 로직을 수행하기 위한 Service를 호출한다. Service는 로직 수행 후 결과를 Controller에게 반환한다. 이때 Service가 Service Component이다. ****Service Component는 @Service 어노테이션을 달고 있다.단일 책임 원칙을 제대로 지키면 변경이 필요할 때 수정할 대상이 명확해진다. 그리고 이러한 단일 책임 원칙의 장점은 시스템이 커질수록 극대화되는데, 시스템이 커지면서 서로 많은 의존성을 갖게되는 상황에서 변경 요청이 오면 딱 1가지만 수정하면 되기 때문이다.단일 책임 원칙을 적용하여 적절하게 책임과 관심이 다른 코드를 분리하고, 서로 영향을 주지 않도록 추상화함으로써 애플리케이션의 변화에 손쉽게 대응할 수 있다.2) 개방 폐쇄 원칙 (Open-Closed Principle, OCP)개방 폐쇄 원칙(Open-Closed Principle, OCP)은 확장에 대해 열려있고 수정에 대해서는 닫혀있어야 한다는 원칙으로, 각각이 갖는 의미는 다음과 같다. 확장에 대해 열려 있다: 요구사항이 변경될 때 새로운 동작을 추가하여 애플리케이션의 기능을 확장할 수 있다. 수정에 대해 닫혀 있다: 기존의 코드를 수정하지 않고 애플리케이션의 동작을 추가하거나 변경할 수 있다.이번에는 비밀번호 암호화를 강화해야 한다는 요구사항이 새롭게 들어왔다고 가정하자. 비밀번호 암호화를 강화하기 위해 다음과 같이 SHA-256 알고리즘을 사용하는 새로운 PasswordEncoder를 생성하였다.@Componentpublic class SHA256PasswordEncoder { private final static String SHA_256 = &quot;SHA-256&quot;; public String encryptPassword(final String pw) { // MessageDigest는 데이터를 다이제스트(해시)하는 데 사용되는 클래스 final MessageDigest digest; try { digest = MessageDigest.getInstance(SHA_256); } catch (NoSuchAlgorithmException e) { throw new IllegalArgumentException(); } final byte[] encodedHash = digest.digest(pw.getBytes(StandardCharsets.UTF_8)); return bytesToHex(encodedHash); } private String bytesToHex(final byte[] encodedHash) { final StringBuilder hexString = new StringBuilder(2 * encodedHash.length); for (final byte hash : encodedHash) { final String hex = Integer.toHexString(0xff &amp;amp; hash); if (hex.length() == 1) { hexString.append(&#39;0&#39;); } hexString.append(hex); } return hexString.toString(); }}그리고 새로운 비밀번호 암호화 정책을 적용하려고 봤더니 새로운 암호화 정책과 무관한 UserService를 다음과 같이 수정해주어야 하는 문제가 발생하였다.@Service@RequiredArgsConstructorpublic class UserService { private final UserRepository userRepository; private final SHA256PasswordEncoder passwordEncoder; ...}이는 기존의 코드를 수정하지 않아야 하는 개방 폐쇄 원칙에 위배된다. 그리고 나중에 또 다시 비밀번호 암호화 정책을 변경해야 한다는 요구사항이 온다면 또 다시 UserService에 변경에 필요해진다.이러한 문제를 해결하고 개방 폐쇄 원칙을 지키기 위해서는 추상화에 의존해야 한다. 추상화란 핵심적인 부분만 남기고, 불필요한 부분은 제거함으로써 복잡한 것을 간단히 하는 것이고, 추상화를 통해 변하지 않는 부분만 남김으로써 기능을 구체화하고 확장할 수 있다. 변하지 않는 부분은 고정하고 변하는 부분을 생략하여 추상화함으로써 변경이 필요한 경우에 생략된 부분을 수정하여 개방-폐쇄의 원칙을 지킬 수 있다.위의 예제에서 변하지 않는 것은 사용자를 추가할 때 암호화가 필요하다는 것이고, 변하는 것은 사용되는 구체적인 암호화 정책이다. 그러므로 UserService는 어떠한 구체적인 암호화 정책이 사용되는지는 알 필요 없이 단지 passwordEncoder 객체를 통해 암호화가 된 비밀번호를 받기만 하면 된다. 그러므로 UserService가 구체적인 암호화 클래스에 의존하지 않고 PasswordEncoder라는 인터페이스에 의존하도록 추상화하면 우리는 개방 폐쇄의 원칙이 충족되는 코드를 작성할 수 있다.public interface PasswordEncoder { String encryptPassword(final String pw);}@Componentpublic class SHA256PasswordEncoder implements PasswordEncoder { @Override public String encryptPassword(final String pw) { ... }}@Service@RequiredArgsConstructorpublic class UserService { private final UserRepository userRepository; private final PasswordEncoder passwordEncoder; public void addUser(final String email, final String pw) { final String encryptedPassword = passwordEncoder.encryptPassword(pw); final User user = User.builder() .email(email) .pw(encryptedPassword).build(); userRepository.save(user); }}OCP가 본질적으로 얘기하는 것은 추상화이며, 이는 결국 런타임 의존성과 컴파일타임 의존성에 대한 이야기이다. 여기서 런타임 의존성이란 애플리케이션 실행 시점에서의 객체들의 관계를 의미하고, 컴파일타임 의존성이란 코드에 표현된 클래스들의 관계를 의미한다.위와 같이 불필요한 변경이 이루어지는 의존성 전이를 최소화하기 위해서는 컴파일 타임 의존성이 아닌 런타임 의존성을 가져야 한다. 의존성을 갖기 위해서는 의존성 주입을 해주어야 하는데, 다양한 의존성 주입 방법들 중에서 생성자 주입 방법이 가장 권장된다.다형성을 지원하는 객체지향 프로그래밍에서 런타임 의존성과 컴파일타임 의존성은 동일하지 않다. 위의 예제에서 UserService는 컴파일 시점에 추상화된 PasswordEncoder에 의존하고 있지만 런타임 시점에는 구체 클래스(SHA256PasswordEncoder)에 의존한다.객체가 알아야 하는 지식이 많으면 결합도가 높아지고, 결합도가 높아질수록 개방-폐쇄의 원칙을 따르는 구조를 설계하기가 어려워진다. 추상화를 통해 변하는 것들은 숨기고 변하지 않는 것들에 의존하게 하면 우리는 기존의 코드 및 클래스들을 수정하지 않은 채로 애플리케이션을 확장할 수 있다. 그리고 이것이 개방 폐쇄의 원칙이 의미하는 것이다.3) 인터페이스 분리 원칙 (Interface segregation principle, ISP)객체가 충분히 높은 응집도의 작은 단위로 설계됐더라도, 목적과 관심이 각기 다른 클라이언트가 있다면 인터페이스를 통해 적절하게 분리해줄 필요가 있는데, 이를 인터페이스 분리 원칙이라고 부른다.즉, 인터페이스 분리 원칙이란 클라이언트의 목적과 용도에 적합한 인터페이스 만을 제공하는 것이다. 인터페이스 분리 원칙을 준수함으로써 모든 클라이언트가 자신의 관심에 맞는 퍼블릭 인터페이스(외부에서 접근 가능한 메세지)만을 접근하여 불필요한 간섭을 최소화할 수 있으며, 기존 클라이언트에 영향을 주지 않은 채로 유연하게 객체의 기능을 확장하거나 수정할 수 있다.인터페이스 분리 원칙을 지킨다는 것은 어떤 구현체에 부가 기능이 필요하다면 이 인터페이스를 구현하는 다른 인터페이스를 만들어서 해결할 수 있다. 예를 들어 파일 읽기/쓰기 기능을 갖는 구현 클래스가 있는데 어떤 클라이언트는 읽기 작업 만을 필요로 한다면 별도의 읽기 인터페이스를 만들어 제공해주는 것이다. 예를 들어 사용자가 비밀번호를 변경할 때 입력한 비밀번호가 기존의 비밀번호와 동일한지 검사해야 하는 로직을 다른 Authentication 로직에 추가해야 한다고 가정하자. 그러면 우리는 다음과 같은 isCorrectPassword라는 퍼블릭 인터페이스를 SHA256PasswordEncoder에 추가해줄 것이다.@Componentpublic class SHA256PasswordEncoder implements PasswordEncoder { @Override public String encryptPassword(final String pw) { ... } public String isCorrectPassword(final String rawPw, final String pw) { final String encryptedPw = encryptPassword(rawPw); return encryptedPw.equals(pw); }}하지만 UserService에서는 비밀번호 암호화를 위한 encryptPassword() 만을 필요로 하고, 불필요하게 isCorrectPassword를 알 필요가 없다. 현재 UserService는 PasswordEncoder를 주입받아 encrpytPassword에만 접근 가능하므로 인터페이스 분리가 잘 된 것 처럼 보인다.하지만 새롭게 추가될 Authentication 로직에서는 isCorrectPassword에 접근하기 위해 구체 클래스인 SHA256PasswordEncoder를 주입받아야 하는데 그러면 불필요한 encryptPassword에도 접근 가능해지고, 인터페이스 분리 원칙을 위배하게 된다.물론 PasswordEncoder에 isCorrectPassword 퍼블릭 인터페이스를 추가해줄 수 있지만, 클라이언트의 목적과 용도에 적합한 인터페이스 만을 제공한다는 인터페이스 분리 원칙을 지키기 위해서라도 이미 만든 인터페이스는 건드리지 않는 것이 좋다. 그러므로 위의 상황을 해결하기 위해서는 비밀번호를 검사를 의미하는 별도의 인터페이스(PasswordChecker)를 만들고, 해당 인터페이스로 주입받도록 하는 것이 적합하다.public interface PasswordChecker { String isCorrectPassword(final String rawPw, final String pw);}@Componentpublic class SHA256PasswordEncoder implements PasswordEncoder, PasswordChecker { @Override public String encryptPassword(final String pw) { ... } @Override public String isCorrectPassword(final String rawPw, final String pw) { final String encryptedPw = encryptPassword(rawPw); return encryptedPw.equals(pw); }}클라이언트에 따라 인터페이스를 분리하면 변경에 대한 영향을 더욱 세밀하게 제어할 수 있다. 그리고 이렇게 인터페이스를 클라이언트의 기대에 따라 분리하여 변경에 의해 의한 영향을 제어하는 것을 인터페이스 분리 원칙이라고 부른다.4) 리스코프 치환 원칙 (Liskov Substitution Principle, LSP)리스코프 치환 원칙은 올바른 상속 관계의 특징을 정의하기 위한 것으로, 하위 타입은 상위 타입을 대체할 수 있어야 한다는 것이다.즉, 해당 객체를 사용하는 클라이언트는 상위 타입이 하위 타입으로 변경되어도, 차이점을 인식하지 못한 채 상위 타입의 퍼블릭 인터페이스를 통해 서브 클래스를 사용할 수 있어야 한다는 것이다.리스코프 치환 원칙에 대해 이해하기 위해 기존의 예시들과 다른 정사각형은 직사각형이다(Square is a Rectangle)는 예시를 살펴보도록 하자. 직사각형과 정사각형을 각각 구현하면 다음과 같다.@Getter@Setter@AllArgsConstructorpublic class Rectangle { private int width, height; public int getArea() { return width * height; }}public class Square extends Rectangle { public Square(int size) { super(size, size); } @Override public void setWidth(int width) { super.setWidth(width); super.setHeight(width); } @Override public void setHeight(int height) { super.setWidth(height); super.setHeight(height); }}Square는 1개의 변수만을 생성자로 받으며, width나 height 1개 만을 설정하는 경우 모두 설정되도록 메소드가 오버라이딩 되어 있다. 이를 이용하는 클라이언트는 당연히 직사각형의 너비와 높이가 다르다고 가정할 것이고, 직사각형을 resize()하기를 원하는 경우 다음과 같은 메소드를 만들어 너비와 높이를 수정할 것이다. (항상 클라이언트의 입장에서 생각해야 함에 유의해야 한다.)public void resize(Rectangle rectangle, int width, int height) { rectangle.setWidth(width); rectangle.setHeight(height); if (rectangle.getWidth() != width &amp;amp;&amp;amp; rectangle.getHeight() != height) { throw new IllegalStateException(); }}문제는 resize()의 파라미터로 정사각형인 Square이 전달되는 경우다. Rectangle은 Square의 부모 클래스이므로 Square 역시 전달이 가능한데, Square는 가로와 세로가 모두 동일하게 설정되므로 예를 들어 다음과 같은 메소드를 호출하면 문제가 발생할 것이다.Rectangle rectangle = new Square();resize(rectangle, 100, 150);이러한 케이스는 명백히 클라이언트의 관점에서 부모 클래스와 자식 클래스의 행동이 호환되지 않으므로 리스코프 치환 원칙을 위반하는 경우이다. 리스코프 치환 원칙이 성립한다는 것은 자식 클래스가 부모 클래스 대신 사용될 수 있어야 하기 때문이다.리스코프 치환 원칙은 자식 클래스가 부모 클래스를 대체하기 위해서는 부모 클래스에 대한 클라이언트의 가정을 준수해야 한다는 것을 강조한다. 위의 예시에서 클라이언트는 직사각형의 너비와 높이는 다를 것이라고 가정하는데, 정사각형은 이를 준수하지 못한다. 우리는 여기서 대체 가능성을 결정해야 하는 것은 해당 객체를 이용하는 클라이언트임을 반드시 잊지 말아야 한다.이러한 문제를 해결하기 위해 빈 메소드를 호출하도록 하거나 호출 시에 에러를 던지는 등의 조치를 취할 수 있다. 하지만 이러한 방법은 클라이언트가 예상하지 못할 수 있으므로 추상화 레벨을 맞춰서 메소드 호출이 불가능하도록 하거나(Square은 resize를 호출하지 못하게 하거나) 해당 추상화 레벨에 맞게 메소드를 오버라이딩 하는게 합리적일 것이다.5) 의존 역전 원칙 (Dependency Inversion Principle, DIP)의존 역전 원칙이란 고수준 모듈은 저수준 모듈의 구현에 의존해서는 안 되며, 저수준 모듈이 고수준 모듈에 의존해야 한다는 것이다. 객체 지향 프로그래밍에서는 객체들 사이에 메세지를 주고 받기 위해 의존성이 생기는데, 의존성 역전의 원칙은 올바른 의존 관계를 위한 원칙에 해당된다.여기서 각각 고수준 모듈과 저수준 모듈이란 다음을 의미한다. 고수준 모듈: 입력과 출력으로부터 먼(비즈니스와 관련된) 추상화된 모듈 저수준 모듈: 입력과 출력으로부터 가까운(HTTP, 데이터베이스, 캐시 등과 관련된) 구현 모듈의존 역전 원칙이란 결국 비즈니스와 관련된 부분이 세부 사항에는 의존하지 않는 설계 원칙을 의미한다. 우리는 위의 예시들을 살펴보면서 의존 역전 원칙에 준수하도록 코드를 수정한 경험이 있다.위에서 살펴봤던 SimplePasswordEncoder는 변하기 쉬운 암호화 알고리즘과 관련된구체 클래스인데, UserService가 SimplePasswordEncoder에 직접 의존하는 것은 DIP에 위배되는 것이다. 그러므로 UserService가 변하지 않는 추상화에 의존하도록 변경이 필요하고, 우리는 PasswordEncoder 인터페이스를 만들어 이에 의존하도록 변경하였다.UserService가 추상화된 PasswordEncoder에 의존하므로 비밀번호 암호화 정책이 변경되어도 다른 곳들로 변경이 전파되지 않으며 유연한 애플리케이션이 된다.의존 역전 원칙은 개방 폐쇄 원칙과 밀접한 관련이 있으며, 의존 역전 원칙이 위배되면 개방 폐쇄 원칙 역시 위배될 가능성이 높다.또한 의존 역전 원칙에서 주의해야 하는 것이 있는데, 의존 역전 원칙에서 의존성이 역전되는 시점은 컴파일 시점이라는 것이다. 런타임 시점에는 UserService가 SHA256PasswordEncoder라는 구체 클래스에 의존한다.하지만 의존 역전 원칙은 컴파일 시점 또는 소스 코드 단계에서의 의존성이 역전되는 것을 의미하며, 코드에서는 UserService가 PasswordEncoder라는 인터페이스에 의존한다.정리5가지의 객체 지향 설계 원칙인 SOLID가 얘기하는 핵심은 결국 추상화와 다형성이다.구체 클래스에 의존하지 않고 추상 클래스(또는 인터페이스)에 의존함으로써 우리는 유연하고 확장가능한 애플리케이션을 만들 수 있는 것이다.Reference https://mangkyu.tistory.com/194" }, { "title": "(Network)(Paper Review) MAC Protocol", "url": "/posts/post230701/", "categories": "Network", "tags": "Network", "date": "2023-07-01 19:00:00 +0900", "snippet": "MAC Protocol [ 응용 / 표현 / 세션 / 전송 / 네트워크 / 데이터링크 / 물리 ] OSI 7계층 데이터링크 계층의 MAC프로토콜에 대하여 정리통신 Protocol 이란? 통신 프로토콜(Communication Protocol)은 서로 다른 기기들 간의 데이터 교환을 원활하게 수행할 수 있도록 표준화시켜 놓은 통신 규약통신 프로토콜의 기본 요소 구문(Syntax) : 전송하고자 하는 데이터의 형식, 부호화, 신호 레벨등을 규정 의미(Semantics) : 두 기기 간의 효율적이고 정확한 정보 전송을 위한 협조 사항과 오류 관리를 위한 제어 정보를 규정 시간(Timing) : 두 기기 간의 통신 속도, 메시지의 순서 제어 등을 규정통신 프로토콜의 기능단편화와 재결합송신 측에서 전송할 데이터를 전송에 알맞은 일정 크기의 작은 블록으로 자르는 작업을 단편화(Fragmentation)이라 하고, 수신 측에서 단편화된 블록을 원래의 데이터로 모으는것을 재결합(Reassembly)이라고 합니다. 단편화를 통해 세분화된 데이터 블록을 프로토콜 데이터 단위라고 합니다. 데이터를 단편화하여 전송하면 전송 시간이 빠르고, 통신중의 오류를 효과적으로 제어할 수 있습니다. 너무 작은 블록으로 단편화할 경우 재결합 시 처리 시간이 길어지고, 데이터외에 부수적인 데이터가 많아지므로 비효율적입니다.캡슐화캡슐화(Encapsulation)는 단편화된 데이터에 송, 수신지 주소, 오류 검출 코드, 프로토콜 기능을 구현하기 위한 프로토콜 제어 정보 등의 정보를 부가하는 것으로 요약화라고도 합니다. 대표적인 예가 데이터 링크 제어 프로토콜의 HDLC(High-Level Data Link Control) 프레임입니다. HDLC 프레임은 기본적으로 Flag, 주소 및 제어, 정보 및 CRC(Cyclic Redundancy Check) 세 가지 부분으로 구성됨. 각 부분은 데이터 링크 프레임을 시작하고 종료하며, 제어 및 오류 확인에 필요한 정보를 제공 프로토콜의 확장인 PPP(Point-to-Point Protocol)과 HDLC 기반의 LAPB(Link Access Procedure, Balanced) 등이 사용 정보 데이터를 오류 없이 정확하게 전송하기 위해 캡슐화를 수행합니다.흐름제어흐름제어(Flow Control)는 수신 측의 처리 능력에 따라 송신 측에서 송신하는 데이터의 전송량이나 전송 속도를 조절하는 기능입니다. 정지-대기방식, 슬라이딩 윈도우 방식을 이용합니다.오류제어오류제어(error Control)는 전송중에 발생하는 오류를 검출하고 정정하여 데이터나 제어 정보의 파손에 대비하는 기능입니다.동기화동기화(Synchroniztion)는 송, 수신 측이 같은 상태를 유지하도록 타이밍(Timing)을 맞추는 기능입니다.순서제어순서제어(sequencing)는 전송되는 데이터 블록(PDU)에 전송 순서를 부여하는 기능으로, 연결 위주의 데이터 전송 방식에만 사용됩니다. 송신 데이터들이 순서적으로 전송되도록 함으로써 흐름 제어 및 오류 제어를 용이하게 하는 기능을 합니다.주소지정주소지정(Addressing)은 데이터가 목적지까지 정확하게 전송될 수 있도록 목적지 이름, 주소, 경로를 부여하는 기능입니다. 목적지 이름은 전송할 데이터가 가리키는곳, 주소는 목적지의 위치, 경로는 목적지에 도착할 수 있는 방법을 의미합니다.다중화다중화(Multiplexing)는 한개의 통신 회선을 여러 가입자들이 동시에 사용하도록 하는 기능입니다.경로제어경로제어(Routing)는 송, 수신 측 간의 송신 경로 중에서 최적의 패킷 교환 경로를 설정하는 기능입니다.전송 서비스전송하려는 데이터가 사용하도록 하는 별도의 부가 서비스입니다. 우선순위 (Priority): 특정 메시지를 최대한 빠른 시간 안에 목적지로 전송하기 위하여 메시지 단위에 우선순위를 부여하여 우선순위가 높은 메시지가 먼저 도착하도록 합니다. 예를 들어, 음성 통화나 비디오 스트리밍과 같이 실시간으로 처리되어야 할 데이터는 우선순위를 높게 설정하여 최소한의 지연으로 전송되도록 합니다. 반면에 이메일과 같은 일반적인 데이터는 상대적으로 낮은 우선순위를 가지게 됩니다. 서비스 등급 (Quality of Service - QoS): 데이터의 요구에 따라 서비스 등급을 부여하여 서비스합니다. 한정된 대역폭을 효율적으로 분배하고 데이터의 중요성에 따라 우선순위를 조절함으로써, 더 중요한 서비스가 더 나은 성능을 유지합니다. 보안성 (Security): 액세스 제한과 같은 보안체제를 구현합니다.매체 접근 제어 (Medium Access Control, MAC) 이란? 데이터링크 계층은 물리계층의 문제여부를 판단하여 신뢰성을 확보하며, 데이터링크 계층에는 다음 2개의 부계층(서브레이어)로 구분된다 LLC (Logical Link Control) MAC (Medium Access Control) LLC에서 MAC을 거쳐 물리계층으로 전달되는 구조 (LLC 또는 MAC으로 전송되는게 아니고 둘다 거친다) MAC 주소: MAC 부계층 상에서, 노드 또는 장치의 식별을 위해, 48 비트(6 바이트) 크기를 갖는, 하드웨어 상에 구현된 물리적 주소 여기서 매체(Medium)은 데이터를 전송하는 데 사용되는 물리적인 통신 매체를 의미. 이 매체는 데이터가 전송되는 물리적인 환경을 나타냄. 예를 들어, 유선 통신에서는 동축 케이블, 광섬유 케이블, 트위스트 페어 케이블 등이 매체에 해당. 이러한 유선 매체는 전기적인 신호를 사용하여 데이터를 전송 무선 통신에서는 라디오 또는 마이크로파를 사용하여 데이터를 전송. 무선 매체는 전파를 이용하여 데이터를 공기를 통해 전송하는 방식으로, 더 넓은 범위에서 통신이 가능하며, 유선 제약이 없음 MAC(Medium Access Control)은 여러 단말들 간에 공유 매체(Shared Medium)의 동시 사용에 대한 단말 간 충돌(경합) 발생을 제어(경감)하는 방식을 총칭 예를 들어, 이더넷에서는 CSMA/CD(Carrier Sense Multiple Access with Collision Detection)라는 매체 접근 제어 방식이 사용되며, 무선 네트워크에서는 CSMA/CA(Carrier Sense Multiple Access with Collision Avoidance) 방식이 사용 매체 자원 관점의 보다 일반화된 기술 용어로는, Multiple Access (다원접속)가 있음 한정된 전송 자원을 다수의 노드들이 효율적으로 공평하게 공유 (통신 자원의 공유 MAC Protocol MAC(Medium Access Control) 프로토콜은 네트워크에서 여러 개의 노드가 공유 매체(예: 이더넷, 무선 채널 등)에 접근하는 방법을 규정하는 프로토콜 유선 LAN: CSMA/CD → 802.3, Token Bus → 802.4, Token Ring → 802.5 무선 LAN: CSMA/CA → 802.11 CSMA 기지국이 매체를 사용하려고 시도하기 이전에 매체를 감지하게 되면 충돌의 기회를 줄일 수 있다. CSMA(반송파 감지 다중 접근)는 각 지국이 전송하기 이전에 먼저 매체에 귀를 기울일 것(또는 매체의 상태를 확인)을 요구하고 있다. 다시 말해 CSMA는 Listen before Talk (LBT) 원칙에 기반을 두고 있다. 각 노드들이 프레임을 전송하려고 공유 매체(반송파)에 접근하기 전에, 먼저 매체가 사용중인지 확인(Carrier Sensing)하며 다중접속(Multiple Access)하는 방식 CSMA의 한계 CSMA는 충돌의 가능성을 줄일 수 있으나 완전히 없앨 수는 없다. 기지국이 매체를 감지하여 매체가 idle한 것을 감지한다 해도 다른 지국이 전송한 프레임의 첫 번째 비트가 아직 도달 중일 수 있다. 프레임이 전송(전파)되는 시간차 때문에 idle한 것을 감지하고 나서 프레임을 전송하는 경우 다른곳에서 보낸 프레임이 도착하여 두 프레임이 충돌, 손상될 수 있다. 전파 지연(Propagation Delay) 때문 IEEE 802.3 - CSMA/CD (Carrier Sense Multiple Access/Collision Detection) 반송파 감지 다중 액세스/충돌 검출 유선랜 중 반이중 방식의 이더넷에서 각 단말이 신호 전송을 위해 전송 공유매체에 규칙있게 접근하기 위한 MAC 방식 동일한 전송로(버스)를 여러 단말기가 공유하도록 전송매체에 대한 다중접근 기능이 필요한데 그에 사용 되는 방식 중 가장 많은게 CSMA/CD CSMA/CD 어느 A, B 컴퓨터가 다른 컴퓨터로 스위치를 통해 서버로 정보를 요청한다 가정 A, B 컴퓨터는 서버에 정보를 전송하기 위해 회선이 사용 중이지 않는지 확인. (반송파 감지 - Carrier Sense, 또는 청취) 양 컴퓨터는 회선이 사용 중이지 않다는 것을 확인하고 두 컴퓨터가 서버로 정보를 요청한다 (다중 접근 - Multi Access) 두 컴퓨터의 통신이 충돌(Collision), 신호가 퍼져나갈 때 비정상적인 증폭으로 충돌을 확인한다. (충돌 감지 - Collision Detection) 충돌을 확인한 전송장비가 충돌을 알린다. (충돌 신호 - Jam Signal) A, B 컴퓨터는 충돌을 확인 후 백오프(Backoff) 알고리즘을 수행하고, 임의의 시간동안 전송을 중단한다. 임의의 시간이 지난 후, 다시 청취모드로 돌아가 이 과정을 충돌이 일어나지 않을 때까지 반복한다. 네트워크 허브라는 것이 등장하여 네트워크의 형태가 버스형에서 스타형으로 변경되고, 허브가 업그레이드가 되어 ‘스위칭 허브’ 또는 ‘L2 스위치’로 변경됨에 따라, 이더넷은 실질적으로 충돌 자체가 발생하지 않는 구조로 바뀌었다. 현재의 이더넷은 충돌이 발생하지 않는 구조이지만, 과거와의 호환성 문제로 CSMA/CD는 여전히 이더넷 표준에 포함되어 있다.IEEE 802.11 - CSMA/CA (Carrier Sense Multiple Access/Collision Avoidance) 반송파 감지 다중 액세스/충돌 무시 Wi-Fi가 이 IEEE 802.11 표준에 속한다. 위에는 유선랜, 여기는 무선랜 전파 신호는 감쇠가 크므로 여러개의 충돌되는 신호 에너지도 그렇게 높지 않아 유선 LAN 처럼 전송매체에서의 에너지 레벨 변화로는 매체 사용 감지 판단을 할 수 없음. 따라서 감지하지 않고 회피하는 방식을 사용 참고) 유선 LAN (Ethernet) 유선매체 전압의 변화에 의해 현재 매체 점유 및 충돌 검출을 쉽게 알 수 있음 Carrier Sensing Threshold - LAN 카드 자신 보다 높은 전압이 감지되는지 여부로 판단하거나, 또는 맨체스터 코딩 방식에서의 전압 변화폭 등으로 판단 IEEE 802.11 표준을 보면 두가지 매체 접근 방식이 있음 하나는 PCF(Point Coordination Function) Mode라고 하고 우선 순위 기반으로 경쟁하는 방식이다. 기본적으로 사용하는 방식은 DCF(Distributed Coordination Function) Mode로, CSMA/CA 프로토콜을 사용하는 동등한 우선순위를 가지고 경쟁하는 방식이다. CSMA/CA (CSMA개념은 위랑 동일. CSMA/CD 에서는 ACK 프레임을 사용하지 않지만, CSMA/CA 에서는 ACK 프레임을 사용한다.) 프레임을 전송하고자 하는 Station은 매체가 idle인 상태가 될 때까지 기다린다. 만약 idle 상태가 된다면 원거리의 다른 Station이 매체를 이미 사용하고 있을 수도 있기 때문에 IFS(Inter frame space)라고 부르는 시간동안 대기한다. IFS동안 대기한 뒤에도 idle 상태라면 Contention Window에서 랜덤한 Slot time을 갖고 대기한다. Slot time만큼 대기한 뒤에도 idle 상태라면 전송한 뒤 수신자로부터 ACK 메세지가 오길 기다린다. 이 때, 기다리면서 타이머를 돌리는데 타이머가 끝날 때 까지 ACK 메세지가 자신에게 오지 않으면 다시 뒤로 돌아가서 재전송을 시도한다. ACK 메시지가 도착하면 전송이 성공적으로 이루어졌다고 생각하고 종료한다. IFS (Inter Frame Space) 충돌 회피 방법 요소 IFS (Inter Frame Space)는 프레임 간 공간을 이용한 하나의 충돌 회피 방법으로 한 프레임의 전송이 끝난 후 다음 프레임을 전송하기 전에 기다리는 시간을 의미 우성 채널이 휴지 상태인 것으로 확인 되더라도 전송을 늦추어서 충돌을 회피한다. 휴지 상태의 채널이 발견된 즉시 전송하지 않는 것이다. 기지국은 IFS라 불리는 일정 시간을 기다린다. 채널을 감지 했을 때 휴지 상태인 것처럼 보일지라도 멀리 떨어진 지국이 이미 전송을 시작 했을지 모르기 때문이다. 이런 경우 기다리지 않고 전송을 해버리면 충돌이 일어날 수 있으므로 IFS동안 기다리게 된다. CSMA/CA에서 IFS는 기지국이나 프레임의 우선순위를 규정하는 것에도 사용될 수 있다. 예를 들어 더 짧은 IFS시간을 갖도록 허락된 기지국은 다른 기지국에 비해 높은 우선순위를 갖는 셈이다. 동기화된 MAC 프로토콜에서의 IFS 각 장치들이 데이터 전송을 위해 정해진 프레임 구조와 타이밍을 따르는 프로토콜. 이러한 프로토콜에서는 각 장치들이 데이터를 주고받을 때 일정한 프레임 간격과 IFS를 준수하여 동작 송신측 DIFS(Distributed IFS), 수신측 SIFS(Short IFS)Contention Window 충돌 회피 방법 요소 초기 백오프 (Initial Backoff): 공유 매체가 사용가능함을 알고난 후에도 일정시간(IFS)을 기다리고 그때부터 임의 대기하게 되는 슬롯 단위로 구분되는 시간 범위 역방향 백오프 (Backoff After Collision): CSMA 방식은 충돌이 발생하면 잠시 전송을 멈추는 Back off 상태가 되는데 contention window 구간만큼 대기 후 다시 전송 contention window는 { 0, 1, 2, 3, … , 2^n-1} 만큼의 크기를 가지며, 이 contention window가 커질수록 충돌 할 확률이 낮아진다. 경합 창은 초기 크기로 시작하고, 충돌이 발생할 때마다 두 배로 증가하는 것이 일반적임. 이렇게 함으로써 초기에는 경합이 낮아지고 노드들 사이의 충돌 가능성이 줄어듬 무작위 시간만큼 대기하는 무작위의 스펙트럼이 contention window. 방법이라기보다는 충돌 시 대기할 시간의 스펙트럼이라고 기억하면 될 것 같다. Clear Channel Assessment (CCA) 무선 LAN 802.11 물리 계층(PHY) 상의 기능 중의 하나 공유 무선채널에 대해 물리적으로 사용 가능 여부(busy 또는 idle)에 대한 감지 기능 물리 계층은 CCA를 통해 알아낸 채널상태를 무선 LAN MAC 부계층에 알려주어야 함 참고) 논리적으로(물리적인 신호나 데이터 전송 상태를 이해하고 해석하여) 채널 사용중(busy) 여부를 감지하는 방법 → NAV ED(Energy Detect)/CCA: RSSI 값이 임계 레벨(단위:dBm)을 넘는지 여부로 busy 판단하여 상위계층에게 보고 CS(Carrier Sense)/CCA: 수신기에서 고정 속도(DSSS PLCP 1 Mbps, DSSS Short Preamble 2 Mbps, OFDM 6 Mbps)로 잡아내는 PLCP 프리엠블 및 PLCP 헤더내의 길이 필드를 살펴보고, 현재의 프레임의 지속시간을 계산하여 busy 예상시간을 상위계층에게 보고함유선/무선 MAC 프레임의 일반 포멧 차이 유선 LAN은 대부분 동일 유형의 프레임으로 전달되지만, 무선 LAN은 많은 유형의 프레임들이 저마다 다른 형태와 역할을 갖고 전달됨 유선 LAN : IEEE 802.3 (CSMA/CD) MAC 부계층의 프레임 포멧 무선 LAN : IEEE 802.11 MAC 부계층의 일반적인 프레임 포멧 무선 MAC 프레임의 유형 구분 802.11 표준은 MAC 프레임 형태를 역할에 따라 크게 3가지로 구분 802.11 데이터프레임 (유형 type : 10): 주로, 실제 정보 데이터를 실어나르는 역할 802.11 제어프레임 (유형 type : 01): 데이터의 올바른 전달을 위한 채널 획득, 반송파 감지, 데이터 수신 긍정 확인 응답 등 802.11 관리프레임 (유형 type : 00): 무선망 및 무선 노드에 대한 스캔, 결합, 인증, 해제 등 802.11 MAC 프레임의 일반적인 포멧MAC Protocol 성능 척도 (measure) Energy consumption Delay ThroughputIEEE802.15.4 (WSN) IEEE 802.11 무선 LAN 기술이 저속의 전송속도와 소비전력 측면에서 문제점이 대두되고 있고 IEEE 802.15.1의 블루투스는 복잡도가 나날이 증가함에 따라 가격 및 배터리에 문제점이 노출되고 있다. 이러한 단점을 극복하기 위해 IEEE 802.15.4는 무선 통합 리모컨, 가전기기 컨트롤러, 빌딩 제어 등에 사용하기 위한 저속, 저가격, 저소비전력의 무선 전송 기술 표준을 제정 물리 계층(PHY)과 미디어 액세스 콘트롤 계층(MAC)을 정의하는 표준으로서, 저속도 무선 개인 통신망(Low Rate Wireless Personal Area Networks, LR-WPANs)를 위한 표준 가운데 하나이다. 대표적 이름은 지그비 Zigbee이다. 주로 2.4GHz, 915MHz, 868MHz 등의 무선 주파수 대역을 사용. 2.4GHz 주파수 대역은 Wi-Fi와 블루투스와 공유되며, 주파수 대역의 선택은 지역 규제에 따라 달라질 수 있음 868.0 ~868.6 MHz : 유럽 902~928 MHz : 북미 2400~2483.5 MHz : 세계 IEEE 802.15.4는 16비트 주소 체계를 사용. 따라서 네트워크 내에서 최대 65,535개의 디바이스를 구별 CSMA/CA (Carrier Sense Multiple Access with Collision Avoidance) 방식을 사용하여 효율적인 채널 접근을 지원 Duty cycling in WSNs 무선 센서 네트워크에서 노드들이 네트워크에서 깨어나고 수면하는 동안 고속 데이터 전송, 낮은 지연, 에너지 효율성을 어떻게 달성할 수 있는지가 도전 과제 에너지 제약이 있는 WSNs에서 저전력 동작(Energy consumption)을 위한 핵심 메커니즘 중 하나는 duty cycling. 이 방식에서 각 센서 노드는 주기적으로 활성 상태와 수면 상태를 번갈아 가며 동작 참고) CSMA 메커니즘은 Throughput과 관련 Duty cycling MAC Protocol은 Delay랑 Throughput을 개선시키는 쪽으로 연구가 진행되어야 할 것 Duty cycling의 주요 매개변수로는 수면 시간, 활성 시간, 그리고 활성 상태와 수면 상태에서의 에너지 소비량이 포함됨. Duty cycle의 주기는 수면 시간과 활성 시간의 합 Duty cycling 무선 센서 노드를 대상으로 개발된 표준 MAC 프로토콜은 동기화된 접근과 비동기화된 접근, 그리고 이 두 가지 방식의 하이브리드 조합으로 나뉨. 이러한 방식들은 idle listening을 줄이는 것을 목표로 하며, idle listening은 노드가 패킷을 받지 않는 상태에서도 매체를 청취하는 시간을 의미(802.11 프로토콜에서는 idle listening이 상당한 에너지를 소비한다는 것이 확인되었기 때문)Duty cycling MAC Protocol Duty cycling MAC Protocol 은 두 가지 범주로 나뉨 노드의 깨어있는 시간이 동시에 발생하도록 보장하기 위해 동기화 방법을 사용 동기화 요구사항이 없으며 대신 확장된 preamble과 저전력 수신(low power listening)에 의존하는 방법 동기화된 프로토콜 S-MAC, T-MAC 프레임 내에서 노드가 활성 상태와 수면 상태인 시간을 협상하는 방식으로 동작. 노드들이 통신을 위해 깨어나야 하는 시간을 지정함으로써 idle listening에서 발생하는 시간과 에너지를 줄임(데이터를 전송하기 전에 미리 정해진 타이밍 또는 클럭 신호에 맞추어 데이터를 전송하는 방식) 동기식 기술은 동기화를 위한 오버헤드가 발생하므로 비동기식 기술에 비해 단점이 될 수 있음비동기화된 프로토콜 B-MAC, X-MAC low power listening (LPL) 또는 preamble sampling을 활용하여 데이터를 전송하는 발신자와 동작 중인 수면 상태인 수신자를 연결. 노드들 사이에서 명시적인 동기화 없이도 저전력 통신이 가능하며, idle listening을 제한할 수 있음. 장점 비동기화된 low power listening 프로토콜의 주요 장점은 발신자와 수신자가 완전히 분리된 상태에서 duty cycle을 수행할 수 있다는 점. 동기화된 깨어짐/수면 스케줄링에 필요한 노드간 동기화와 관련된 오버헤드를 제거할 수 있음 단점 low power listening의 긴 프리앰블은 몇 가지 단점을 가짐. 발신자와 수신자 모두 에너지 소비 면에서 최적이 아니며, 비목표 수신자들이 과도한 에너지 소비를 일으키는 overhearing 문제와 각 호프마다의 초과 지연 문제가 발생 overhearing (more) 예를 들어, A, B, C라는 세 개의 노드가 같은 무선 채널을 사용하여 통신하고 있다고 가정해봅시다. 이 때, A 노드가 데이터를 B 노드에게 전송하려고 할 때, C 노드가 현재 채널을 사용하여 B 노드와 통신하고 있을 수 있습니다. A 노드는 C 노드의 통신을 무작위로 감지하게 되는데, 실제로는 A 노드가 C 노드의 데이터를 필요로 하지 않더라도 이러한 감지가 발생할 수 있습니다. 이런 오버허어링은 무선 네트워크에서 성능 저하와 자원 낭비를 초래할 수 있습니다. 왜냐하면 오버허어링으로 인해 통신이 중단되거나 지연될 수 있기 때문입니다. 오버허어링을 관리하고 최소화하기 위해 무선 네트워크에서는 앞서 언급한 CSMA/CA와 같은 프로토콜이 사용됩니다. 이러한 프로토콜은 노드가 채널의 사용 상태를 모니터링하고, 채널이 사용 가능한 경우에만 통신을 시작하도록 지시하여 오버허어링을 감소시키고 전송 충돌을 방지하는 역할을 합니다. 목표 수신자는 데이터 패킷을 수신하기 위해 프리앰블이 끝날 때까지 기다려야 하므로 수신자와 송신자 모두 에너지가 낭비. 또한, low power listening 접근 방식은 더 먼 거리의 노드에게 불필요하게 에너지를 소비하게 만들어, 수신자들 사이의 초과 에너지 소비를 야기. 수신자가 데이터 패킷을 받기 위해 프리앰블이 끝날 때까지 기다려야 하는 점은 각 호프에서의 지연 시간을 최소한 프리앰블의 길이로 제한하는데 이어지며, 멀티호프 경로에서 이러한 지연이 쌓이면서 실질적인 지연이 크게 증가 하이브리드 프로토콜 T-MAC과 같은 동기화된 프로토콜과 비동기화된 low power listening의 조합으로 이루어짐 비교 에너지 소비, 지연 시간 및 처리량 측면에서 비동기적인 듀티 사이클링 기술이 동기화된 기술보다 선호되는 경우가 많습니다. 이는 동기화로 인한 오버헤드가 없기 때문이기도 합니다. 또한 비동기적인 기술은 스케줄 정보를 공유할 필요가 없으며, 데이터를 수신하거나 전송하는 경우를 제외하고는 매체를 샘플링하기 위해 충분히 오래 깨어 있지 않아도 됩니다. 따라서 깨어 있는 기간은 동기화된 방법보다 훨씬 짧을 수 있습니다. 깨어 있는 기간이 짧으면서도 낮은 듀티 사이클을 유지할 수 있기 때문에 비동기적인 프로토콜은 더 자주 깨어나서 작동할 수 있으며, 이로 인해 지연 시간이 감소하고 처리량이 증가할 수 있습니다. 그러나 프리앰블이 너무 길 경우, 패킷 당 에너지 소비가 증가하고 지연 시간이 늘어날 수 있음 상세 설명 (more) 프리앰블이 길어지면 데이터를 전송하기 위해 더 많은 시간이 필요하게 됩니다. 이는 통신 지연을 증가시키며, 실시간 통신이 요구되는 애플리케이션에서는 부적합할 수 있습니다. 예를 들어 음성 통화나 동영상 스트리밍과 같은 응용 프로그램에서는 짧은 지연 시간이 중요합니다. 비동기적 듀티 사이클링 기술은 수신기를 주기적으로 깨우고 수면 상태로 전환하여 에너지를 절약하는 방법입니다. 그러나 프리앰블이 길어지면 수신기가 데이터를 수신하기 위해 더 오래 깨어 있어야 합니다. 이는 전력 소모를 증가시키며, 저전력 통신 시스템의 핵심 목표인 에너지 절약에 부정적인 영향을 미칠 수 있습니다. 일반적으로, 지연 요구 사항이 여유로운 응용 분야의 경우, 동기화된 접근 방식이 더 적절할 수 있습니다.S-MAC (**Sensor MAC**) 이 프로토콜은 주기적인 수면, 가상 클러스터링, 그리고 적응적 수신(adaptive listening)이라는 세 가지 기술을 사용하여 저전력 duty-cycling을 달성 기존 많은 WSN에서는 센싱 이벤트가 발생하지 않을 경우 노드가 오랫동안 대기 상태(idle)에 있음. 이 기간 동안 데이터 전송률이 매우 낮기 때문에 노드를 항상 수신 대기 상태로 유지할 필요가 없음. 우리의 프로토콜은 주기적인 수면 모드로 노드가 들어가도록하여 수신 시간을 줄임 S-MAC에서 노드들은 주기적으로 깨어나서 데이터를 수신하고 송신한 뒤 다시 수면 상태로 돌아감. 깨어나는 기간의 시작부분에서, 노드는 이웃 노드들과 동기화와 스케줄 정보를 교환하여(브로드캐스트) 노드와 이웃 노드들이 동시에 깨어나도록 보장. 이를 통해 idle listening이 감소하고, RTS와 CTS를 통해 충돌 및 오버히어링을 피함 첫 번째 부분은 SYNC 패킷을 수신하는 데 사용되며, 두 번째 부분은 RTS 패킷을 수신하기 위해 사용. 각 부분은 발신자가 캐리어 감지를 수행할 수 있는 여러 시간 슬롯으로 나누어짐 동일한 수면 스케줄을 갖는 노드들을 가상의 클러스터로 형성. 이 스케줄은 로컬적으로만 적용되며, 시스템 전체의 동기화를 필요로하지 않는 가상 클러스터를 형성. 두 개의 가상 클러스터 경계에 있는 노드들은 두 클러스터의 스케줄을 모두 따르며, 이로써 네트워크 전체적인 연결성을 유지 각 노드가 주기적인 listen 및 sleep을 시작하기 전에, 해당 노드는 일정을 선택하고 이를 이웃 노드와 교환. 각 노드는 모든 알려진 이웃의 일정을 저장하는 일정 테이블을 유지 contention-based scheme 노드는 브로드캐스트를 통해 근처의 이웃 노드들과 스케줄을 교환 A가 B랑 통신하기를 원한다면, B가 들을 때까지 기다려야 함 여러 노드가 어떤 노드랑 통신하기를 원한다면 그 노드가 들을 때까지 매체에 대해 경쟁해야 함(contention 메커니즘은 RTS-CTS를 사용하는 802.11과 동일) RTS-CTS (more) RTS/CTS(Request to Send / Clear to Send)는 802.11 무선 네트워크 프로토콜에서 선택적으로 사용할 수 있는 통신 매커니즘이다. RTS/CTS는 은닉 노드 문제 (hidden terminal problem)로 알려진 프레임 충돌을 막기 위해 사용한다. 데이터 전송을 원하는 노드가 무선 링크를 듣고 있는 모든 노드에게 송신 요청(Request To Send) 프레임을 보내는 것으로 프로세스가 시작된다. 송수신 중인 다른 신호가 없어 전송이 가능한 무선 환경인 경우, 목적지 노드는 이 신호에 대해서 무선 링크를 듣고 있는 모든 노드에게 송신 확인(Clear To Send) 프레임을 보내 응답하게 된다. RTS나 CTS 프레임을 받은 다른 모든 노드는 정해진 시간 동안 데이터 전송을 제한하게 된다. (은닉 노드 문제가 해결됨). 전송을 제한하게 되는 시간은 RTS와 CTS 프레임 안에 적혀있다. RTS/CTS는 Carrier sense multiple access with collision avoidance (CSMA/CA) 논리적 신호 탐지(virtual carrier sensing) 을 구현하기 위한 추가적이고 선택적인 방법이다. 첫 번째 RTS 패킷을 보내는 노드가 매체를 점유하며, 수신자는 CTS 패킷으로 응답 메시지 패싱 긴 메시지를 하나의 패킷으로 전송하는 것의 단점은, 첫 번째 전송에서 몇 비트만 손상되었을 경우에도 긴 패킷을 다시 전송하는 데 드는 높은 재전송 비용. SMAC에서는 긴 데이터 메시지가 분할되어 송신자에서 수신자로 전송됩니다. 수신자는 모든 프래그먼트에 대해 확인 응답을 해야하며 그렇지 않으면 재전송 됩니다. 하나의 CTS 및 RTS 메시지만을 사용하여 여러 프래그먼트가 전송됩니다. 802.11의 fragmentation ↔ 메시지 패싱(Message Passing) 802.11에서 RTS와 CTS는 첫 번째 데이터 조각과 첫 번째 ACK에 대해서만 매체를 예약. 첫 번째 조각과 ACK는 두 번째 조각과 ACK에 대한 매체를 예약하고, 이런 식으로 계속됨. 따라서 각 이웃 노드는 조각이나 ACK를 받은 후에도 아직 보내야 할 조각이 하나 더 있다는 것을 알 수 있습니다. 따라서 모든 조각이 전송될 때까지 계속해서 수신 대기해야 함. 다시 말해 에너지 제약이 있는 노드에서는 모든 이웃 노드가 수신 대기하면서 많은 에너지가 낭비될 수 있음 802.11에서 송신자가 어떤 조각에 대한 ACK를 받지 못한 경우, 전송을 포기하고 매체를 재경쟁해야 합니다. 그래서 다른 노드가 전송할 기회를 갖게 됩니다. 이로 인해 수신자가 실제로 전체 메시지를 처리하기 위해 전체 메시지가 필요한 경우 오랜 지연이 발생할 수 있습니다. 이와 대조적으로 메시지 패싱(Message Passing)은 전송 시간을 연장하고 현재 조각을 다시 전송합니다. 이로써 경합이 적고 지연 시간이 짧아집니다. 센서 네트워크의 경우 노드별 공정성(per-node fairness)이 아닌 응용 프로그램 수준의 공정성(application-level fairness)이 목표 Contribution 대기 리스닝 감소(주기적인 리스닝 및 슬립은 네트워크의 유휴 청취를 줄이며, 동일한 수면 일정을 가진 노드의 가상 클러스터를 형성하기 위해 동기화를 사용) 노드가 이웃이 다른 노드로 전송할 때 슬립 모드로 들어가도록 채널 내 신호화를 사용합니다. 이는 overhearing 문제를 해결 RTS 및 CTS 사용으로 충돌 및 동시 수신 방지 메시지의 연속적인 프래그먼트 전송으로 에너지 및 시간 절약(모든 프래그먼트를 전송한 후 경쟁을 하지 않음) 한계점 각 노드의 주기적인 수면으로 인해 지연이 증가. 또한 지연은 각 호프에서 누적 S-MAC과 802.11-like 프로토콜을 비교할 때, sleep 지연은 S-MAC에서 더 크지만 에너지 절약도 더 큽니다. 이는 S-MAC에서 노드가 더 많은 시간을 sleep 상태로 보내기 때문입니다. 따라서, S-MAC은 energy efficiency와 latency 사이의 trade-offs를 제공합니다. 더 많은 에너지를 절약하기 위해 sleep 지연을 증가시킬 수 있습니다. 또는, 더 낮은 latency를 위해 sleep 지연을 줄일 수 있습니다. 다른 추가 연구 latency를 줄이기 위해 adaptive listening을 도입합니다. 노드가 이웃의 RTS 또는 CTS를 듣는 경우, 전송이 끝날 때 잠깐 깨어납니다. 노드가 data path의 다음 hop이라면, 전송이 끝날 때 깨어나면 패킷을 즉시 전달할 수 있으므로 latency가 줄어듭니다. T-MAC (Timeout MAC) S-MAC의 설계를 개선하여, 채널이 유휴 상태(idle)인 경우 깨어있는 기간을 단축시킴 (S-MAC에서는 노드들이 데이터를 보내거나 수신하지 않더라도 깨어있는 기간 동안 깨어있게 됨) T-MAC은 동기화 단계 이후에 채널을 짧은 시간 동안(TA) 감지하고, 이 기간 동안 데이터를 수신하지 않으면 노드는 다시 수면 상태로 돌아감. 데이터를 수신하는 경우, 노드는 추가적인 데이터가 없거나 깨어있는 기간이 끝날 때까지 깨어있음 RTS Operation TMAC Fixed contention interval T-MAC 프로토콜에서 각 노드는 프레임의 시작에서 대기열에 있는 메시지를 버스트로 전송. 부하가 대부분 높고 변하지 않기 때문에 증가하는 경합 간격은 유용하지 않음 RTS retries 노드는 응답을 받지 못한 경우 RTS를 재전송하여 다시 시도해야 함. 두 번의 재시도 후에도 응답이 없으면 포기하고 잠자기로 들어감 Determining TA 노드는 이웃들이 아직 통신 중일 때 잠자기 상태로 들어가선 안됨. 이후 메시지의 수신자가 될 수 있기 때문. 따라서 TA는 적어도 CTS 패킷의 시작을 수신하기에 충분히 길어야 함 한계점 S-MAC 프로토콜에 비해 높은 지연을 가질 수 있음 Early sleeping problem 이웃한 노드가 아직 해당 노드를 위해 메시지를 가지고 있을 때 노드가 sleep 시작. 이로 인해 T-MAC의 throughput이 전통적인 프로토콜이나 S-MAC throughput의 절반 이하로 감소 Future request-to-send 만약 노드가 다른 노드를 위해 설정된 CTS 패킷을 들어 들었다면, 그 노드는 즉시 FRTS 패킷을 보냄. FRTS 패킷에는 블로킹 데이터 통신의 길이가 포함됨(이 정보는 원래 CTS 패킷에 있었음). FRTS 패킷을 수신한 노드는 자신이 미래에 RTS 패킷의 목표가 될 것임을 알고 그 시간까지 깨어 있음. 노드는 FRTS 패킷의 타이밍 정보를 통해 이를 판단 FRTS 패킷이 CTS 이후의 데이터 패킷을 방해하지 않도록 하기 위해, 데이터 패킷은 FRTS 패킷의 기간 동안 지연되어야 함. 이 기간 동안 다른 노드가 채널을 사용하지 못하도록 하기 위해 초기 RTS를 보낸 노드는 작은 Data-Send(DS) 패킷을 전송 FRTS 패킷은 DS 패킷과 크기가 동일하기 때문에 DS 패킷과 충돌하지만 다음 데이터 패킷과는 충돌하지 않음. DS 패킷은 소실(DS 패킷에는 유용한 정보가 없음) full-buffer priority 노드의 전송/라우팅 버퍼가 거의 가득 찬 경우, 해당 노드는 자신을 향한 RTS(Request to Send) 패킷을 받으면 일반적인 CTS(Clear to Send) 응답 대신 즉시 다른 노드로 자신의 RTS 패킷을 전송. Early sleeping problem 확률이 작아짐 하지만 단방향 통신이 아닌 경우, 충돌 확률이 급격히 증가할 수 있음. 노드는 적어도 두 번의 경합을 실패한 경우에만 사용할 수 있음 B-MAC B-MAC은 CSMA 기반 기술로, 저전력 수신과 확장된 프리앰블을 활용하여 저전력 통신을 달성. 각 노드는 깨어있는 기간과 수면 기간을 가지며, 각 노드는 독립적인 스케줄을 가질 수 있음 노드가 전송하고자 하는 경우 데이터 패킷 앞에 수신자의 수면 기간보다 약간 더 긴 프리앰블을 둠. 활성 상태 동안, 노드는 매체를 샘플링(무선 매체 또는 무선 채널을 주기적으로 감지)하고 프리앰블이 감지되면 데이터를 수신하기 위해 깨어있게 됨. 확장된 프리앰블을 사용함으로써 발신자는 언제든지 프리앰블 도중에 수신자가 깨어나서 프리앰블을 감지하고 데이터를 수신할 것으로 보장받음 B-MAC은 트래픽 부하 변화에 적응할 수 있도록 수면 스케줄을 조정. 저자들은 B-MAC이 대부분의 경우에서 처리량, 지연 시간, 에너지 소비 측면에서 기존 프로토콜을 능가한다고 보여줌. 하지만 B-MAC은 overhearing 문제와 긴 프리앰블로 인한 에너지 사용의 문제를 갖음X-MAC 새로운 low power listening 방식을 제안, 에너지 소비를 더욱 줄이고 지연 시간을 감소시키기 위해 짧은 프리앰블을 사용 주소 정보를 내장한 짧은 preamble: X-MAC은 프리앰블에 목표 수신자의 주소 정보를 포함시켜서 비목표 수신자들이 빠르게 수면 상태로 돌아가도록 합니다. 이는 overhearing 문제를 해결하는데 도움이 됩니다. 즉, 비목표 수신자들이 불필요하게 활성화되어 에너지를 소비하는 것을 방지합니다. strobed preamble: X-MAC은 프리앰블들 사이에 간격을 두어 스트로브드 프리앰블을 만듭니다. 이렇게 하면 목표 수신자가 깨어나서 목표 수신자임을 확인하고 바로 일찍 응답함으로써 프리앰블이 전체적으로 끝날 때까지 기다리며 발생하는 시간과 에너지의 낭비를 줄일 수 있습니다. 이러한 짧은 스트로브드 프리앰블 접근 방식은 송신자와 수신자 모두에서 에너지 절약과 호프당 지연 시간 감소를 이룰 수 있습니다. 수신자 duty cycle을 동적으로 조정하는 적응 알고리즘: X-MAC은 네트워크에서의 트래픽 부하에 가장 적합하도록 노드들의 수신자 duty cycle을 동적으로 조정하는 적응 알고리즘을 설명합니다. 이로써 데이터 패킷 당 에너지 소비와 지연을 최적화 위와 같은 방법을 통해 overhearing 문제를 개선함 LPL의 주요한 한계는, 비-목표 수신기들은 프리앰블이 전송되는 동안 매체를 샘플링하고 깨어나 있어야 하며, 마침내 그들이 목표가 아니라는 것을 알게 되는데 확장된 프리앰블이 끝날 때까지 기다려야 한다는 점. 이것을 overhearing 문제라고 하며, 비동기적 기술에서 비효율성과 에너지 낭비의 큰 부분임. 이는 각 송신에 대한 에너지 소모가 수신 범위 내의 수신기 수와 비례함 Comparison of the timelines between LPL’s extended preamble and X-MAC’s short preamble approach. WiseMAC WiseMAC은 B-MAC과 유사한 기술을 사용하지만, 송신자는 수신자의 awake period 일정을 학습하고, extended preamble의 길이를 줄이기 위해 전송을 예약합니다. 이를 위해 수신자는 데이터 acknowledgment 프레임에 다음 awake period의 시간을 넣습니다. 다음에 송신자가 해당 수신자에게 전송하려는 경우, 송신자는 수신자가 깨어날 때까지 잠시만 preamble을 시작할 수 있습니다. 이는 preamble을 전송할 때 에너지를 절약합니다. 또한, preamble이 data frame보다 긴 저 트래픽 부하의 경우, WiseMAC은 extended preamble 대신 data frame을 반복합니다. 수신자는 이 data frame을 처리하고, 노드가 대상 수신자가 아닌 경우 sleep으로 돌아갑니다. 노드가 대상 수신자이면 전송이 끝날 때까지 깨어 있고 acknowledgment을 보냅니다. WiseMAC은 저전력 통신과 관련된 많은 문제를 해결하지만, 노드가 변화하는 트래픽 패턴에 적응할 수 있는 메커니즘을 제공하지 않습니다.IEEE802.15.4(WSN)B-MAC (Berkeley MAC)X-MACS-MACT-MACCWBEB/BackoffIEEE802.11CSMA/CA CDX-MAC CA(Dynamic) Duty CycleNS-3 Simulator6G/7GWSN vs. LORA vs. LIFIml/dl/rl Trend" }, { "title": "(Python)[백준] 친구_1058", "url": "/posts/post230525/", "categories": "CodingTest", "tags": "CodingTest", "date": "2023-05-24 19:00:00 +0900", "snippet": "1058번: 친구풀이# floydwarshallimport sysn = int(sys.stdin.readline())graph = [list(sys.stdin.readline().strip()) for _ in range(n)]f = [[0] * n for _ in range(n)]for k in range(n): for i in range(n): for j in range(n): if i == j: continue if graph[i][j] == &#39;Y&#39; or (graph[i][k] == &#39;Y&#39; and graph[k][j] ==&#39;Y&#39;): f[i][j] = 1ans = 0for row in f: ans = max(ans,sum(row))print(ans)" }, { "title": "(Python)[백준] 평범한 배낭_12865", "url": "/posts/post230522/", "categories": "CodingTest", "tags": "CodingTest", "date": "2023-05-22 19:00:00 +0900", "snippet": "12865번: 평범한 배낭 현재 허용 무게에서 최대 가치를 dp 테이블에 저장해 나감 현재 물건을 넣었을 때와 넣지 않았을 때를 비교하여 큰 값을 dp 테이블에 저장 현재 물건을 넣었을 때를 보려면 현재의 허용 무게에서 현재 물건의 무게를 빼야함. 현재의 허용 무게에서 현재 물건의 무게를 뺐을 때의 최대 가치는 dp 테이블에 저장되어 있으므로 그 최대 가치를 찾아감 아래 그림 예시에서, 3의 무게를 가진 물건을 넣기 위해 현재 허용 무게인 7에서 3을 뺌 → 7-3 = 4 허용 무게가 4일 때의 최대 가치를 찾아감 → (2, 4) 허용 무게 4에서 현재 물건을 넣었을 때의 값과, 현재 허용 무게인 7에 있던 값을 비교함 → 8+6 vs. 13 풀이# knapsack[i][j] = max(현재 물건 가치 + knapsack[이전 물건][현재 가방 무게 - 현재 물건 무게], knapsack[이전 물건][현재 가방 무게])# knapsack[i][j] = max(value + knapsack[i - 1][j - weight], knapsack[i - 1][j])import sysinput = sys.stdin.readline# 물품의 수 N(1 ≤ N ≤ 100)과 준서가 버틸 수 있는 무게 KN, K = map(int,input().split())items = [[0,0]]knapsack = [[0 for _ in range(K + 1)] for _ in range(N + 1)]for _ in range(N): items.append(list(map(int, input().split())))for i in range(1, N + 1): for j in range(1, K + 1): weight = items[i][0] value = items[i][1] if j &amp;lt; weight: knapsack[i][j] = knapsack[i - 1][j] # weight보다 작으면 위의 값을 그대로 가져온다 else: knapsack[i][j] = max(value + knapsack[i - 1][j - weight], knapsack[i - 1][j])print(knapsack[N][K])" }, { "title": "Hyper-v 환경에서 k8s 클러스터 구축", "url": "/posts/post230423/", "categories": "Kubernetes", "tags": "Hyper-v, Kubernetes", "date": "2023-04-23 19:00:00 +0900", "snippet": " 본 글은 ‘쿠버네티스 클러스터 구성을 위한 Hyper-v Provisioning’ 이후 진행함0. 개요 1개의 Master와 3개의 Worker로 구성된 쿠버네티스 클러스터를 구축하는 것이 목표 환경 Host OS: Window11 Hyper-v OS: Rocky-9.1-x86_64-minimal.iso Customize vim / promptline (if nessesary)sudo dnf install -y vim git ctags ShellCheckcurl -fLo &quot;${HOME}/.vim/autoload/plug.vim&quot; --create-dirs &#39;https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim&#39;cat &amp;lt;&amp;lt; EOF &amp;gt; &quot;${HOME}/.vimrc&quot; .vimrc set term=xterm-256color set nu set ai set si set cindent set shiftwidth=4 set tabstop=4 set hlsearch set ruler set title set showmatch set wmnu set expandtab set background=dark set nocompatible set fileencodings=utf-8,euc-kr set bs=indent,eol,start set history=1000 set laststatus=2 set foldenable set foldlevelstart=10 set foldnestmax=10 set foldmethod=indent set autoread set cursorline filetype plugin on filetype indent on call plug#begin(&#39;~/.vim/plugged&#39;) Plug &#39;morhetz/gruvbox&#39; Plug &#39;vim-airline/vim-airline&#39; Plug &#39;vim-airline/vim-airline-themes&#39; Plug &#39;nathanaelkane/vim-indent-guides&#39; Plug &#39;itchyny/vim-cursorword&#39; Plug &#39;tpope/vim-surround&#39; Plug &#39;vim-scripts/WhiteWash&#39; Plug &#39;roxma/vim-paste-easy&#39; Plug &#39;bitc/vim-bad-whitespace&#39; Plug &#39;mtdl9/vim-log-highlighting&#39; Plug &#39;scrooloose/nerdtree&#39;, { &#39;on&#39;: &#39;NERDTreeToggle&#39; } Plug &#39;edkolev/promptline.vim&#39; Plug &#39;godlygeek/tabular&#39; Plug &#39;preservim/tagbar&#39; Plug &#39;preservim/nerdcommenter&#39; Plug &#39;dense-analysis/ale&#39; Plug &#39;vim-scripts/AutoComplPop&#39; Plug &#39;mg979/vim-visual-multi&#39; call plug#end() syntax on colorscheme gruvbox map &amp;lt;C-e&amp;gt; :NERDTreeToggle &amp;lt;CR&amp;gt; map &amp;lt;C-t&amp;gt; :Tagbar &amp;lt;CR&amp;gt; inoremap &amp;lt;S-Tab&amp;gt; &amp;lt;C-d&amp;gt; nnoremap &amp;lt;S-Tab&amp;gt; &amp;lt;&amp;lt; nnoremap &amp;lt;space&amp;gt; za nnoremap &amp;lt;tab&amp;gt; zM nnoremap \\ zR nnoremap &amp;lt;F1&amp;gt; :noh &amp;lt;CR&amp;gt; nnoremap &amp;lt;F2&amp;gt; :set nonumber! &amp;lt;CR&amp;gt; nnoremap &amp;lt;F3&amp;gt; :set mouse=a &amp;lt;CR&amp;gt; nnoremap &amp;lt;F4&amp;gt; :set mouse-=a &amp;lt;CR&amp;gt; nnoremap &amp;lt;F5&amp;gt; :set list! &amp;lt;CR&amp;gt; nnoremap &amp;lt;F6&amp;gt; :%!python -m json.tool &amp;lt;CR&amp;gt; nnoremap &amp;lt;F7&amp;gt; :!vi -u NONE % &amp;lt;CR&amp;gt; nnoremap &amp;lt;F12&amp;gt; :!cat % &amp;lt;CR&amp;gt; let g:gruvbox_contrast_dark = &#39;hard&#39; let g:airline#extensions#tabline#enabled = 1 let g:airline#extensions#tabline#left_sep = &#39; &#39; let g:airline#extensions#tabline#left_alt_sep = &#39;|&#39; let g:airline#extensions#tabline#formatter = &#39;unique_tail_improved&#39; let g:airline_theme = &#39;hybrid&#39; let g:airline_powerline_fonts = 1 let g:indent_guides_enable_on_vim_startup = 1 let g:indent_guides_start_level = 2 let g:indent_guides_guide_size = 1 let g:promptline_theme = &#39;airline&#39; let git_sha_slice = { \\&#39;function_name&#39;: &#39;git_sha&#39;, \\&#39;function_body&#39;: [ \\&#39;function git_sha {&#39;, \\&#39; local sha&#39;, \\&#39; sha=$(git rev-parse --short HEAD 2&amp;gt;/dev/null) || return 1&#39;, \\&#39; printf &quot;%s&quot; &quot;$sha&quot;&#39;, \\&#39;}&#39;]} let g:promptline_preset = { \\&#39;a&#39; : [ &#39;\\h&#39; ], \\&#39;b&#39; : [ &#39;\\u&#39; ], \\&#39;c&#39; : [ &#39;\\w&#39; ], \\&#39;warn&#39; : [ promptline#slices#vcs_branch(), git_sha_slice ] \\} let g:promptline_powerline_symbols = 1 command! -nargs=0 WriteWithSudo :w !sudo tee % &amp;gt; /dev/null cnoreabbrev w!! WriteWithSudo EOFprintf &#39;\\n&#39; | vim +PlugInstall +qall &amp;amp;&amp;gt; /dev/nullprintf &#39;\\n&#39; | vim +&quot;PromptlineSnapshot ${HOME}/.promptline airline&quot; +qall &amp;amp;&amp;gt; /dev/nullprintf &#39;source &quot;${HOME}/.promptline.sh&quot; &amp;amp;&amp;gt; /dev/null\\nfunction vi { vim &quot;${@}&quot;; }\\n&#39; &amp;gt;&amp;gt; &quot;${HOME}/.bashrc&quot; &amp;amp;&amp;amp; source &quot;${HOME}/.bashrc&quot;1. 클러스터 설정Host file (모든 노드에서 설정)cat &amp;lt;&amp;lt; EOF | sudo tee /etc/hosts192.168.25.220 woobin-vm1192.168.25.221 woobin-vm2192.168.25.222 woobin-vm3EOF환경변수 설정export CLUSTER_HOSTS=(woobin-vm1 woobin-vm2 woobin-vm3)export HOME_DIR_PATH=/home/$USERSSH key sharing 각 서버에 접근할 때 비밀번호 없이 로그인하기 위해 host 계정 ssh key를 생성하고 각 서버에 배포# sshd_config 변경for i in ${!CLUSTER_HOSTS[*]}; do ssh woobin@${CLUSTER_HOSTS[$i]} -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no &quot;sudo dnf install -y sshpass &amp;amp;&amp;amp; sudo sed -i -e &#39;s/PasswordAuthentication no/PasswordAuthentication yes/g&#39; /etc/ssh/sshd_config &amp;amp;&amp;amp; sudo systemctl restart sshd&quot; &amp;amp;&amp;gt; /dev/null; done# ssh key 생성echo -e &quot;&amp;gt;&amp;gt; Enter Password:&quot;; read -s PASSWD; for i in ${!CLUSTER_HOSTS[*]}; do echo &quot;i[$i]: [${CLUSTER_HOSTS[$i]}]&quot;; sshpass -p $PASSWD ssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no woobin@${CLUSTER_HOSTS[$i]} &quot;mkdir -p $HOME_DIR_PATH/.ssh; echo -e &#39;n\\n&#39; | ssh-keygen -t rsa -f $HOME_DIR_PATH/.ssh/id_rsa -q -N &#39;&#39;; cp $HOME_DIR_PATH/.ssh/id_rsa.pub $HOME_DIR_PATH/.ssh/authorized_keys; chmod 700 $HOME_DIR_PATH/.ssh&quot; &amp;amp;&amp;gt; /dev/null; done# ssh key 공유echo -e &quot;&amp;gt;&amp;gt; Enter Password:&quot;; read -s PASSWD; for i in ${!CLUSTER_HOSTS[*]}; do echo &quot;i[$i]: [${CLUSTER_HOSTS[$i]}]&quot;; for j in ${!CLUSTER_HOSTS[*]}; do echo &quot;j[$j]: [${CLUSTER_HOSTS[$i]}] -&amp;gt; [${CLUSTER_HOSTS[$j]}]&quot;; sshpass -p $PASSWD ssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no woobin@${CLUSTER_HOSTS[$i]} &quot;sshpass -p $PASSWD ssh-copy-id -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no woobin@${CLUSTER_HOSTS[$j]} &amp;amp;&amp;gt; /dev/null&quot; &amp;amp;&amp;gt; /dev/null; done; done# 체크for i in ${!CLUSTER_HOSTS[*]}; do ssh ${CLUSTER_HOSTS[$i]} -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no &quot;ls -al .ssh&quot;; doneDisable Firewallfor i in ${!CLUSTER_HOSTS[*]}; do ssh woobin@${CLUSTER_HOSTS[$i]} -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no &quot;sudo systemctl stop firewalld &amp;amp;&amp;amp; sudo systemctl disable firewalld &amp;amp;&amp;amp; sudo systemctl mask --now firewalld&quot;; done systemctl stop firewalld: 현재 기동중인 방화벽 중지 systemctl disable firewalld: 시스템 기동시 방화벽 기동 비활성화 systemctl mask --now firewalld: 다른 서비스에서 방화벽 시작 방지 (Created symlink /etc/systemd/system/firewalld.service → /dev/null.) mask: mask는 서비스를 “마스크”하거나 비활성화하는 기능을 합니다. 마스크된 서비스는 수동으로 시작할 수 없으며, 다른 서비스나 사용자의 요청에 의해서도 자동으로 시작되지 않습니다. -now: -now 옵션은 서비스 상태를 변경하는 동시에 즉시 실행하도록 지시하는 옵션입니다. Install initial Packagefor i in ${!CLUSTER_HOSTS[*]}; do ssh woobin@${CLUSTER_HOSTS[$i]} -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no &quot;sudo dnf install -y epel-release; sudo dnf update -y&quot;; done2. DockerInstall docker 현재 구성하는 클러스터에서 도커는 컨테이너 빌드 도구로 사용할 예정. 컨테이너 런타임으로는 containerd를 사용 참고) 도커 엔진은 컨테이너 런타임이 쿠버네티스와 호환되기 위한 요구 사항인 CRI를 만족하지 않는다. 쿠버네티스 v1.24 이전 릴리스는 도커심이라는 구성 요소를 사용하여 도커 엔진과의 직접 통합을 지원했다. 이는 더 이상 쿠버네티스에 포함되지 않는다. for i in ${!CLUSTER_HOSTS[*]}; do ssh woobin@${CLUSTER_HOSTS[$i]} -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no &quot;sudo dnf config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo &amp;amp;&amp;amp; sudo dnf install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin&quot;; doneBash command completion for the docker client 쉘 세션 재시작 시 적용됨for h in ${CLUSTER_HOSTS[*]}; do ssh ${h} -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no &quot;sudo dnf -y install bash-completion &amp;amp;&amp;amp; sudo curl -L https://raw.githubusercontent.com/docker/cli/master/contrib/completion/bash/docker -o /etc/bash_completion.d/docker&quot;; doneEnsure docker for Operation User docker 그룹에 사용자를 추가하여 docker 명령어를 실행할 수 있도록 권한을 부여for h in ${CLUSTER_HOSTS[@]}; do ssh ${h} -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no &quot;sudo usermod -aG docker $USER&quot;; doneConfigure docker(d) kubelet과 컨테이너 런타임이 같은 cgroup 드라이버를 사용해야 하며 구성도 동일해야 함. 본 포스팅에서는 cgroup 드라이버로 systemd 사용 https://kubernetes.io/ko/docs/setup/production-environment/container-runtimes/#cgroup-드라이버for h in ${CLUSTER_HOSTS[@]}; do ssh ${h} -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no &#39;cat &amp;lt;&amp;lt;EOF | sudo tee /etc/docker/daemon.json{ &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;], &quot;hosts&quot;: [&quot;fd://&quot;,&quot;tcp://0.0.0.0:2375&quot;], &quot;containerd&quot;: &quot;/run/containerd/containerd.sock&quot;, &quot;storage-driver&quot;: &quot;overlay2&quot;}EOF&#39;; done &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;]: 컨테이너 런타임의 cgroup 드라이버로 cgroupfs 대신 systemd를 사용 &quot;hosts&quot;: [&quot;fd://&quot;,&quot;tcp://0.0.0.0:2375&quot;]: Docker 데몬이 수신 대기할 호스트와 포트를 지정. &quot;fd://&quot;는 유닉스 도메인 소켓을 통한 연결, &quot;tcp://0.0.0.0:2375&quot;는 모든 IP 주소에서 2375 포트를 통한 TCP 연결을 허용함 &quot;containerd&quot;: &quot;/run/containerd/containerd.sock&quot;: 컨테이너 런타임 “containerd”의 소켓 경로를 지정 &quot;storage-driver&quot;: &quot;overlay2&quot;: overlay2&quot;는 컨테이너 레이어를 효율적으로 관리하기 위해 사용되는 드라이버Configure docker systemd unitfor h in ${CLUSTER_HOSTS[@]}; do ssh ${h} -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no &quot;sudo sed -i &#39;/ExecStart/s/^/# /&#39; /usr/lib/systemd/system/docker.service &amp;amp;&amp;amp; sudo sed -i &#39;/ExecStart/a ExecStart=/usr/bin/dockerd&#39; /usr/lib/systemd/system/docker.service&quot;; done# AS-IS: ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sockRun Docker(d)for h in ${CLUSTER_HOSTS[@]}; do ssh ${h} -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no &quot;sudo systemctl daemon-reload &amp;amp;&amp;amp; sudo systemctl start docker &amp;amp;&amp;amp; sudo systemctl enable docker&quot;; done3. KubernetesDisable SELinux (Security-Enhanced Linux) setenforce 0 및 sed ... 를 실행하여 permissive 모드로 SELinux를 설정하면 효과적으로 비활성화된다. 컨테이너가 호스트 파일시스템(예를 들어, 파드 네트워크에 필요한)에 접근하도록 허용하는 데 필요하다. kubelet에서 SELinux 지원이 개선될 때까지 이 작업을 수행해야 한다.for i in ${!CLUSTER_HOSTS[*]}; do ssh woobin@${CLUSTER_HOSTS[$i]} -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no &quot;sudo setenforce 0 &amp;amp;&amp;amp; sudo sed -i &#39;s/^SELINUX=enforcing$/SELINUX=permissive/&#39; /etc/selinux/config&quot;; doneDisable Memory Swap 메모리 스왑이 활성화돼 있으면 컨테이너의 성능이 일관되지 않을 수 있기 때문# 현재 활성화된 swap 정보 확인cat /proc/swapsfor host in ${CLUSTER_HOSTS[@]}; do ssh ${host} -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no &quot;sudo swapoff -a &amp;amp;&amp;amp; sudo sed -i &#39;/ swap / s/^/#/&#39; /etc/fstab &amp;amp;&amp;amp; sudo mount -a&quot;; doneConfigure k8s repositoryfor host in ${CLUSTER_HOSTS[@]}; do ssh ${host} -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no &quot; cat &amp;lt;&amp;lt;EOF | sudo tee /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=https://pkgs.k8s.io/core:/stable:/v1.29/rpm/enabled=1gpgcheck=1gpgkey=https://pkgs.k8s.io/core:/stable:/v1.29/rpm/repodata/repomd.xml.keyexclude=kubelet kubeadm kubectl cri-tools kubernetes-cniEOF &quot;doneInstall kubelet, kubeadm, kubectlfor host in ${CLUSTER_HOSTS[@]}; do ssh ${host} -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no &quot;sudo dnf install -y kubelet kubeadm kubectl --disableexcludes=kubernetes &amp;amp;&amp;amp; sudo systemctl enable --now kubelet&quot;; done kubeadm: Kubernetes 클러스터를 부트스트랩(시작)하는 데 사용 kubelet: Kubernetes 클러스터의 모든 노드에서 실행되는 구성 요소. pod 및 컨테이너를 시작하는 등 클러스터 내의 모든 노드에서 필요한 작업을 수행 kubectl: Kubernetes 클러스터의 모든 노드에서 실행되는 구성 요소. 이는 pod 및 컨테이너를 시작하는 등 클러스터 내의 모든 노드에서 필요한 작업을 수행 -disableexcludes=kubernetes: Kubernetes 관련 패키지를 설치할 때 다른 패키지 제외 설정을 무시하고 모든 관련 패키지를 설치하도록 지시하는 것Configure containerdfor host in ${CLUSTER_HOSTS[@]}; do ssh ${host} -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no &#39; sudo containerd config default | sudo tee /etc/containerd/config.toml &amp;amp;&amp;amp; sudo sed -i &quot;s/SystemdCgroup = false/SystemdCgroup = true/g&quot; /etc/containerd/config.toml &amp;amp;&amp;amp; sudo systemctl restart containerd &#39;done참고) error: The connection to the server 192.168.x.x:6443 was refused - did you specify the right host or port? kubeadm init 이후에 kubectl get node를 했을 때 처음에는 결과가 잘 나타나다가 시간이 조금 지나면 위와 같은 에러가 나타나기 시작한다. 6443은 쿠버네티스 API에서 사용하는 포트이고 192.168.x.x는 localhost니깐 위의 에러는 자기 자신에 연결할 수 없다는 이야기가 된다. 6443 포트를 통해서 자기 내부에서 돌고 있는 쿠버네티스 시스템과 통신을 하게 되는데 그게 불가능하다는 것은 쿠버네티스가 제대로 돌고 있지 않다는 것이다 컨테이너 런타임(containerd)의 cgroup 드라이버를 설정해줘서 해결Initializing control-plane node 세팅할 클러스터에서 Pod가 서로 통신할 수 있도록 Pod 네트워크 애드온을 설치 해야 한다. kubeadm을 통해 만들어진 클러스터는 CNI(Container Network Interface) 기반의 애드온이 필요하다. 본 글에서는 Calico를 설치하여 사용할 것이다.sudo kubeadm init --pod-network-cidr=192.168.0.0/16 --apiserver-advertise-address=192.168.25.220 —-pod-network-cidr : Pod 네트워크를 설정할 때 사용 192.168.0.0/16 네트워크는 Calico에서 기본적으로 권장하는 네트워크 대역 -apiserver-advertise-address : 특정 마스터 노드의 API Server 주소를 설정할 때 사용 ifconfig 명령를 통해 마스터 노드의 IPv4 주소를 확인 만약 고가용성을 위해 마스터 노드를 다중으로 구성했다면 --control-plane-endpoint 옵션을 사용하여 모든 마스터 노드에 대한 공유 엔드포인트를 설정할 수 있다.참고) [ERROR CRI]: container runtime is not running /etc/containerd/config.toml에서 disabled_plugins 라인을 비활성화하여 CRI 인터페이스를 활성화for host in ${CLUSTER_HOSTS[@]}; do ssh ${host} -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no &quot;sudo sed -i &#39;/^disabled_plugins/s/^/#/&#39; /etc/containerd/config.toml &amp;amp;&amp;amp; sudo systemctl restart containerd&quot;; doneAdditional# maser nodemkdir -p $HOME/.kube &amp;amp;&amp;amp; sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config &amp;amp;&amp;amp; sudo chown $(id -u):$(id -g) $HOME/.kube/config# worker nodefor host in ${CLUSTER_HOSTS[@]}; do ssh ${host} -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no \\ &quot;mkdir -p \\$HOME/.kube &amp;amp;&amp;amp; scp woobin@woobin-vm1:${HOME}/.kube/config \\$HOME/.kube/&quot;done root 계정이 아닌 다른 사용자 계정에서 kubectl 명령어를 사용하여 클러스터를 제어하기 위함Install calico https://docs.tigera.io/calico/latest/getting-started/kubernetes/quickstartkubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.27.3/manifests/tigera-operator.yamlkubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.27.3/manifests/custom-resources.yamlJoin nodessudo kubeadm join 192.168.25.220:6443 \\ --token ielh36.8k2eiq8m5rk0u12d \\ --discovery-token-ca-cert-hash sha256:6a4e73b78661ecbe9d7a43694ae5809c2601309461a14fed6f595fdb13796edc 명령어에서 확인할 수 있는 것과 같이 워커 노드가 마스터 노드에 결합(join)하기 위해서는 아래 인자들이 필요하다. 마스터 노드의 IP:6443 (6443 포트는 kubernetes api server 프로세스의 기본 포트이다. 만약 마스터 노드의 api server 포트가 6443이 아니라면 해당 마스터 노드의 api server 포트 번호를 기입해주면 된다.) -token (token은 기본적으로 24시간 뒤 만료된다.) -discovery-token-ca-cert-hash 마스터 노드의 IP와 포트는 쉽게 알 수 있지만, 만약 --token 값과 --discovery-token-ca-cert-hash 값을 잊어버렸다면 아래와 같이 다시 찾을 수 있다. -token 찾는 명령어 kubeadm token list -discovery-token-ca-cert-hash 찾는 명령어 openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2&amp;gt;/dev/null | openssl dgst -sha256 -hex | sed &#39;s/^.* //&#39; 만약 token이 24시간이 지나서 만료가 되었을 때에는 아래의 명령어를 통해 새로 생성이 가능하다. kubeadm token create Unsetfor host in ${CLUSTER_HOSTS[@]}; do ssh ${host} -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no &quot;unset CLUSTER_HOSTS&quot;; doneReference https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/" }, { "title": "(Python)[백준] 미친 로봇_1405", "url": "/posts/post230421/", "categories": "CodingTest", "tags": "CodingTest", "date": "2023-04-21 19:00:00 +0900", "snippet": "문제1405번: 미친 로봇풀이# 이동 경로 -&amp;gt; 좌표 -&amp;gt; 이차원 리스트, 방향 정의 필요# 이동 경로가 단순하다는 것은 한 번 간 곳을 다시 가지 않는다는 것 # 단순할 확률 = 한 번 간 곳을 다시 가지 않을 확률 -&amp;gt; 방문 처리 하며 DFS 탐색from typing import Listimport sys# sys.setrecursionlimit(10**6) # 왜 여기서는 안해줘도 에러가 안나지? 저번 문제하고 무슨 차이?# 저번 문제는 재귀 기본 제한을 늘려준 것. 이번 문제는 늘릴 필요가 없는 것input=sys.stdin.readlineN,e,w,s,n = map(int, input().split())# 가로 x축, 세로 y축 일 때# 동,서,남,북 방향 정의 dx = [1,-1,0,0]dy = [0,0,1,-1]# 동,서,남,북 이동할 확률pred_list = [e,w,s,n]# 현재 위치에서 최대 N만큼 이동해야 하므로 # N이 중앙으로 오도록 2차원 배열 생성graph = [[0]*(2*N+1) for _ in range(2*N+1)]answer = 0def dfs(x: int, y: int, pred: float, cnt: int): global answer if cnt == N: # cnt가 N인 모든 경우에 대한 OR 연산이므로 + answer += pred return # 현재 노드 방문 처리 graph[x][y] = 1 # 현재 노드의 방문 확률 now_pred = pred for i in range(len(pred_list)): next_x = x + dx[i] next_y = y + dy[i] if 0 &amp;lt;= next_x &amp;lt; (2*N+1) and 0 &amp;lt;= next_y &amp;lt; (2*N+1): if not graph[next_x][next_y]: # 현재 위치에서 연달아 동서남북 이동할 경우에 대한 AND 연산이므로 * dfs(next_x, next_y, now_pred * (pred_list[i]/100), cnt+1) # 이후 실행될 dfs 함수 처리를 위해 방문 처리 해제 graph[next_x][next_y] = 0 else: continuedfs(N, N, 1, 0)print(answer)" }, { "title": "(Python)[백준] 트리의 부모 찾기_11725", "url": "/posts/post230419/", "categories": "CodingTest", "tags": "CodingTest", "date": "2023-04-19 19:00:00 +0900", "snippet": "문제11725번: 트리의 부모 찾기풀이from typing import Listimport sys# 자기 호출 개수 제한. 안하면 메모리 초과..ㅂㄷ# Python3의 기본 재귀 깊이가 1000이므로 재귀깊이를 해제한다sys.setrecursionlimit(10**6)# 안하면 시간 초과..ㅂㄷinput=sys.stdin.readline# 노드의 개수N = int(input())# 2차원 리스트(인접 행렬)graph = [[] for _ in range(N+1)] # 1부터 시작하므로 n+1# 노드의 부모를 기록하는 리스트visited = [0] * (N+1)# 트리 상에서 연결된 두 정점 입력 받기for _ in range(N-1): a, b = map(int, input().split()) graph[a].append(b) graph[b].append(a)def dfs(graph: List[int], vertex: int, visited: List[int]): # 현재 노드와 연결된 다른 노드를 재귀적으로 방문 for i in graph[vertex]: if not visited[i]: visited[i] = vertex # 부모 노드를 저장 dfs(graph, i, visited)# 1의 부모는 1visited[1] = 1dfs(graph, 1, visited)for i in range(2, N+1): print(visited[i])" }, { "title": "(Python)[백준] 트리와 쿼리_15681", "url": "/posts/post230416/", "categories": "CodingTest", "tags": "CodingTest", "date": "2023-04-16 19:00:00 +0900", "snippet": "문제15681번: 트리와 쿼리풀이from typing import Listimport sys# 자기 호출 개수 제한. 안하면 메모리 초과..ㅂㄷ 아래 옵션으로 늘려줘야 함# Python3의 기본 재귀 깊이가 1000이므로 재귀깊이를 해제한다sys.setrecursionlimit(10**6)# 안하면 시간 초과..ㅂㄷinput=sys.stdin.readline# 트리의 정점의 수 N과 루트의 번호 R, 쿼리의 수 QN, R, Q = map(int, input().split())# 2차원 리스트(인접 행렬)graph = [[] for _ in range(N+1)] # 1부터 시작하므로 n+1# 노드의 부모를 기록하는 리스트visited = [0] * (N+1)# 트리에 속한 간선의 정보for _ in range(N-1): a, b = map(int, input().split()) graph[a].append(b) graph[b].append(a)# 노드의 부모를 기록하는 리스트visited = [0] * (N+1)def dfs(graph: List[int], vertex: int, visited: List[int]): visited[vertex] = 1 # 현재 노드와 연결된 다른 노드를 재귀적으로 방문 for i in graph[vertex]: if not visited[i]: dfs(graph, i, visited) # 각 노드에 대한 서브 트리의 수를 저장 visited[vertex] += visited[i]dfs(graph, R, visited)for i in range(Q): q = int(input()) print(visited[q])" }, { "title": "(Java) 의존관계 주입 (Dependency Injection)", "url": "/posts/post230413/", "categories": "Java", "tags": "Java", "date": "2023-04-13 19:00:00 +0900", "snippet": "DI 란 무엇인가DI는 Dependency Injection의 줄임말로, 다양한 우리 말 번역이 있지만, 이 글에서는 의존관계 주입이라는 말로 사용하고자 한다.먼저 Dependency, 의존관계에 대해 알아보자.Dependency 의존관계란 무엇인가?“A가 B를 의존한다.”는 표현은 어떤 의미일까? 추상적인 표현이지만, 토비의 스프링에서는 다음과 같이 정의한다. 의존대상 B가 변하면, 그것이 A에 영향을 미친다. 이일민, 토비의 스프링 3.1, 에이콘(2012), p113 즉, B의 기능이 추가 또는 변경되거나 형식이 바뀌면 그 영향이 A에 미친다.다음의 햄버거 가게 요리사 예시를 보며 설명을 계속하겠다.햄버거 가게 요리사는 햄버거 레시피에 의존한다. 햄버거 레시피가 변화하게 되었을 때, 변화된 레시피에 따라서 요리사는 햄버거 만드는 방법을 수정해야 한다. 레시피의 변화가 요리사의 행위에 영향을 미쳤기 때문에, “요리사는 레시피에 의존한다”고 말할 수 있다. 코드로 표현해보면 다음과 같다.class BurgerChef { private HamBurgerRecipe hamBurgerRecipe; public BurgerChef() { hamBurgerRecipe = new HamBurgerRecipe(); }}의존관계를 인터페이스로 추상화하기위 BurgerChef 예시를 보자. 지금의 구현에서는 HamBurgerRecipe만을 의존할 수 있는 구조로 되어있다. 더 다양한 BurgerRecipe를 의존 받을 수 있게 구현하려면 인터페이스로 추상화해야 한다.다음의 코드에서 볼 수 있듯이, 다양한 버거들의 레시피에 의존할 수 있는 BurgerChef가 된다.class BurgerChef { private BurgerRecipe burgerRecipe; public BurgerChef() { burgerRecipe = new HamBurgerRecipe(); //burgerRecipe = new CheeseBurgerRecipe(); //burgerRecipe = new ChickenBurgerRecipe(); }}interface BugerRecipe { newBurger(); // 이외의 다양한 메소드} class HamBurgerRecipe implements BurgerRecipe { public Burger newBurger() { return new HamBerger(); } // ...}의존관계를 인터페이스로 추상화하게 되면, 더 다양한 의존 관계를 맺을 수가 있고, 실제 구현 클래스와의 관계가 느슨해지고, 결합도가 낮아진다.그렇다면 Dependency Injection은?의존관계가 무엇인지에 대해, 그리고 다양한 의존관계를 위해 인터페이스로 추상화함을 알아봤다. 그렇다면, Dependency Injection은 무엇인가?지금까지의 구현에서는 BurgerChef 내부적으로 의존관계인 BurgerRecipe가 어떤 값을 가질지 직접 정하고 있다. 만약 어떤 BurgerRecipe를 만들지를 버거 가게 사장님이 정하는 상황을 상상해보자. 즉, BurgerChef가 의존하고 있는 BurgerRecipe를 외부(사장님)에서 결정하고 주입하는 것이다.이처럼 그 의존관계를 외부에서 결정하고 주입하는 것이 DI(의존관계 주입)이다.토비의 스프링에서는 다음의 세 가지 조건을 충족하는 작업을 의존관계 주입이라 말한다. 클래스 모델이나 코드에는 런타임 시점의 의존관계가 드러나지 않는다. 그러기 위해서는 인터페이스만 의존하고 있어야 한다. 런타임 시점의 의존관계는 컨테이너나 팩토리 같은 제3의 존재가 결정한다. 의존관계는 사용할 오브젝트에 대한 레퍼런스를 외부에서 제공(주입)해줌으로써 만들어진다. - 이일민, 토비의 스프링 3.1, 에이콘(2012), p114DI 구현 방법DI는 의존관계를 외부에서 결정하는 것이기 때문에, 클래스 변수를 결정하는 방법들이 곧 DI를 구현하는 방법이다. 런타임 시점의 의존관계를 외부에서 주입하여 DI 구현이 완성된다.Burger 레스토랑 주인이 어떤 레시피를 주입하는지 결정하는 예시로 설명하고자 한다. 생성자를 이용class BurgerChef { private BurgerRecipe burgerRecipe; public BurgerChef(BurgerRecipe burgerRecipe) { this.burgerRecipe = burgerRecipe; }} 메소드를 이용 (대표적으로 Setter 메소드)`class BurgerChef { private BurgerRecipe burgerRecipe = new HamburgerRecipe(); public void setBurgerRecipe(BurgerRecipe burgerRecipe) { this.burgerRecipe = burgerRecipe; }}class BurgerRestaurantOwner { private BurgerChef burgerChef = new BurgerChef(); public void changeMenu() { burgerChef.setBurgerRecipe(new CheeseBurgerRecipe()); }}`DI 장점그렇다면, DI, 의존 관계를 분리하여, 주입을 받는 방법의 코드 구현은 어떠한 장점이 있을까?1. 의존성이 줄어든다.앞서 설명했듯이, 의존한다는 것은 그 의존대상의 변화에 취약하다는 것이다(대상이 변화하였을 때, 이에 맞게 수정해야함). DI로 구현하게 되었을 때, 주입받는 대상이 변하더라도 그 구현 자체를 수정할 일이 없거나 줄어들게 됨.2. 재사용성이 높은 코드가 된다.기존에 BurgerChef 내부에서만 사용되었던 BurgerRecipe을 별도로 구분하여 구현하면 다른 클래스에서 재사용할 수가 있다.3. 테스트하기 좋은 코드가 된다.BurgerRecipe의 테스트를 BurgerChef 테스트와 분리하여 진행할 수 있다.4. 가독성이 높아진다.BurgerRecipe의 기능들을 별도로 분리하게 되어 자연스레 가동성이 높아진다.정리DI(의존관계 주입)는 객체가 의존하는 또 다른 객체를 외부에서 선언하고 이를 주입받아 사용하는 것이다. 이를 구현함으로써 얻을 수 있는 장점들을 알아봤다.Reference https://tecoble.techcourse.co.kr/post/2021-04-27-dependency-injection/ https://ahea.wordpress.com/2018/09/09/1754/ https://jwchung.github.io/DI는-IoC를-사용하지-않아도-된다" }, { "title": "Hyper-v 환경에서 k8s 클러스터 구성을 위한 provisioning", "url": "/posts/post230329/", "categories": "Kubernetes", "tags": "Hyper-v, Kubernetes", "date": "2023-03-29 19:00:00 +0900", "snippet": "0. 개요 1개의 마스터와 2개의 워커로 구성된 쿠버네티스 클러스터를 구축하는 것이 목표 환경 Host OS: Window11 Hyper-v OS: Rocky-9.1-x86_64-minimal.iso 1. Hyper-v 설정1) Hyper-V 켜기 실행 창 켜기: Windows Key + R 명령어 입력: OptionalFeatures Hyper-V 켜기 재부팅2) Hyper-V Network Adapter 생성Public Network 로컬 PC를 브릿지로 사용하여 외부랑 통신하기 위한 Public Network 스위치 구축 Hyper-v 관리자 열어서 네트워크 생성 pc 이름 우클릭 → 가상스위치 관리자 ![Untitled](/assets/img/2023-03-29-post230329/Untitled%201.png) 새 가상 네트워크 스위치 → 외부 → 가상 스위치 만들기 가상 스위치 설정: 연결 형식 → 외부 네트워크 → 연결되어 있는 네트워크 선택 → 확인 [경고] 보류 중인 변경 내용은 네트워크 연결을 방해할 수 있습니다 → 예 주의: 네트워크가 한 번 끊기고 다시 연결됨. 새로 생성된 네트워크 디바이스에 DNS 설정을 다시 해줘야 함. 2. VM 생성1) 배포 이미지 다운로드 Rocky-9.1-x86_64-minimal.iso2) Hyper-v 관리자에서 가상 컴퓨터 생성 가상 컴퓨터 이름 설정 1세대는 legacy 모델 이므로 2세대 선택 메모리 할당 (주의! : 동적메모리 체크 해제) Default Switch를 선택 Default Switch는 폐쇄망 구축 시 사용할 예정. gateway 역할을 하는 하나의 노드만 외부망으로 연결하고 나머지 노드는 Default Switch의 내부망으로 통신함 본 글에서는 스터디를 위하여 편의상 모든 노드에 외부망을 연결함 가상 하드 디스크 만들기 OS ISO 파일을 마운트 하고 다음을 클릭하여 진행 마침 k8s-worker-node도 위와 동일한 방법으로 생성 3) 생성된 VM 설정 변경 프로세서 개수 변경 외부 통신을 위해 public network 추가 검사점 유형 변경 보안 부팅 사용 안함 실행 3. 서버 설정 각 노드에서 설정1) 계정 생성 및 sudoer 설정[root@localhost ~]# useradd woobin[root@localhost ~]# printf &quot;%s:%s&quot; &quot;woobin&quot; &quot;woobin&quot; | chpasswdChanging password for user woobin.passwd: all authentication tokens updated successfully.[root@localhost ~]# cat /etc/passwd | grep woobinwoobin:x:500:500::/home/woobin:/bin/bash[root@localhost ~]# touch /etc/sudoers.d/woobin[root@localhost ~]# echo &#39;woobin ALL=NOPASSWD:ALL&#39; &amp;gt;&amp;gt; /etc/sudoers.d/woobin[root@localhost ~]# cat /etc/sudoers.d/woobinwoobin ALL=NOPASSWD:ALLexitlocalhost login: woobin 사용자명 ALL=NOPASSWD: ALL → 여기서 NOPASSWD:를 빼면 sudo 실행시 자신의 패스워드를 입력해야만 함 사용자명 ALL=NOPASSWD: 명령어1, 명령어2 → 지정한 명령어들만 sudo 사용가능 계정 삭제 시, userdel -r ${user} -r 없이 userdel userid만 하게 되면 같은 아이디의 유저를 생성하게 될 경우 Creating mailbox file: File exists 에러를 만날 수 있다. 2) 필수 패키지 설치sudo dnf -y updatesudo dnf install -y epel-releasesudo dnf install -y openssh-server NetworkManager vim jq net-tools# sshd 상태 확인sudo systemctl status sshd● sshd.service - OpenSSH server daemon Loaded: loaded (/usr/lib/systemd/system/sshd.service; enabled; preset: enabled) Active: active (running)3) Hostname 변경sudo hostnamectl set-hostname &amp;lt;VM 이름&amp;gt;4) 네트워크 설정# 현재 network 연결 확인nmcliCONNECTION_NAME=&#39;eth1&#39;PUBLIC_IP=&#39;192.168.25.220&#39; # 192.168.25.220-192.168.25.222# network 삭제nmcli con delete ${CONNECTION_NAME}# network 추가nmcli con add con-name ${CONNECTION_NAME} autoconnect yes \\ipv4.address ${NETWORK_IP}/20 \\ipv4.gateway 192.168.20.1 \\ipv4.dns 168.126.63.1,168.126.63.2 \\ipv4.method manual \\type ethernet \\ifname eth1# 변경 사항 반영nmcli con up eth1exit이제부터 터미널 클라이언트(윈도우 터미널, putty, 모바엑스텀 등)로 ssh 접속하여 작업하면 편리하다." }, { "title": "(Hadoop) Abstract of Zookeeper and ZKFC", "url": "/posts/post230224/", "categories": "Hadoop", "tags": "Hadoop", "date": "2023-02-24 19:00:00 +0900", "snippet": "0. 개요1) Raft Consensus Algorithm 분산 시스템에서 전체 노드의 최신화 및 동기화, 그리고 장애를 복구할 수 있는 능력인 내결함성(False Tolerance)을 동시에 구현하기 위해 만들어진 합의 알고리즘 리더 선출 프로세스, 로그 엔트리 복제 등의 메커니즘을 사용 합의 알고리즘을 채택한 분산 시스템에서는 전체 노드 수를 가급적 3개 이상의 홀수로 유지하는 것이 권장 전체 노드 수가 3개 이상이어야 허용 가능한 장애 노드가 생긴다. 그 미만으로는 내결함성을 갖출 수 없음 전체 노드 수가 홀수일 때 허용 가능한 장애 노드 수의 비율이 좀 더 높다. 분할 투표(split votes)로 인한 리더 선출(Leader Election)의 불필요한 반복과 명령 처리 지연 가능성을 줄이기 위해서라도 홀수 개의 노드 운영이 더욱 권장 2) Hadoop HA Architecture Active Name Node와 Standby Name Node는 데이터 노드로부터 블록 리포트와 하트비트를 받아서 동일한 메타데이터를 유지하고, Journal Node 를 이용하여 edit log 공유 Active Name Node에 문제가 발생하면 Standby Name Node가 Active Name Node로 동작 Active Name Node에 문제가 발생하는 것을 자동으로 확인하는 것이 어렵기 때문에 보통 Zookeeper를 이용하여 장애 발생시 자동으로 변경될 수 있도록 함Zookeeper Zookeeper는 어떤 Name Node가 Active 인지, Standby 인지를 저장함으로써 Name Node들을 관리 클러스터의 각 Name Node는 Zookeeper에서 영구 세션을 유지함. 시스템이 문제가 생기면 Zookeeper 세션이 만료되어 장애 조치가 트리거 되어야 함을 다른 Name Node에 알림ZKFC (ZooKeeper Failover Controller) zkfc는 Hadoop 클러스터의 Name Node 장애 복구를 관리하는 데몬 Zookeepr Client 로써 동작 Name Node가 동작하는 서버에 zkfc 도 같이 동작하면서 상태 확인 명령을 통해 Name Node 상태를 모니터링 Zookeeper를 기반으로 Name Node를 활성화Zookeeper와 ZKFC zkfc는 평소(Name Node 가 정상 동작할 때)에 Zookeeper 와 zkfc 간 세션을 유지 zkfc는 Active Name Node의 상태가 비정상이 되면 이를 감지하여 zkfc 와 Zookeeper 간 세션을 종료시킴 Zookeeper는 Active 가 반응이 없으면 (세션이 끊기면) 바로 Standby Name Node 에게 Active 가 장애가 났음을 알림 zkfc는 로컬 Name Node가 정상이고 현재 lock znode를 보유하고 있는 다른 노드가 없음을 확인하면 자체적으로 lock 획득을 시도함 Zookeeper는 여러 Standby Name Node 가 있다면 어떤 것을 Active 로 선출할지 정함 zkfc는 Zookeeper를 기반으로 다음 Name Node를 활성화(다른 노드는 차단. fencing method)1. Zookeeper 소개 분산 시스템을 설계할 때의 문제점 분산된 시스템간의 정보 공유 클러스터에 있는 서버들의 상태 체크 분산된 서버들간에 동기화를 위한 락(lock) 처리 이러한 문제를 해결하는 시스템을 코디네이션 서비스 시스템 (coordination service) 이라고 하며, Apache Zookeeper가 대표적임2. Zookeeper 구성1) Zookeeper 데이터 모델 Zookeeper는 디렉토리 구조 기반으로 된 key-value 자료구조. 사실상 Zookeeper는 여기에 데이터를 넣고 빼는 기능이 가장 큰 핵심. 나머지는 분산 시스템의 문제를 이로 구현할 것일 뿐임 znode는 ZooKeeper 서버에 등록한 노드 또는 경로 크기가 작은 data를 저장할 것이라고 가정하고 구현되어 있기 때문에 각 znode의 크기는 1MB로 제한 znode 종류 Persistent Node znode에 데이터를 저장하는 순간 영구 저장되는 노드 (단, 강제 삭제시엔 삭제됨) Ephemeral Node znode를 생성한 클라이언트의 세션이 연결되어 있을 때만 유효한 노드 (연결이 끊어질 시 자동 삭제) 이를 통해서 클라이언트가 연결이 되어 있는지 아닌지를 판단하는데 사용할 수 있다. (클러스터를 구성할때 클러스터내에 서버가 들어오면, 이 Ephemeral Node로 등록하면 된다.) Sequence Node znode를 생성할때 자동으로 sequence 번호가 붙는 노드 (분산락 구현에 이용) znode 예) [ Hadoop DataNode Zookeeper zkCli.sh ] 2) Zookeeper Watcher ZooKeeper 클라이언트에서 발생하는 이벤트를 처리하기 위해 사용되는 콜백 인터페이스 Watch 기능은 ZooKeeper 클라이언트가 특정 znode에 watch를 걸어놓으면, 해당 znode가 변경이 되었을때, 클라이언트로 callback 호출을 날려서 클라이언트에 해당 znode가 변경이 되었음을 알려준다. 그리고 해당 watcher는 삭제 된다.3. ZooKeeper 활용 시나리오 ZooKeeper 클라이언트 쉘, 또는 ZooKeeper API로 구현 (보통 ZooKeeper 클라이언트 쉘은 주로 간단한 테스트 및 디버깅 용도로 사용)1) 큐 Watcher와 Sequence node를 이용 Queue 라는 Node를 만든 후에, 이 노드의 Child node를 sequence node로 구성하면 새롭게 생성되는 메세지들은 이 sequence node 순차적으로 생성 이 큐를 읽는 클라이언트가 이 큐 node를 watch 하도록 설정하면, 이 클라이언트는 새로운 메세지가 들어올 때 마다 call back을 받아서, 마치 메세지 Queue의 pub/sub 과 같은 형태의 효과를 낼 수 있다.2) 서버 설정 정보 저장 가장 일반적인 용도로는 클러스터 내의 각 서버들의 설정 정보(Configuration)를 저장하는 저장소로 쓸 수 있다. 정보가 안정적으로 저장이 될 뿐 아니라. Watch 기능을 이용하면, 설정 정보가 저장될 경우, 각 서버로 알려서 바로 반영을 할 수 있다.3) 클러스터 정보 유지 현재 클러스터에서 기동중인 서버 목록을 유지할 수 있다. Ephemeral Node는 Zookeeper 클라이언트가 살아 있을 경우에만 유효하기 때문에, 클러스터내의 각 서버가 Ephemeral Node를 등록하도록 하면, 해당 서버가 죽으면 Ephemeral Node 가 삭제 되기 때문에 클러스터 내의 살아 있는 Node 리스트만 유지할 수 있다.4) 글로벌 락 Zookeeper를 이용하여 많이 사용되는 시나리오 중의 하나로, 여러개의 서버로 구성된 분산 서버가 공유 자원을 접근하려고 했을 때, 동시에 하나의 작업만이 발생해야 한다고 할 때, 그 작업에 Lock을 걸고 작업을 할 수 있는 기능을 구현할때 사용한다. 자바 멀티 쓰레드 프로그램에서 synchronized를 생각하면 쉽게 이해가 가능할 것4. ZooKeeper 응용 사례 Zookeeper는 보통 Hadoop Eco System과 같이 사용됨1) Spark with Zookeeper Zookeeper는 스케줄링 Cluster Manager(Master)의 장애에 대비하여 고가용성 기능을 제공2) Kafka Cluster with ZooKeeper Kafka의 Zookeeper 클라이언트는 Kafka 의 브로커를 관리하고 조정하는 데 사용 Kafka도 분산 처리 플랫폼이지만 메시지를 주고 받는 Pub/Sub 외에는 아무것도 하지 않음 → 브로커 상태를 저장하지 않기 때문에 상태 관리를 위해 Zookeeper를 사용 클러스터 아키텍처 Producer와 Consumer는 kafka의 브로커 정보를 가지고 있음. 만약 동적으로 브로커의 상태가 변경(스케일 아웃되는 등) 되는 경우 Zookeeper가 이를 알려줌 브로커로 메시지 생산 실패 시 Zookeeper가 다른 정상 서버로 Producer와 Consumer에게 브로커를 알림 3) Redis Cluster with Zookeeper ZooKeeper의 기능(디렉터리 구조, Watcher)을 이용하여 Redis Cluster의 Health check, Server failover, Sharding rule 관리를 담당하는 서비스(Redis Cluster Manager)를 설계 클러스터 아키텍처 ZooKeeper 디렉터리 구조 아래와 같이 ZooKeeper의 분산 저장소 기능을 사용해 디렉터리 구조를 설계하고, Watch 기능을 이용하여 애플리케이션 서버에서 해당 디렉터리 정보를 이용 4) Apache Storm, HBase, Solr, Flume, Ambari, Nutch, etc.5. 결론 제품의 앱 스택이 대부분 컨테이너로 구축되어 있다면 k8s로 장애 대응 가능. Zookeeper를 쓴다면 컨테이너로 구축되지 않은 앱을 HA 구성할 때 사용할 수 있을 것 같음 Hive, Spark, etc. Hadoop을 Docker로 구축하면 Zookeeper-ZKFC를 안쓰고 쿠버네티스를 통해 고가용성을 챙길 수 있을 것 같음 만약 zkfc가 문제가 발생한다면 네임 노드가 정상이어도 다른 네임 노드로 Active 변경 필요 네임노드 간의 fencing 설정이 중요(아래는 설정이 제대로 안되어 있는 예시) [ hdfs-site.xml ] fencing 설정이 안되어 있으면 둘 다 Active가 되어 충돌 발생할 수 있음(다른 하나의 네임 노드가 완전히 죽었을 경우 만을 고려할 수 있음) Hadoop Eco 클러스터 내 앱 간에는 소켓 통신이(SSH) 필수Reference https://seongjin.me/raft-consensus-algorithm/ https://sencia.tistory.com/38 https://bcho.tistory.com/1016 https://zookeeper.apache.org/doc/r3.4.6/recipes.html#ch_recipes https://d2.naver.com/helloworld/294797 https://docs.cloudera.com/HDPDocuments/HDP3/HDP-3.0.0/fault-tolerance/content/configure_and_deploy_automatic_failover.html https://github.com/apache/zookeeper https://spark.apache.org/docs/latest/spark-standalone.html#high-availability" }, { "title": "(Python) 정규표현식 메타 문자 정리", "url": "/posts/post230212/", "categories": "Python", "tags": "Python", "date": "2023-02-12 19:00:00 +0900", "snippet": "1. [ ] 문자 클래스로 만들어지는 정규식은, [ ]로 둘러쌓인 내부의 문자열과 매치되는 것이라는 의미import re# r은 Raw String (원시 문자열)을 나타내는 접두사 # 파이썬에서 Raw String은 백슬래시 \\를 이스케이프 시키지 않고 그대로 사용할 수 있도록 해줌pattern = r&#39;[aiueo]&#39;strings = [&#39;apple&#39;, &#39;banana&#39;, &#39;aaii&#39;, &#39;bbb&#39;, &#39;ccc&#39;]for string in strings: if re.search(pattern, string): result = re.findall(pattern, string) print(f&quot;&#39;{string}&#39; matches the pattern. \\n {result}&quot;) else: print(f&quot;&#39;{string}&#39; does not match the pattern.&quot;)‘apple’ matches the pattern.[‘a’, ‘e’]‘banana’ matches the pattern.[‘a’, ‘a’, ‘a’]‘aaii’ matches the pattern.‘banana’ matches the pattern.[‘a’, ‘a’, ‘a’]‘aaii’ matches the pattern.[‘a’, ‘a’, ‘i’, ‘i’]‘bbb’ does not match the pattern.‘ccc’ does not match the pattern. 자주 사용되는 문자클래스는 아래와 같이 별도의 표기법으로 사용될 수있음 import repattern = r&#39;[\\d]&#39; strings = [&#39;a&#39;, &#39;2a&#39;, &#39;3&#39;, &#39;aaa&#39;]for string in strings: if re.search(pattern, string): result = re.findall(pattern, string) print(f&quot;&#39;{string}&#39; matches the pattern. \\n {result}&quot;) else: print(f&quot;&#39;{string}&#39; does not match the pattern.&quot;)‘a’ does not match the pattern.‘2a’ matches the pattern.[‘2’]‘3’ matches the pattern.[‘3’]‘aaa’ does not match the pattern. 문자클래스 내부에서 쓰이는 ^ 는 뒤에서 알아볼 메타문자와는 다른의미인, not의 의미를 가지고 있음import repattern = r&#39;[^aiueo]&#39; strings = [&#39;apple&#39;, &#39;banana&#39;, &#39;aaii&#39;, &#39;bbb&#39;, &#39;ccc&#39;]for string in strings: if re.search(pattern, string): # a,i,u,e,o가 아닌 모든 문자를 찾음. 있으면 참 result = re.findall(pattern, string) print(f&quot;&#39;{string}&#39; matches the pattern. \\n {result}&quot;) else: print(f&quot;&#39;{string}&#39; does not match the pattern.&quot;)‘apple’ matches the pattern.[‘p’, ‘p’, ‘l’]‘banana’ matches the pattern.[‘b’, ‘n’, ‘n’]‘aaii’ does not match the pattern.‘bbb’ matches the pattern.[‘b’, ‘b’, ‘b’]‘ccc’ matches the pattern.[‘c’, ‘c’, ‘c’]2. . (Dot) .(Dot) 은 줄바꿈 문자인 \\n을 제외한 모든 하나의 문자와 매치되는 것을 의미import repattern = r&#39;a.b&#39; strings = [&#39;aasdfb&#39;, &#39;asb&#39;, &#39;a2b&#39;, &#39;sdfba&#39;, &#39;ab&#39;]for string in strings: if re.search(pattern, string): result = re.findall(pattern, string) print(f&quot;&#39;{string}&#39; matches the pattern. \\n {result}&quot;) else: print(f&quot;&#39;{string}&#39; does not match the pattern.&quot;)‘aasdfb’ does not match the pattern.‘asb’ matches the pattern.[‘asb’]‘a2b’ matches the pattern.[‘a2b’]‘sdfba’ does not match the pattern.‘ab’ does not match the pattern.import repattern = r&#39;a...b&#39; strings = [&#39;aasdfb&#39;, &#39;asb&#39;, &#39;a2b&#39;, &#39;sdfba&#39;, &#39;ab&#39;]for string in strings: if re.search(pattern, string): result = re.findall(pattern, string) print(f&quot;&#39;{string}&#39; matches the pattern. \\n {result}&quot;) else: print(f&quot;&#39;{string}&#39; does not match the pattern.&quot;)‘aasdfb’ matches the pattern.[‘asdfb’]‘asb’ does not match the pattern.‘a2b’ does not match the pattern.‘sdfba’ does not match the pattern.‘ab’ does not match the pattern.3. ***** *는 반복을 나타내는 메타문자로써, 해당 메타문자 앞의 글자가 0번이상 반복되는 모든 문자열과 매치import repattern = r&#39;go*gle&#39; strings = [&#39;ggle&#39;, &#39;gogle&#39;, &#39;google&#39;, &#39;gooooogle&#39;, &#39;goooooog&#39;]for string in strings: if re.search(pattern, string): result = re.findall(pattern, string) print(f&quot;&#39;{string}&#39; matches the pattern. \\n {result}&quot;) else: print(f&quot;&#39;{string}&#39; does not match the pattern.&quot;)‘ggle’ matches the pattern.[‘ggle’]‘gogle’ matches the pattern.[‘gogle’]‘google’ matches the pattern.[‘google’]‘gooooogle’ matches the pattern.[‘gooooogle’]‘goooooog’ does not match the pattern.4. + +는 *과 같은 반복을 나타내는 메타문자. *는 다르게 앞의 글자가 0번을 제외한, 1번이상 반복되는 모든 문자열과 매치import repattern = r&#39;go+gle&#39; strings = [&#39;ggle&#39;, &#39;gogle&#39;, &#39;google&#39;, &#39;gooooogle&#39;, &#39;goooooog&#39;]for string in strings: if re.search(pattern, string): result = re.findall(pattern, string) print(f&quot;&#39;{string}&#39; matches the pattern. \\n {result}&quot;) else: print(f&quot;&#39;{string}&#39; does not match the pattern.&quot;)‘ggle’ does not match the pattern.‘gogle’ matches the pattern.[‘gogle’]‘google’ matches the pattern.[‘google’]‘gooooogle’ matches the pattern.[‘gooooogle’]‘goooooog’ does not match the pattern.5. {m,n} {m,n}또한 반복을 나타내는 메타문자. 위와는 다르게 반복횟수를 m과 n으로 정할 수 있음. 즉, 앞의 문자가 m번 이상 n번이하 반복되는 모든 문자열과 매치import repattern = r&#39;go{1,3}gle&#39; strings = [&#39;ggle&#39;, &#39;gogle&#39;, &#39;google&#39;, &#39;gooooogle&#39;, &#39;goooooog&#39;]for string in strings: if re.search(pattern, string): result = re.findall(pattern, string) print(f&quot;&#39;{string}&#39; matches the pattern. \\n {result}&quot;) else: print(f&quot;&#39;{string}&#39; does not match the pattern.&quot;)‘ggle’ does not match the pattern.‘gogle’ matches the pattern.[‘gogle’]‘google’ matches the pattern.[‘google’]‘gooooogle’ does not match the pattern.‘goooooog’ does not match the pattern.6. ? ? 는 앞의 문자가 0~1번 반복되는 모든 문자열과 매치import repattern = r&#39;go?gle&#39; strings = [&#39;ggle&#39;, &#39;gogle&#39;, &#39;google&#39;, &#39;gooooogle&#39;, &#39;goooooog&#39;]for string in strings: if re.search(pattern, string): result = re.findall(pattern, string) print(f&quot;&#39;{string}&#39; matches the pattern. \\n {result}&quot;) else: print(f&quot;&#39;{string}&#39; does not match the pattern.&quot;)‘ggle’ matches the pattern.[‘ggle’]‘gogle’ matches the pattern.[‘gogle’]‘google’ does not match the pattern.‘gooooogle’ does not match the pattern.‘goooooog’ does not match the pattern.7. | 해당 메타문자는 a b 와 같은 형식으로 사용되며 a 또는 b와 매치되는 문자열을 반환 import repattern = r&#39;b|s&#39; strings = [&#39;aasdfb&#39;, &#39;asb&#39;, &#39;a2b&#39;, &#39;sdfba&#39;, &#39;ab&#39;]for string in strings: if re.search(pattern, string): result = re.findall(pattern, string) print(f&quot;&#39;{string}&#39; matches the pattern. \\n {result}&quot;) else: print(f&quot;&#39;{string}&#39; does not match the pattern.&quot;)‘aasdfb’ matches the pattern.[’s’, ‘b’]‘asb’ matches the pattern.[’s’, ‘b’]‘a2b’ matches the pattern.[‘b’]‘sdfba’ matches the pattern.[’s’, ‘b’]‘ab’ matches the pattern.[‘b’]8. ^ ^는 문자열의 맨처음을 의미하는 메타문자. 문자클래서 내부에서 not의 의미로 사용되기도 하므로 혼동되지 않도록 주의. 정규식으로 찾고자 하는 문자열의 앞에 입력import repattern = r&#39;^apple&#39;strings = [&#39;apple&#39;, &#39;banana&#39;, &#39;apple mango&#39;]for string in strings: if re.search(pattern, string): result = re.findall(pattern, string) print(f&quot;&#39;{string}&#39; matches the pattern. \\n {result}&quot;) else: print(f&quot;&#39;{string}&#39; does not match the pattern.&quot;)‘apple’ matches the pattern.[‘apple’]‘banana’ does not match the pattern.‘apple mango’ matches the pattern.[‘apple’]import repattern = r&#39;[^apple]&#39; # strings = [&#39;apple&#39;, &#39;banana&#39;, &#39;apple mango&#39;]for string in strings: if re.search(pattern, string): # a,p,l,e가 아닌 모든 문자를 찾음. 있으면 참 result = re.findall(pattern, string) print(f&quot;&#39;{string}&#39; matches the pattern. \\n {result}&quot;) else: print(f&quot;&#39;{string}&#39; does not match the pattern.&quot;)‘apple’ does not match the pattern.‘banana’ matches the pattern.[‘b’, ‘n’, ‘n’]‘apple mango’ matches the pattern.[’ ‘, ‘m’, ‘n’, ‘g’, ‘o’]9. $ $는 ^와 반대로 문자열의 맨 마지막을 의미하는 메타문자. ^와는 다르게 매치할 문자열의 뒤에 입력import repattern = r&#39;apple$&#39;strings = [&#39;apple&#39;, &#39;banana&#39;, &#39;apple mango&#39;]for string in strings: if re.search(pattern, string): result = re.findall(pattern, string) print(f&quot;&#39;{string}&#39; matches the pattern. \\n {result}&quot;) else: print(f&quot;&#39;{string}&#39; does not match the pattern.&quot;)‘apple’ matches the pattern.[‘apple’]‘banana’ does not match the pattern.‘apple mango’ does not match the pattern.10. \\A, \\Z \\A는 기본적으로 ^와 같이 문자열의 맨 처음을 의미하는 메타문자 하지만 다른점이 있다면 우리가 re.MULTILINE이라는 컴파일 옵션을 사용했을 때, ^는 라인별 문자열의 맨처음을 의미하지만 \\A는 라인별이 아닌 문자열 전체에서의 맨 처음을 의미import rep = re.compile(&quot;^python\\s\\w+&quot;)data = &quot;&quot;&quot;python onelife is too shortpython twoyou need pythonpython three&quot;&quot;&quot;print(p.findall(data))[‘python one’]^ 메타 문자를 문자열 전체의 처음이 아니라 각 라인의 처음으로 인식시키고 싶은 경우,import rep = re.compile(&quot;^python\\s\\w+&quot;, re.MULTILINE)data = &quot;&quot;&quot;python onelife is too shortpython twoyou need pythonpython three&quot;&quot;&quot;print(p.findall(data))[‘python one’, ‘python two’, ‘python three’] \\Z는 기본적으로 $와 같이 문자열의 맨 뒤를 의미하는 메타문자 하지만 다른점은 \\A와 같이, re.MULTILINE이라는 컴파일 옵션을 사용했을 때, $는 라인별 문자열의 맨뒤를 의미하지만 \\Z는 라인별이 아닌 문자열 전체에서의 맨 뒤를 의미" }, { "title": "(AWS) AWS 기초 개념", "url": "/posts/post230102/", "categories": "AWS", "tags": "AWS", "date": "2023-01-02 19:00:00 +0900", "snippet": " Overview 클라우드 업계 구조 클라우드 업계는 크게 2가지의 Provider로 이뤄져 있음. 클라우드에 대한 리소스, 인프라를 직접적으로 제공해주는 CSP(Cloud Service Provider), 관련 리소스를 받아서 직접 활용하고 구축해서 운영관리까지 해주는 MSP(Managed Service Provider)로 나눠짐. 간단히 말해 CSP와 MSP가 서로 협력해서 안정적인 클라우드 서비스의 운영지원을 해주는 것입니다. AWS 리전 AWS가 전 세계에서 데이터 센터를 클러스터링하는 물리적 위치를 말함 더 높은 가용성, 확장성, 내결함성을 위해서 다중의 가용영역으로 구성 어플리케이션과 데이터는 다른 가용영역 간에 실시간 복제가 되며 일관성을 가짐 콘텐츠 전송 네트워크 (CDN) 최종 사용자에게 더 짧은 지연시간으로 콘텐츠를 전송하기 위해 Amazon CloudFront는 310+개의 Points of Presence 글로벌 네트워크를 이용 CloudFront 사용 사례 미디어 스트리밍 웹사이트 정적 리소스 대용량 파일 다운로드 전체 웹사이트 모바일 앱(API) Network AWS VPC(Virtual Private Cloud) 사용자가 정의한 가상의 네트워크 공간 한 리전의 모든 가용영역에 거쳐 존재함 리전마다 최소 두개의 가용영역이 존재함 AWS 계정을 생성하면 default VPC가 각 리전당 하나씩 생성됨 완전한 네트워크 제어 가능 IP 범위 Subnet Route Table Network ACL, 보안 그룹 다양한 게이트웨이 VPC내의 모든 EC2 인스턴스들은 사설 IP가 부여됨 개별 인스턴스에 공인 IP 할당 가능 (Public IP/Elastic IP) VPC 생성 순서 리전 선택 및 IP주소 범위 설정 CIDR 블록 설정 Classless Inter-DomainRouting 예: 172.31.0.0/16 RFC 1918에 정의된 사설 IP 대역 사용 권고 VPC CIDR은 생성 후 변경 불가능 VPC의 네트워크 범위는 /16~/28까지 가능 향후 직접 연결할 가능성이 있는 네트워크와 주소가 중복되지 않도록 할당 권고 On-premises network와 연동을 고려 AWS 내 리전 간 확장 인터넷 게이트웨이 생성 가용 영역 내에 필요한 서브넷 정의 라우팅 구성 인터넷이 목적지인 경우 : 인터넷 게이트웨이 VPC CIDR 주소가 목적지인 경우 : Local VPC로 송수신되는 트래픽 제어 VPC간 연결 방법 인터넷 게이트웨이를 통한 연결 동일 리전 VPC peering 서로 다른 리전 VPC peering VPC peering 구성 전에 알아두어야 할 것들 같은 리전의 VPC Peer에서 Security Group 참조 가능 DNS Host Name을 참조해서, Private IP 주소 반환 가능 IPv4/v6 주소 모두 Peering 가능 IP 주소 대역 중복 할당 불가능 양방향 Peering 불가능 On- Prem 네트워크 연결 연결옵션 AWS site-to-site VPN setup - VGW, CGW 1xVPN Connection = 2xVPN Tunnels 1xVPN Tunnel = 1.25Gbps AWS Direct Connect (물리적 연결) AWS Transit Gateway 간편한 멀티 VPC 접근 모델 VPC peering의 근본적인 문제를 해결 Scale 문제 발생과 관리의 복잡성 AWS VPC Endpoint 완전 관리형 서비스 연동 방법 VPC flow logs Amazone CloudWatch Logs / Amazon S3 성능/응답시간에 영향 없음 VPC, Subnet, ENI에 적용 가능 허용 거부, 모든 트래픽 선택 가능 VPC traffic mirroring UDP listener를 기반으로 특정 ENI, NLB로 트래픽 copy 전송 특정 트래픽만 Copy 전송 Compute EC2 (Amazon Elastic Compute Cloud) 안전하고 크기 조정이 가능한 컴퓨팅 용량을 클라우드에서 제공하는 웹 서비스 AMI (Amazon Machine Image) 인스턴스를 구동할 때 필요한 정보를 제공 하나의 AMI로 여러 개의 인스턴스를 시작 가능 AMI에는 다음과 같은 정보가 있음 루트 볼륨을 구성하는 템플릿 (OS, 어플리케이션 등) 인스턴스에 연결되는 볼륨의 블록 디바이스 매핑 EC2 인스턴스 스토어 인스턴스의 로컬 저장소 임시 데이터 저장소 데이터 복제 미 지원 (by default) Snapshot 미 지원 SSD 또는 HDD Amazon EBS 블록 스토리지 API를 이용하여 생성, 연결 수정 워크로드에 따라 스토리지 및 컴퓨팅 선택 하나의 EBS 볼륨은 하나의 인스턴스에만 연결 마그네틱 및 SSD 기반 볼륨 유형 선택 스냅 샷 지원 : 특정 시점 백업 EC2 인스턴스 수명 주기 EC2 인스턴스 표기법 인스턴스 패밀리 : 타입 의미, M은 범용 인스턴스는 하나 이상의 추가 기능을 가질 수 있음 Elastic Load Balancing 애플리케이션 트래픽을 Amazon EC2 인스턴스, 컨테이너, IP 주소, Lambda 함수와 같은 여러 대상에 자동으로 분산 EC2 Auto Scaling 변화하는 수요에 동적으로 대응하고 비용을 최적화 ECS (Elastic Container Service) 여러 컨테이너를 EC2에서 중앙집중식으로 관리하는 서비스 Docker 컨테이너를 여러 EC2 인스턴스에 분산 배치할 수 있는 서비스 (모든 규모의 클러스터를 쉽게 관리) 임시 계산 처리에 긴 러닝 처리에도 대응 ELB 연계 등 각종 AWS 서비스와의 친화성 AWS Fargate 컨테이너를 위한 serverless compute engine AWS에 의해 관리되므로 프로비저닝, 확장 또는 관리할 EC2 인스턴스가 없음 탄력적으로 구성되므로 원활하게 확장 및 축소 사용한 만큼만 지불 배치 그룹 워크로드의 요구 사항을 충족하도록 독립적 인스턴스의 그룹의 배치에 영향 클러스터 : 짧은 네트워크 지연 시간, 높은 네트워크 처리량 또는 둘 다의 이점을 활용할 수 있는 애플리케이션에 권장 파티션 : 애플리케이션에 대한 상관 관계가 있는 하드웨어 장애 가능성을 줄이는 데 도움 분산형 : 두 파티션이 동일한 랙을 공유하지 않으므로 애플리케이션 내 하드웨어 장애의 영향을 격리 Amazon Cloud Watch AWS 리소스 및 애플리케이션의 모니터링 및 관찰 기능 로그, 지표 및 이벤트 형태로 모니터링 및 운영 데이터를 수집 AWS 리소스, 애플리케이션 및 서비스에 대한 통합 뷰 이상 동작 감지 경보 설정 로그와 지표 시각화 AWS systems manager 규모에 맞게 안전하게 운영 패치 및 구성의 준수 유지 여러 계정 및 지역에서 자동화 브라우저 및 CLI를 통해 Amazon EC2 인스턴스에 연결, 여러 계정에서 소프트웨어 인벤토리 추적 속도 제어를 통해 인스턴스에 에이전트를 안전하게 설치 EC2 Image Builder 보다 쉽고 빠르게 안전한 OS 이미지 구축 및 유지 이미지를 생성, 저장 및 공유하는데 사용되는 기본 AWS 리소스 비용 외에는 무료로 제공 Storage 스토리지 타입 블록 스토리지 : 데이터를 일정 크기의 블록으로 나누어 저장 호스트에서 파일 시스템을 생성, Storage Area Network (SAN) 파일스토리지 : 디렉터리 구조로 파일을 저장 스토리지단에서 파일 시스템을 생성, Netwrok Attached Storage (NAS) 오브젝트 스토리지 : REST 기반의 API 호출을 통해 데이터에 접근, HTTP 프로토콜 Amazon Elastic Block Store (EBS) EC2에서 사용하도록 설계도니 영구 지속 블록 스토리지 서비스 EBS 볼륨을 활용하여 파일 시스템을 생성하거나 블록 디바이스 자체로 활용 고성능 대규모 데이터 처리와 트랜잭션 집약적인 워크로드에 사용 데이터베이스, 빅데이터분석, 엔터프라이즈 애플리케이션과 같은 중요한 업무에 활용 고가용성, 안전성, 확장성, 성능, 백업 Amazon EBS Multi-Attach 여러 서버에서 동일한 공간에 있는 파일을 Access 해야 하는경우 서버, 스토리지, 네트워크 등의 장애 발생시에도 지속적인 서비스가 필요한 경우 Block 기반의 database에서 가용성을 확보하기 위한 목적 고성능이 필요한 HPC(Hight Performance Computing) 시스템 Amazon Elastic File System (EFS) 안정적이고 비용 효과적인 클라우드 네이티브 NFS 파일 스토리지 서비스 탄력적인 확장, 고가용성, 손쉬운 운영, 고성능 제공, 비용 최적화, 하이브리드 구성 백업 EFS 파일 시스템은 AWS Backup 서비스를 이용해 데이터를 안전하게 백업하고 복원 가능 AWS Backup은 스케쥴링 정책에 따라 자동으로 데이터를 백업하고 데이터 보유 기간을 지정 AWS Backup은 두가지 종류의 스토리지 클래스를 제공 개별 파일과 디렉토리에 대한 복구 기능 지원 서로 다른 리전간 백업도 지원 Amazon FSx for Windows File Server 윈도우 서버에 구축되는 확장 가능한 완전 관리형 파일 스토리지 서비스 완전 관리형, 다수의 가용 영역 사용, 윈도우 서버에서 구축, 윈도우 파일시스템과 호환, Active Directory 사용, 비용 효율 파일 레벨 복구 가능 Amazon FSx for Lustre 컴퓨팅 워크로드를 위한 경제적인 고성능 스토리지 완전 관리형, POSIX 파일시스템, 고성능 제공, HPC, 머신러닝 등 고성능 워크로드에 적합, 유연한 데이터 프로세싱 옵션 제공, 온프레미스 혹은 다른 AWS 서비스에서 엑세스 가능 Amazon S3 무제한에 가까운 스토리지 용량과 오브젝트 Amazon S3 기반의 데이터 레이크 구축 S3 Intelligent-Tiering를 통한 자동화된 비용 절감 S3 Glacier Deep Archive를 사용해 비용 효율적인 스토리지 저장 데이터는 3곳 이상의 물리적인 분리된 가용 영역에 저장 " }, { "title": "(Network) CIDR(Classless Inter-Domain Routing)", "url": "/posts/post220901/", "categories": "Network", "tags": "Network", "date": "2022-09-01 13:00:00 +0900", "snippet": "IP Address Class 원래 32비트 IPv4 주소는 호스트가 연결되어있는 특정 네트워크를 가리키는 네트워크 영역과 해당 네트워크 내에서 호스트의 주소를 가리키는 나머지 영역으로 구분되어 있습니다. Network Address:그룹(네트워크를 식별하기 위한) Host Address: 개인(네트워크의 호스트 컴퓨터를 식별하기 위한 것) 클래스는 총 5가지의(A,B,C,D,E)클래스로 나누어져 있습니다. 하지만 D,E클래스는 멀티캐스트용과 연구 또는 개발용 미래를 위한 예약 IP이므로 보통 사용되지 않습니다. A Class 0xxxxxxx. xxxxxxxx. xxxxxxxx. xxxxxxxx Network Address Host Address Host Address Host Address B Class 10xxxxxx. xxxxxxxx. xxxxxxxx. xxxxxxxx Network Address Network Address Host Address Host Address C Class 110xxxxx. xxxxxxxx. xxxxxxxx. xxxxxxxx Network Address Network Address Network Address Host Address A Class 0 ~ 127로 Network Address가 시작되며 Host Address는 (2^24)개를 가질 수 있습니다. 0.0.0.0의 경우는 자체 네트워크를 의미 해서 빠지며 127.0.0.0~127.255.255.255는 루프백 ip address(자기 자신을 가리키기 위한 목적으로 쓰기 위해 예약된 IP 주소입니다. 로컬호스트의 주소라고 생각하시면 됩니다.)로 사용하기때문에 사용하실 수 없습니다. B Class 128.0~191.255로 Network Address가 시작되며 Host Address는 총 2^16개를 가질 수 있습니다. C Class 192.0.0~223.255.255로 Network Address가 시작되며 Host Address는 총 2^8개를 가질 수 있습니다. 0이면 A Class, 10이면 B Class, 110이면 C Class로 생각해주세요. 십진수로 바꾸어 보시면 왜 앞이 0,10,110인지 좀더 쉽게 이해 하실 수 있습니다.클래스 A 0.0.0.0 = 00000000.00000000.00000000.00000000 127.255.255.255 = 01111111.11111111.11111111.11111111클래스 B 128.0.0.0 = 10000000.00000000.00000000.00000000 191.255.255.255 = 10111111.11111111.11111111.11111111클래스 C 192.0.0.0 = 11000000.00000000.00000000.00000000 223.255.255.255 = 11011111.11111111.11111111.11111111Subnetting, SupernettingSubnetting Subnet(부분망) 이란 하나의 IP 네트워크 주소를 네트워크 내부에서 적절히 분할하여 다수의 상호 연결된 하부 네트워크로 나누어 사용하는 방법 Network Address Host Address   Network ID Subnet Address Host Address Subnetmask Network Address 와 Host Address를 구별하기 쉽게 만들어주는 방법 네트워크 부분에 해당하는 비트는 1, 호스트 부분에 해당하는 비트는 0으로 쓴다. Class A의 디폴트 서브넷 마스크는 1111 1111 . 0000 0000 . 0000 0000 . 0000 00 00 = 255 . 0 . 0 . 0 Class B의 디폴트 서브넷 마스크는 1111 1111 . 1111 1111 . 0000 0000 . 0000 00 00 = 255 . 255 . 0 . 0 Subnetting을 하는 방법 할당받은 Classful Network를 이진수로 변환합니다. 네트워크를 나눌 조건에 맞는 이진수를 찾아 Subnetmask를 추가합니다. 추가된 Subnetmask를 순서대로 나열합니다. 순서대로 나열된 이진수를 다시 십진수로 변환하여 재할당합니다. 서브넷 마스크의 표현은 IP 주소 끝에 ‘/’문자를 쓰고, 다음에 네트워크 부분에 해당하는 비트개수를 쓴다. (Prefix 표기법) 예를 들어, ‘192.168.0.3’이라는 IP주소의 서브넷 마스크가 ‘1111 1111 . 1111 1111 . 1111 1111 .0000 0000 = 255 . 255 . 0 . 0’ 이라면 ‘192.168.0.3/24’라고 쓴다. 더 자세한 예를 들면, (디폴트 서브넷 마스크가 아닌 경우) IP주소 서브넷 마스크 표현 192.168.0.3 1111 1111 . 1111 1111 . 1111 1111 . 0000 0000 = 255.255.255.0 192.168.0.3/24 192.168.0.3 1111 1111 . 1111 1111 . 1111 1111 . 1000 0000 = 255.255.255.128 192.168.0.3/25 192.168.0.3 1111 1111 . 1111 1111 . 1111 1111 . 1100 0000 = 255.255.255.192 192.168.0.3/26 Supernetting subnet의 반대 개념으로 , Network를 합치는 것입니다. Network ID 부분을 줄이고 , Host ID 부분을 늘립니다. Network 규모는 커지고 , 소속된 Host 수는 많아집니다. Supernetting으로 인해 서로 다른 Network 영역 이었기 때문에 routing 하던 것을 같은 Network 영역으로 만들어지기 때문에 switching하게 됩니다.198.168.32.0/24 198.168.32.0~198.168.32.255 = 256198.168.33.0/24 198.168.33.0~198.168.33.255 = 256198.168.34.0/24 198.168.34.0~198.168.34.255 = 256198.168.35.0/24 198.168.35.0~198.168.35.255 = 256198.168.32.0/22 198.168.32.0~198.168.35.255 = 1024(256*4)와 같은 방식으로 256개를 할당 받은 4개를 하나로 합치는 것입니다. 뒤의 “/”부분은 Network Address를 나타내는 개수라고 생각하시면 됩니다.CIDR(Classless Inter-Domain Routing), VLSM(Variable Length Subnet Mask) CIDR 기존의 IP 주소 할당 방식이었던 네트워크 클래스를 대체한 방식입니다. 슈퍼넷팅을 수행하므로 라우팅 테이블의 정보량이 줄어듭니다. CIDR는 IP Address의 영역을 나눌 때 기존 방식보다 유연하게 자신이 원하는 Network Address와 Host Address를 나눌 수 있습니다. VLSM 서브넷팅을 여러번 수행하는 기법이다. 일반 서브넷팅처럼 모두 동일한 크기의 서브넷을 만드는 것이 아니라 서로 다른 크기의 서브넷을 만든다. 예제 우리회사(Main Network 1개)에 8개의 부서(subnet 8개 필요)가 있습니다. 각 부서별로 Network를 분리하여야 합니다. 풀이 Main Network : 200.1.1 /24 Subnet-bit = 3bit = 2^3 = 8개 subnet Host-bit = 8bit - 3bit = 5bit = 2^5-2(첫주소 + 끝주소) = 30 영업부 200.1.1.0 ~ 200.1.1.31 1100 1000 . 0000 0001 . 0000 0001 . 000    0 0000 [200.1.1.0] ~ 1100 1000 . 0000 0001 . 0000 0001 . 000    1 1111 [200.1.1.31] Netmask : 1111 1111 . 1111 1111 . 1111 1111 . 111    0 0000 [255.255.255.224] Wildcard : 0000 0000 . 0000 0000 . 0000 0000 . 000    1 1111 [0.0.0.31] →200.1.1.0/27 첫 시작 주소 : 200.1.1.0/27 → 영업부 대표주소 마지막 주소 : 200.1.1.31/27 → 영업부 direct broadcast address 영업부 PC 주소 : 200.1.1.1 ~ 200.1.1.30 관리부 200.1.1.32 ~ 200.1.1.63 1100 1000 . 0000 0001 . 0000 0001 . 001    0 0000 [200.1.1.32] ~ 1100 1000 . 0000 0001 . 0000 0001 . 001    1 1111 [200.1.1.63] Netmask : 1111 1111 . 1111 1111 . 1111 1111 . 111    0 0000 [255.255.255.224] Wildcard : 0000 0000 . 0000 0000 . 0000 0000 . 000    1 1111 [0.0.0.31] →200.1.1.32/27 첫 시작 주소 : 200.1.1.32/27 → 관리부 대표주소 마지막 주소 : 200.1.1.63/27 → 관리부 direct broadcast address 관리부 PC 주소 : 200.1.1.33 ~ 200.1.1.62 전산부 200.1.1.64 ~ 200.1.1.95 1100 1000 . 0000 0001 . 0000 0001 . 010    0 0000 [200.1.1.64] ~ 1100 1000 . 0000 0001 . 0000 0001 . 010    1 1111 [200.1.1.95] Netmask : 1111 1111 . 1111 1111 . 1111 1111 . 111    0 0000 [255.255.255.224] Wildcard : 0000 0000 . 0000 0000 . 0000 0000 . 000    1 1111 [0.0.0.31] →200.1.1.64/27 첫 시작 주소 : 200.1.1.64/27 → 전산부 대표주소 마지막 주소 : 200.1.1.95/27 → 전산부 direct broadcast address 전산부 PC 주소 : 200.1.1.65 ~ 200.1.1.94 . . . 구매부 200.1.1.224 ~ 200.1.1.255 1100 1000 . 0000 0001 . 0000 0001 . 111    0 0000 [200.1.1.224] ~ 1100 1000 . 0000 0001 . 0000 0001 . 111    1 1111 [200.1.1.255] Netmask : 1111 1111 . 1111 1111 . 1111 1111 . 111    0 0000 [255.255.255.224] Wildcard : 0000 0000 . 0000 0000 . 0000 0000 . 000    1 1111 [0.0.0.31] →200.1.1.224/27 첫 시작 주소 : 200.1.1.224/27 → 구매부 대표주소 마지막 주소 : 200.1.1.255/27 → 구매부 direct broadcast address 구매부 PC 주소 : 200.1.1.225 ~ 200.1.1.254 네트워크 주소가 192.168.0.0/24인 네트워크를 사용자 60명이 사용할 수 있도록 서브넷팅하시오 풀이 y = 2^x-2 에서 x=6일 때 y=62 (62라는 숫자는 60명이 가장 적합하게 들어갈 공간) 첫번째 서브넷 : 192.168.0.(00)00 0000 ~ 192.168.0.(00)11 1111 ~&amp;gt; 192.168.0.0/26 두번째 서브넷 : 192.168.0.(01)00 0000 ~ 192.168.0.(01)11 1111 ~&amp;gt; 192.168.0.64/26 세번째 서브넷 : 192.168.0.(10)00 0000 ~ 192.168.0.(10)11 1111 ~&amp;gt; 192.168.0.128/26 네번째 서브넷 : 192.168.0.(11)00 0000 ~ 192.168.0.(11)11 1111 ~&amp;gt; 192.168.0.192/26 이렇게 총 4개의 서브넷이 생성된다. ※ 참고로 각각의 서브넷에서 2개씩은 사용할 수 없음 (네트워크 주소와 브로드캐스트 주소) 네트워크 주소가 192.168.0.0/24인 네트워크를 8개의 네트워크로 서브넷팅하시오 풀이 y = 2^x 에서 x=3일 때 y=8 네트워크 부분 비트수인 x를 구했으므로 네트워크 부분 비트수는 24+3 = 27 즉, 192.168.0.0/27로 서브넷팅하면 된다. 첫번째 서브넷 : 192.168.0.(000)0 0000 ~ 192.168.0.(000)1 1111 ~&amp;gt; 192.168.0.0/27 두번째 서브넷 : 192.168.0.(001)0 0000 ~ 192.168.0.(001)1 1111 ~&amp;gt; 192.168.0.64/27 세번째 서브넷 : 192.168.0.(010)0 0000 ~ 192.168.0.(010)1 1111 ~&amp;gt; 192.168.0.128/27 네번째 서브넷 : 192.168.0.(011)0 0000 ~ 192.168.0.(011)1 1111 ~&amp;gt; 192.168.0.192/27 다섯번째 서브넷 : 192.168.0.(100)0 0000 ~ 192.168.0.(100)1 1111 ~&amp;gt; 192.168.0.0/27 여섯번째 서브넷 : 192.168.0.(101)0 0000 ~ 192.168.0.(101)1 1111 ~&amp;gt; 192.168.0.64/27 칠곱번째 서브넷 : 192.168.0.(110)0 0000 ~ 192.168.0.(110)1 1111 ~&amp;gt; 192.168.0.128/27 여덟번째 서브넷 : 192.168.0.(111)0 0000 ~ 192.168.0.(111)1 1111 ~&amp;gt; 192.168.0.192/27 192.168.0.0/24 ~ 192.168.3.0/24 인 네트워크들을 하나의 네트워크로 슈퍼넷팅하시오 풀이 1100 0000 . 1010 1000 . 0000 0000 . 0000 0000 = 192.168.0.0 1100 0000 . 1010 1000 . 0000 0001 . 0000 0000 = 192.168.1.0 1100 0000 . 1010 1000 . 0000 0010 . 0000 0000 = 192.168.2.0 1100 0000 . 1010 1000 . 0000 0011 . 0000 0000 = 192.168.3.0 1111 1111 . 1111 1111 . 1111 1100 . 0000 0000 = 255.255.252.0 (서브넷 마스크) ~&amp;gt; 공통 부분을 1로 처리함 192.168.0.0/22 ~&amp;gt; 슈퍼넷팅을 수행한 네트워크의 네트워크 주소 2^10-2 = 1022 ~&amp;gt; 사용가능한 호스트 수 이렇게 총 1022개의 호스트를 수용가능한 하나의 네트워크(192.168.0.0/22)가 만들어진다. 192.168.0.0/24인 네트워크가 각각 60명, 30명, 30명의 서브넷이 필요하다고 한다. VLSM기법에 의해 서브넷팅 하시오. 풀이 먼저 이렇게 총 4개의 서브넷을 생성한다. x=6일 때 y=62 첫번째 서브넷 : 192.168.0.(00)00 0000 ~ 192.168.0.(00)11 1111 ~&amp;gt; 192.168.0.0/26 두번째 서브넷 : 192.168.0.(01)00 0000 ~ 192.168.0.(01)11 1111 ~&amp;gt; 192.168.0.64/26 세번째 서브넷 : 192.168.0.(10)00 0000 ~ 192.168.0.(10)11 1111 ~&amp;gt; 192.168.0.128/26 네번째 서브넷 : 192.168.0.(11)00 0000 ~ 192.168.0.(11)11 1111 ~&amp;gt; 192.168.0.192/26 두번째 서브넷을 다시 한 번 더 서브넷팅한다. x=5일 때, y=30 두번째 서브넷의 첫번째 서브넷 : 192.168.0.01(0)0 0000 ~ 192.168.0.01(0)1 1111 ~&amp;gt; 192.168.0.64/27 두번째 서브넷의 두번째 서브넷 : 192.168.0.01(1)0 0000 ~ 192.168.0.01(1)1 1111 ~&amp;gt; 192.168.0.96/27 결론적으로 첫번째 서브넷에 60명이 들어갈 수 있고, 두번째 서브넷의 첫번째 서브넷에 30명, 두번째 서브넷의 두번째 서브넷에 30명이 들어갈 수 있다. " }, { "title": "리다이렉션, 2&gt;&amp;1, /dev/null", "url": "/posts/post220805/", "categories": "Linux", "tags": "Linux", "date": "2022-08-05 19:30:00 +0900", "snippet": " 리다이렉션(redirection) 리다이렉션은 컴퓨팅에서 표준 스트림을 사용자 지정 위치로 우회할 수 있는 다양한 유닉스 셸을 포함한 대부분의 명령어 인터프리터에 일반적인 명령. 표준 스트림에 대한 방향을 지정한다고 보면 이해하는데 도움이 될 것 null 장치(디바이스) null 장치(디바이스)는 기록 대상이 되는 모든 데이터를 버리지만 쓰기 작업은 성공했다고 보고하는 장치 파일 이 장치는 유닉스 계열에서는 /dev/null이라고 부르며 어떠한 프로세스에도 데이터를 제공하지 않고 그 즉시 EOF를 내보냄 일반적으로 출력이 필요 없는 경우에 리다이렉션을 이용하여 출력을 null 장치로 보내는 방법으로 자주 이용 표준 스트림 유닉스 계열의 표준 스트림은 3가지로 분류할 수 있으며 다음과 같다. 표준 입력 : stdin, 파일 디스크립터 0 표준 출력 : stdout, 파일 디스크립터 1 표준 오류 : stderr, 파일 디스크립터 2 표준 입력 리다이렉션명령어 &amp;lt; 파일 표준 입력 스트림에 대한 리다이렉션은 위와 같은 방법으로 사용 cat test.txt로 입력을 하여도 같은 결과가 나오겠지만 이는 cat에 대한 아규먼트로 동작하는 방식 위의 예제처럼 동작하는 것은 표준 입력을 cat 명령어로 리다이렉트 하여 전달한 방식표준 출력 리다이렉션명령어 &amp;gt; 파일 표준 출력 스트림에 대한 리다이렉션은 표준 출력과 반대 방향을 가리키면서 사용 cat test.txt 명령에 대한 표준 출력을 ‘test_copy.txt’ 파일로 리다이렉션 test_copy.txt 파일이 있으면 파일 내용을 지우고 새로 내용을 추가 파일이 없으면 새로 파일을 만들어서 내용을 추가명령어 &amp;gt;&amp;gt; 파일 표준 출력 스트림에 대한 리다이렉션 과정에서 파일에 내용을 지우고 새로 내용을 추가하지 않고 기존 내용 뒤에 표준 출력 내용을 추가할 경우에는 ‘&amp;gt;’대신에 ‘»‘를 사용2 &amp;gt;&amp;amp;1 &amp;amp; 의 의미 ex) nohup ${DIR}/bin/scheduler scheduler.ini &amp;gt;scheduler.out 2&amp;gt;&amp;amp;1 &amp;amp; 0, 1, 2는 각각 표준입력, 표준출력, 그리고 표준에러를 의미한다. 2는 표준 오류 출력에 대한 파일 디스크립터 번호이고, 1은 표준 출력에 대한 파일 디스크립터 번호이다. &amp;amp;는 파일 디스크립터를 가리키는 특수 기호이다. ”&amp;gt;”를 기준으로 보면 “2”를 “&amp;amp;1”로 보내라는 뜻인데, 2&amp;gt;&amp;amp;1의 의미는 표준 출력의 전달되는 곳으로 표준에러를 전달하라라는 의미이다. 만약 위와 같다면, 에러 메시지(stderr)는 scheduler.out 파일에 에러 메시지를 출력하지 않고 바고 콘솔에다가 뿌려준다. 이건 stderr이 버퍼를 이용하지 않고 에러가 생기는 즉시 바로 출력을 해주기 때문이다. 이렇게 2&amp;gt;&amp;amp;1 리다이렉션을 시켜 줌으로 인해 stderr &amp;gt; stdout 으로 출력이 되고 scheduler.out 파일에 에러 메시지가 저장이 되게 되는 것이다. 마지막 “&amp;amp;” 는 백그라운드로 실행하라는 뜻이다./dev/null 의 의미명령어 &amp;gt; /dev/null cat 명령어를 사용하여 ‘test.txt’ 내용을 표준 출력으로 터미널상에 표시하였다. 그 다음으로, &amp;gt;/dev/null 은 출력을 /dev/null로 하겠다는 뜻이다. /dev/null로 리다이렉션 하는 건 표준출력을 버리라는 뜻이다. 즉, 출력이 안보인다. 스크립트 등에서 표준 출력을 표시하고 싶지 않을 경우에 유용하게 사용할 수 있다.명령어 2&amp;gt; /dev/null 표준 출력을 버리는 방법과 마찬가지로 표준 오류 또한 null 장치와 리다이렉션을 이용하여 표시하지 않을 수 있다. 차이점은 리다이렉션에서 표준 출력이 아닌 표준 오류를 null 장치로 보내주도록 지정하는 것이다. ‘no_test.txt’라는 존재하지 않은 파일에 대해서 cat 명령를 수행하였고 파일이 없으므로 “No such file or directory”라는 에러 메시지를 출력하였다. “cat no_test.txt 2&amp;gt; /dev/null” 입력을 하게 되면 아무런 오류 메시지도 출력이 되지 않게 된다. 표준 오류를 null 장치로 리다이렉션 하였기 때문에 아무런 메시지도 표시되지 않게 된 것이다.명령어 &amp;amp;&amp;gt; /dev/null &amp;amp;&amp;gt; /dev/null은 명령의 모든 출력을 버리고, 터미널에 아무것도 표시하지 않는 것을 의미한다." }, { "title": "(Python)[백준] 카약과 강풍", "url": "/posts/post220801/", "categories": "CodingTest", "tags": "CodingTest", "date": "2022-08-01 14:23:00 +0900", "snippet": "2891번: 카약과 강풍SolutionSource Coden, s, r = map(int ,input().split())broken = list(map(int, input().split()))haveMore = list(map(int, input().split()))boats = [1] * n# 손상된 보트 -&amp;gt; 보유 보트수 -1for i in broken: boats[i-1] -= 1# 여분의 보트 -&amp;gt; 보유 보트수 +1for i in haveMore: boats[i-1] += 1for i in range(n): if boats[i] == 0: # 손상된 보트일 때(보트 보유수가 0) if i==0: # 첫 번째 순서 if boats[i+1] == 2: boats[i+1] = 1 boats[i] = 1 elif i == n-1: # 마지막 순서 if boats[i-1] == 2: boats[i-1] = 1 boats[i] = 1 else: if boats[i-1] == 2: boats[i-1] = 1 boats[i] = 1 continue if boats[i+1] == 2: boats[i+1] = 1 boats[i] = 1 continue else: continue print(boats.count(0))" }, { "title": "(Python)[백준] Line Friends(Small)", "url": "/posts/post220730/", "categories": "CodingTest", "tags": "CodingTest", "date": "2022-07-30 14:23:00 +0900", "snippet": "14588번: Line Friends (Small)SolutionSource Code# 다익스트라는 하나의 정점에서 다른 모든 정점까지의 최단거리를 구하는 알고리즘# 플로이드워셜은 한 번 실행하여 모든 노드 간 최단거리를 구할 수 있음import sysinput = sys.stdin.readlineINF = int ( 1e9 ) # 무한을 의미하는 값으로 10 억을 설정. 또는 sys.maxsizen = int(input())lines = [list(map(int, input().split())) for _ in range(n)]q = int(input())questions = [list(map(int, input().split())) for _ in range(q)]def checkOverlap(pivot, opponent): if max(pivot[0], opponent[0]) &amp;lt;= min(pivot[1], opponent[1]): return True return Falsedef makeGraph(): dist = [[INF] * n for _ in range(n)] for v in range(n): dist[v][v] = 0 for (p_idx, pivot) in enumerate(lines): for (o_idx, opponent) in enumerate(lines): if p_idx != o_idx and checkOverlap(pivot, opponent): dist[p_idx][o_idx] = 1 return distdef floyd(dist): for k in range(n): for u in range(n): for v in range(n): dist[u][v] = min(dist[u][v], dist[u][k] + dist[k][v])def solution(): dist = makeGraph() floyd(dist) for frm, to in questions: cost = dist[frm-1][to-1] ans = cost if cost != INF else -1 print(ans)solution()" }, { "title": "SSH Key Sharing", "url": "/posts/post220725/", "categories": "Linux", "tags": "Linux", "date": "2022-07-25 19:30:00 +0900", "snippet": " Hyper-v 쿠버네티스 클러스터에서 각 서버에 접근할 때 비밀번호 없이 로그인하기 위해 ssh key를 생성하고 key를 각 서버에 자동 배포하기 위해 작성한 쉘스크립트 코드이다.SSH Key 서버에 접속할 때 비밀번호 대신 key를 제출하는 방식이다.사용하는 목적 비밀번호보다 높은 수준의 보안을 필요로 할 때 로그인 없이 자동으로 서버에 접속 할 때SSH Key가 동작하는 방식SSH Key는 공개키(public key)와 비공개 키(private key)로 이루어 진다.키를 생성하면 공개키와 비공개키가 만들어진다. 이 중에 비공개키는 로컬 머신에 위치해야 하고, 공개키는 리모트 머신에 위치해야 한다. (로컬 호스트는 SSH Client, 원격 호스트는 SSH Server가 설치된 서버를 의미한다)로컬 호스트의 어카운트에 있는 ~/.ssh/id_rsa.pub 키파일의 내용을 원격 호스트 어카운트의 ~/.ssh 디렉토리에 있는 authorized_keys 에 복사한다.정리하면, SSH Server의 authorized_keys의 내용이 SSH Client의 id_rsa.pub 파일과 같아야 한다. ssh 접속을 할 때 id_rsa 파일과 authorized_keys 파일의 내용을 비교한다.아래와 같이 서버에 public key를 카피해 놓았다면 원격 호스트에 로그인 할 어카운트의 암호 없이 로그인이 가능하다.[ssh_key_sharing.sh]export CLUSTER_HOSTS=(vm1 vm2 vm3 vm4 vm5 vm6 vm7 vm8 vm9)export HOME_DIR_PATH=/home/$USER# sshd_config 변경for i in ${!CLUSTER_HOSTS[*]}; do ssh woobin@${CLUSTER_HOSTS[$i]} -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no &quot;sudo dnf install -y sshpass &amp;amp;&amp;amp; sudo sed -i -e &#39;s/PasswordAuthentication no/PasswordAuthentication yes/g&#39; /etc/ssh/sshd_config &amp;amp;&amp;amp; sudo systemctl restart sshd&quot; &amp;amp;&amp;gt; /dev/null; done# ssh key 생성echo -e &quot;&amp;gt;&amp;gt; Enter Password:&quot;; read -s PASSWD; for i in ${!CLUSTER_HOSTS[*]}; do echo &quot;i[$i]: [${CLUSTER_HOSTS[$i]}]&quot;; sshpass -p $PASSWD ssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no woobin@${CLUSTER_HOSTS[$i]} &quot;mkdir -p $HOME_DIR_PATH/.ssh; echo -e &#39;n\\n&#39; | ssh-keygen -t rsa -f $HOME_DIR_PATH/.ssh/id_rsa -q -N &#39;&#39;; cp $HOME_DIR_PATH/.ssh/id_rsa.pub $HOME_DIR_PATH/.ssh/authorized_keys; chmod 700 $HOME_DIR_PATH/.ssh&quot; &amp;amp;&amp;gt; /dev/null; done# ssh key 공유echo -e &quot;&amp;gt;&amp;gt; Enter Password:&quot;; read -s PASSWD; for i in ${!CLUSTER_HOSTS[*]}; do echo &quot;i[$i]: [${CLUSTER_HOSTS[$i]}]&quot;; for j in ${!CLUSTER_HOSTS[*]}; do echo &quot;j[$j]: [${CLUSTER_HOSTS[$i]}] -&amp;gt; [${CLUSTER_HOSTS[$j]}]&quot;; sshpass -p $PASSWD ssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no woobin@${CLUSTER_HOSTS[$i]} &quot;sshpass -p $PASSWD ssh-copy-id -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no woobin@${CLUSTER_HOSTS[$j]} &amp;amp;&amp;gt; /dev/null&quot; &amp;amp;&amp;gt; /dev/null; done; done# 체크for i in ${CLUSTER_HOSTS[*]}; do ssh ${CLUSTER_HOSTS[$i]} -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no &quot;ls -al .ssh&quot;; done코드 설명ssh key 생성echo -e &quot;&amp;gt;&amp;gt; Enter Password:&quot;; read -s PASSWD; for i in ${!CLUSTER_HOSTS[*]}; do echo &quot;i[$i]: [${CLUSTER_HOSTS[$i]}]&quot;; sshpass -p $PASSWD ssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no woobin@${CLUSTER_HOSTS[$i]} &quot;mkdir -p $HOME_DIR_PATH/.ssh; echo -e &#39;n\\n&#39; | ssh-keygen -t rsa -f $HOME_DIR_PATH/.ssh/id_rsa -q -N &#39;&#39;; cp $HOME_DIR_PATH/.ssh/id_rsa.pub $HOME_DIR_PATH/.ssh/authorized_keys; chmod 700 $HOME_DIR_PATH/.ssh&quot; &amp;amp;&amp;gt; /dev/null; done아래부터는 각 부분에 대한 설명입니다.echo -e &quot;&amp;gt;&amp;gt; Enter Password:&quot;; ”» Enter Password:” 메시지를 출력합니다.read -s PASSWD; 사용자로부터 비밀번호를 읽어서 PASSWD 변수에 저장합니다. s 옵션은 입력한 비밀번호가 화면에 표시되지 않도록 합니다.`for i in ${!CLUSTER_HOSTS[*]}; do` 배열 CLUSTER_HOSTS의 모든 인덱스를 순회하는 루프를 시작합니다.echo &quot;i[$i]: [${CLUSTER_HOSTS[$i]}]&quot;; 순회 중인 인덱스 i와 해당 인덱스에 위치한 CLUSTER_HOSTS 배열의 요소를 출력합니다.sshpass -p $PASSWD ssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no ${CLUSTER_HOSTS[$i]} sshpass 명령어를 사용하여 비밀번호를 제공하고, ssh 명령을 통해 원격 호스트에 연결합니다. $PASSWD 변수에 저장된 비밀번호를 p 옵션으로 전달합니다. -o UserKnownHostsFile=/dev/null 옵션은 호스트 키를 known_hosts 파일에 저장하지 않도록 합니다. /dev/null은 특수 파일로, 데이터를 버리는데 사용됩니다. -o StrictHostKeyChecking=no 옵션은 호스트 키의 유효성을 검사하지 않도록 합니다. 일반적으로 클라이언트가 원격 서버의 호스트 키와 일치하는지 확인하며, 일치하지 않으면 경고를 표시하고 연결을 거부합니다. 그러나 이 옵션을 사용하면 호스트 키 검사를 건너뛰고 연결을 허용하게 됩니다. ${CLUSTER_HOSTS[$i]}는 현재 순회 중인 인덱스 i에 해당하는 원격 호스트 주소를 사용합니다.&quot;mkdir -p $HOME_DIR_PATH/.ssh; echo -e &#39;n\\n&#39; | ssh-keygen -t rsa -f $HOME_DIR_PATH/.ssh/id_rsa -q -N &#39;&#39;; cp $HOME_DIR_PATH/.ssh/id_rsa.pub $HOME_DIR_PATH/.ssh/authorized_keys; chmod 700 $HOME_DIR_PATH/.ssh&quot; &amp;amp;&amp;gt; /dev/null; 원격 호스트에 로그인한 후 수행할 명령어들입니다. 여러 명령어를 세미콜론(;)으로 구분하여 순차적으로 실행합니다. mkdir -p $HOME_DIR_PATH/.ssh;은 원격 호스트에서 .ssh 디렉토리를 생성합니다. p 옵션은 이미 디렉토리가 존재하면 무시하도록 합니다. echo -e &#39;n\\n&#39; | ssh-keygen -t rsa -f $HOME_DIR_PATH/.ssh/id_rsa -q -N &#39;&#39;; echo -e &#39;n\\n&#39; |: ssh-keygen 명령을 실행할 때 기존 키 파일이 존재하는 경우에 대한 덮어쓰기 여부를 묻는 메시지가 나오는 것을 피하는 것입니다. echo -e ‘n\\n’ 명령을 통해 “n”이라는 문자를 출력하고 줄 바꿈을 추가하여, ssh-keygen 명령이 “n” 입력을 받아 덮어쓰기를 거부하도록 하는 것입니다. -t rsa: RSA 알고리즘을 사용하여 키를 생성한다는 것을 나타냅니다. RSA는 공개키 암호화 방식으로 널리 사용됩니다. -f $HOME_DIR_PATH/.ssh/id_rsa: 생성할 개인키와 공개키의 파일 이름과 경로를 지정합니다. ssh key가 저장되는 기본 경로는 로그인 한 사용자의 홈디렉토리 아래에 .ssh입니다. SSH Client는 기본적으로 이 디렉토리에 있는 키를 이용해서 인증을 시도합니다. 여기서는 위에서 지정한 HOME_DIR_PATH/.ssh 경로에 생성하며, 생성되는 파일은 아래와 같습니다. id_rsa: private key, 절대로 타인에게 노출되면 안된다. id_rsa.pub: public key, 접속하려는 리모트 머신의 authorized_keys에 입력한다. authorized_keys: .ssh 디렉토리 아래에 위치하면서 id_rsa.pub 키의 값을 저장한다. -q: quiet 모드로 작동하게 합니다. 이 옵션을 사용하면 사용자 입력을 최소화하고 진행 과정에서 메시지를 표시하지 않습니다. -N &#39;&#39;: 개인키에 설정할 암호를 지정합니다. 여기서는 빈 문자열(&#39;&#39;)을 사용하여 암호를 설정하지 않도록 합니다. 암호를 설정하지 않으면 SSH 키를 사용할 때 암호를 입력하지 않아도 됩니다. cp $HOME_DIR_PATH/.ssh/id_rsa.pub $HOME_DIR_PATH/.ssh/authorized_keys;은 공개 키를 authorized_keys 파일에 복사합니다. 이렇게 하면 비밀번호 없이 원격 호스트에 로그인할 수 있게 됩니다. chmod 700 $HOME_DIR_PATH/.ssh는 매우 중요한 보안 정보가 담긴 디렉토리 입니다. 따라서 퍼미션 설정을 해줘야 합니다. 해당 디렉토리가 소유자만 읽기, 쓰기, 실행이 가능하도록 합니다. &amp;amp;&amp;gt; /dev/null;는 모든 출력을 무시하고 실행 결과를 /dev/null로 보냅니다. 즉, 실행 결과를 출력하지 않습니다.ssh key 공유echo -e &quot;&amp;gt;&amp;gt; Enter Password:&quot;; read -s PASSWD; for i in ${!CLUSTER_HOSTS[*]}; do echo &quot;i[$i]: [${CLUSTER_HOSTS[$i]}]&quot;; for j in ${!CLUSTER_HOSTS[*]}; do echo &quot;j[$j]: [${CLUSTER_HOSTS[$i]}] -&amp;gt; [${CLUSTER_HOSTS[$j]}]&quot;; sshpass -p $PASSWD ssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no woobin@${CLUSTER_HOSTS[$i]} &quot;sshpass -p $PASSWD ssh-copy-id -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no woobin@${CLUSTER_HOSTS[$j]} &amp;amp;&amp;gt; /dev/null&quot; &amp;amp;&amp;gt; /dev/null; done; done아래부터는 각 부분에 대한 설명입니다.for i in ${!CLUSTER_HOSTS[*]}; do echo &quot;i[$i]: [${CLUSTER_HOSTS[$i]}]&quot;; for j in ${!CLUSTER_HOSTS[*]}; do echo &quot;-- j[$j]: [${CLUSTER_HOSTS[$i]}] -&amp;gt; [${CLUSTER_HOSTS[$j]}]&quot;; 중첩 for-loop를 통해 모든 클러스터에 대해 진행합니다.sshpass -p $PASSWD ssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no ${CLUSTER_HOSTS[$i]} 현재 i번째 인덱스에 해당하는 원격 호스트에서 아래의 작업을 진행합니다.&quot;sshpass -p $PASSWD ssh-copy-id -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no ${CLUSTER_HOSTS[$j]} &amp;amp;&amp;gt; /dev/null&quot; &amp;amp;&amp;gt; /dev/null; ssh-copy-id: SSH 공개 키를 원격 호스트에 복사합니다. -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no: 호스트 키 확인 및 기록을 하지 않도록 설정합니다. &amp;amp;&amp;gt; /dev/null: 표준 출력과 표준 에러를 /dev/null로 리다이렉트하여 출력을 무시합니다." }, { "title": "(Javascript) 프로토타입(Prototype)", "url": "/posts/post220720/", "categories": "Javascript", "tags": "Javascript", "date": "2022-07-20 19:30:00 +0900", "snippet": " 이 글은 “https://medium.com/@bluesh55/  - 오승환님의 [Javascript ] 프로토타입 이해하기”를 토대로 공부한 내용을 덧붙인 글Prototype아래와 같이 kim과 park은 eyes와 nose를 공통적으로 가지고 있는데, 메모리에는 eyes와 nose가 두 개씩 총 4개 할당된다. 객체를100개 만들면 200개의 변수가 메모리에 할당된다.function Person() { this.eyes = 2; this.nose = 1;}var kim = new Person();var park = new Person();console.log(kim.eyes); // =&amp;gt; 2console.log(kim.nose); // =&amp;gt; 1console.log(park.eyes); // =&amp;gt; 2console.log(park.nose); // =&amp;gt; 1Person.prototype이라는 빈 Object가 어딘가에 존재하고, Person 함수로부터 생성된 객체(kim, park)들은 어딘가에 존재하는 Object에 들어있는 값을 모두 갖다쓸 수 있다. 즉, eyes와 nose를 어딘가에 있는 빈 공간에 넣어놓고 kim과 park이 공유해서 사용하는 것이다.function Person() {}Person.prototype.eyes = 2;Person.prototype.nose = 1;var kim = new Person();var park = new Person():console.log(kim.eyes); // =&amp;gt; 2...Prototype Link / Prototype ObjectPrototype Object객체는 언제나 함수로 생성된다.function Person() {} // =&amp;gt; 함수var personObject = new Person(); // =&amp;gt; 함수로 객체를 생성아래 코드에서, Object는 자바스크립트에서 기본적으로 제공하는 함수이다. Object와 마찬가지로 Function, Array도 모두 함수로 정의되어 있다.var obj = {}; -&amp;gt; var obj = new Object();함수를 정의하면 함수만 생성되는 것이 아니라 Prototype Object도 같이 생성된다. Constructor 자격이 부여되면 new를 통해 객체를 만들어 낼 수 있게 된다. 이것이 함수만 new 키워드를 사용할 수 있는 이유이다. 생성된 함수는 prototype이라는 속성을 통해 Prototype Object에 접근할 수 있음 Prototype Object는 일반적인 객체와 같으며 기본적인 속성으로 constructor와 __proto__를 가지고 있음constructor는 Prototype Object와 같이 생성되었던 함수를 가리키고, __proto__는 Prototype Link를 가리킨다.function Person() {}Person.prototype.eyes = 2;Person.prototype.nose = 1;var kim = new Person();var park = new Person();console.log(kim.eyes); // =&amp;gt; 2...Prototype Object는 일반적인 객체이므로 속성을 마음대로 추가/삭제 할 수 있다. kim과 park은 Person 함수를 통해 생성되었으니 Person.prototype을 참조할 수 있게 된다.Prototype Linkprototype속성은 함수만 가지고 있던 것과는 달리, __proto__속성은 모든 객체가 빠짐없이 가지고 있는 속성이다.이것이 Person 함수를 통해 생성된 kim과 park이 Person.prototype을 참조할 수 있는 이유이다.__proto__는 객체가 생성될 때 조상이었던 함수의 Prototype Object를 가리킨다. kim객체는 Person함수로부터 생성되었으니 Person 함수의 Prototype Object를 가리키고 있는 것이다. kim객체가 eyes를 직접 가지고 있지 않기 때문에 eyes 속성을 찾을 때 까지 상위 프로토타입을 탐색한다. 최상위인 Object의 Prototype Object까지 도달했는데도 못찾았을 경우 undefined를 리턴한다. 이렇게 __proto__속성을 통해 상위 프로토타입과 연결되어있는 형태를 프로토타입 체인(Chain)이라고 한다.이런 프로토타입 체인 구조 때문에 모든 객체는 Object의 자식이라고 불리고, Object Prototype Object에 있는 모든 속성을 사용할 수 있다.toString함수로 예를 들어보면, Object속성인 toString함수를 kim도 사용 가능하다." }, { "title": "Cgroup", "url": "/posts/post220718/", "categories": "Linux", "tags": "Linux", "date": "2022-07-18 19:30:00 +0900", "snippet": " 프로세스에 할당하는 CPU, 메모리, 네트워크 대역폭 등과 같은 자원을 개별적으로 제한하기 위한 시스템 커널의 기능 컨테이너 런타임은 이 기술을 사용하에 컨테이너에 자원을 할당cgroup을 관리하기 위한 기술cgroupfs 직접 cgroup을 마운트해서 사용 cgroup이 관리할 수 있는 자원의 컨트롤러는 파일 시스템의 형태로 관리. 이와 관련된 정보를 파일 시스템의 형태로 변환시켜 주는 매니저가 cgroupfs cgroupfs는 /sys/fs/cgroup 경로의 하위에 이 정보를 마운트하여 관리systemd 프로세스가 사용하는 자원을 관리하기 위해 slice &amp;gt; scope &amp;gt; service 단위의 계층적인 구조로 만들어 각 단위에 자원을 할당 /sys/fs/cgroup/systemd 하위의 파일 시스템의 계층 구조를 통해 확인 가능 systemd에 의해 관리되는 cgroup 정보는 /sys/fs/cgroup 하위의 자원의 컨트롤러(cpu, memory 등)의 하위에서 slice의 이름으로 된 파일 시스템으로 표현 컨테이너에서 어떤 cgroup 매니저를 사용하고 있는지 확인하는 명령어 kubelet --version → Kubernetes v1.20.2 docker info | grep Cgroup kubernetes v1.22로 올라가면서 기존에는 경고 수준으로 처리하던 cgroup driver을 정해진 설정이 없다면 default를 systemd로 설정하도록 코드가 변경됨" }, { "title": "(Java) JDK, JRE, JVM", "url": "/posts/post220714/", "categories": "Java", "tags": "Java", "date": "2022-07-14 19:30:00 +0900", "snippet": "JDK JDK(Java Development Kit)는 자바 개발 도구의 약자입니다. JDK는 JRE 외에 개발을 위해 필요한 도구(javac, java 등등)을 포함 하는 일 중 가장 큰 역할이 컴파일러 역할을 할 수 있습니다. (javac.exe = java컴파일러, java.exe = JVM 구동 프로그램) 사용자가 java소스(.java)를 만들었다. 기계어로 변경해야 기계가 실행합니다. (.java)는 기계어로 변환하려면 과정을 거쳐야합니다. 파일을 변환하기 위해 javac.exe가 도와줍니다. (.java) -&amp;gt; (.class) 바이트 코드 파일(.class)로 컴파일 되어 변환 합니다. 바이트 코드 파일이 실행되도록 java.exe가 도와줍니다. JVM을 구동시킵니다. 바이트 코드가 컴파일되면서 그 뒤부터 JVM이 구동됩니다. (java.exe가 JVM을 구동시키기 위한 명령 프로그램 이라고 합니다.) JVM을 거쳐 컴퓨터가 사용할 수 있는 기계언어로 변경해줍니다. JRE JRE(Java Runtime Environment)는 자바 실행환경의 약자입니다. JVM이 구동할 때 필요한 라이브러리 파일들과 기타 파일들을 가지고 있습니다. JRE는 JVM의 실행환경을 구축 (JVM의 조력자)JVM JVM(Java Virtual Machine)의 약자입니다. JVM은 자바 소스코드로부터 만들어지는 자바 바이트 코드 파일(.class)를 실행할 수 있다. JVM은 운영체제마다 다르다. (.class)파일을 OS에 맞는 기계코드로 변환. 그러나 한번 컴파일 된 코드는 서로 다른 JVM이라도 돌아가도록 만들었다. 플랫폼에 종속적 Java 의 장점이 여기서 나옵니다. JVM을 사용하면 하나의 바이트 코드(.class)로 모든 플랫폼에서 동작하도록 할 수 있습니다. 참고 바이트 코드: JVM 같은 가상 머신이 이해할 수 있는 코드 (.class). 사람이 쓰는 자바 코드에서 컴퓨터가 읽는 기계어로의 중간 단계 바이너리 코드: CPU가 이해할 수 있는 코드 자바 프로그램의 실행 과정과 JVM 예를 들어 C언어로 작성된 Test.c가 있다고 해봅시다. 이 Test.c를 윈도우 컴파일러를 사용해서 컴파일하면 Test.exe가 만들어집니다. 윈도우 컴파일러로 컴파일되었기에 Test.exe는 윈도우에서만 실행되는 실행 파일입니다. 리눅스 운영체제에서는 실행할 수 없습니다. 즉 C / C++에서는 컴파일 플랫폼과 타겟 플랫폼이 다를 경우에는 프로그램이 동작하지 않습니다. 만약 이 Test.exe 파일을 리눅스 운영체제에서 실행하려면 리눅스 환경을 타겟으로 크로스 컴파일을 해서 리눅스 운영체제에 맞는 실행 파일을 새로 만들어야 하는 것입니다. Java의 경우에는 Java언어로 작성된 Test.java는 컴파일하면 Test.class 파일이 생성됩니다. 그리고 이렇게 생성된 바이트 코드는 각자의 플랫폼에 설치되어 있는 자바 가상 머신(JVM)이 운영체제에 맞는 실행 파일로 바꿔줍니다. 즉 Java에서는 C언어와는 달리 JVM을 사용하기 때문에 각자의 플랫폼에 맞게끔 컴파일을 따로따로 해줘야 할 필요가 없습니다. 하나의 바이트 코드로 JVM이 설치되어 있는 모든 플랫폼에서 동작이 가능하다는 이야기입니다. Java는 플랫폼에 종속적이지 않지만 JVM은 플랫폼에 종속적이다. 우리가 자바로 (.java) 코드를 작성하고 파워쉘이나 터미널에 있는 자바 컴파일러인 javac에 컴파일 명령을 내리면 (.class) 파일이 만들어집니다. 이후 이 바이트 코드는 클래스 로더를 통해 JVM Runtime Data Area로 로딩되고, 로딩된 .class 바이트 코드를 실행할 컴퓨터에 깔린 JVM에 가져다주면 그 컴퓨터가 이 프로그램을 실행할 때 이 JVM이 그때그때 기계어로 해석합니다.정리 JDK &amp;gt; JRE &amp;gt; JVM JDK = 개발 환경(+컴파일)  /  JRE = 실행 환경 구축  /  JVM = 실행 간단한 실행 순서 사용자 Java 코드 생성 → JDK컴파일 (.class 파일 생성) → JVM → 실행 (.java) → javac → (.class) → jvm → process Reference https://aws.amazon.com/ko/what-is/java-runtime-environment/" }, { "title": "(Network) Protocol Data Unit (PDU)", "url": "/posts/post220712/", "categories": "Network", "tags": "Network", "date": "2022-07-12 19:30:00 +0900", "snippet": "프로토콜 데이터 단위 데이터 통신에서 상위 계층이 전달한 데이터에 붙이는 제어정보를 뜻한다. 데이터 자체는 동일하지만 각 레이어를 거치면서 헤더 정보가 추가되면서 이름이 달라진다.사용자는 Data 라고 부르고,TCP는 Segment 라고 부르고,IP는 Packet 이라고 부르고,데이터링크는 Frame,컴퓨터 하드웨어는 그것을 Bit 로 연산하고 다루게 되는 것세그먼트(L4 전송 계층) 상위 계층에서 데이터를 전달받은 전송계층에서는 아래의 정보들를 추가해 그룹화 한다. 이때부터 데이터는 데이터가 아니라, 세그먼트라고 불리는 것이다. 발신지 포트 : 발신하는 application의 포트 목적지 포트 : 수신해야 할 application의 포트 순서 번호 : 순차적 전송할 경우 순서를 붙이며, 순서가 어긋나면 목적지 프로토콜이 이를 바로 잡는다. 오류검출코드 : 발신지와 목적지 프로토콜은 세그먼트를 연산하여 오류 검출 코드를 각각 만든다. 만약 발신지에서 전송한 세그먼트에 포함된 오류 검출 코드와 목적지에서 만든 오류 검출 코드가 다르다면 전송되는 과정에서 오류가 발생한 것이다. 이 경우, 수신측은 그 세그먼트를 폐기하고 복구 절차를 밟는다. 오류검출코드는 체크섬, 프레임 체크 시퀀스라고도 부른다.패킷 또는 데이터그램(L3 네트워크 계층) 전송 계층으로 부터 전달받은 세그먼트는 네트워크 계층의 정보를 포함해 패킷이라고 불리게 된다. 발신지 컴퓨터 주소(Destination IP) : 패킷의 발신자 주소 목적지 컴퓨터 주소(Source IP) : 패킷의 수신자 주소프레임(L2 데이터링크 계층) 데이터 링크 레이어 네트워크 레이어로부터 패킷을 받아들여 네트워크 미디어에 제공하는 역할을 수행 데이터 링크 레이어는 프레임의 각 패킷을 캡슐화하고 프레임의 헤더는 송신지 또는 수신지 호스트의 하드웨어 어드레스를 선택 만일 장비가 원격 네트워크 상에 있으면 프레임을 라우터로 전송하여 인터네트워크를 통해 라우팅이 행해짐 수신지 네트워크에 도착하면 새로운 프레임을 이용하여 패킷이 수신지 호스트에 도달하게 됨 이더넷 프레임 구조 이더넷 프레임은 표준인 IEEE 802.3 프레임과 Ethernet II라 불리는 DIX 2.0으로 나뉜다. 실제로는 표준이 아닌 Ethernet II 프레임 포맷을 대부분 사용 각 필드의 개념 Preamble 송신자와 수신자의 동기화를 위해 사용된다. 10101010으로 된 7개의 비트열 전달(56비트) SFD(Start of Frame Delimiter) 802.3 프레임의 경우에만 있다. Preamble의 끝을 표시해주는 10101011의 8비트로 구성. 이더넷 패킷의 첫 번째 필드이자 이더넷 프레임의 시작을 알려주는 역할을 한다. 자신 뒤로 오는 프레임의 내용이 곧 시작된다는 것을 알리는 역할이기도 하다. SFD는 Preamble의 비트 패턴과 실제 프레임의 시작 신호 전달을 위해 디자인 되었다. Preamble과 SFD는 물리계층 헤더이기 때문에 MAC Frame에 포함되지 않는다. 그래서 와이어샤크에서 보이지 않는 것. MAC dst, src 프레임은 출발지와 목적지의 MAC주소를 담고 있다. 6바이트 = 48비트. 앞의 24비트는 제조사 번호(OUI)고 뒤 24비트는 해당 업체의 랜 카드 정보(일련번호)를 담고 있다. EtherType / Length 2바이트로 구성 되어 있으며 데이터에 내제된 네트워크 프로토콜 타입을 식별해주는 역할을 한다. Type값이 0x0600 이상이면 DIX 2.0 Type이고 미만이면 IEEE 802.3 Type이다. Length는 수납되는 LLC(Logical Link Control) 프레임 길이를 나타낸다. Data / Payload Payload의 최소값은 46바이트다. 46바이트가 안되면 padding을 한다(뒤에 0을 붙임). 따라서 최소 Ethernet Frame 사이즈는 18+46바이트인 64바이트다. MTU(Maximum Transmission Unit)란 한 데이터링크에서 하나의 프레임 또는 패킷에 담아 운반 가능한 최대 크기다. 보통 기본 값은 1500바이트를 사용한다. 따라서, Ethernet Frame Header값인 14바이트와 MTU의 최대 값인 1500바이트, 그리고 FCS의 4바이트를 더한 1518바이트는 최대 Ethernet Frame 사이즈가 된다. VLAN Tag가 붙는다면, 4바이트가 더 붙어서 1522바이트가 된다. FCS(Frame Check Sequence) FCS는 수신된 전체 프레임에서 손상된 데이터를 탐지할 수 있는 CRC(Cyclic Redundancy Check)를 의미한다. 에러 검출을 한다고 보면 된다. FCS값은 보호 된 MAC 프레임 필드의 함수로 계산된다. 출발지, 목적지 주소, length type, padding 등 비트(L1 물리적 계층) 물리적 레이어 프레임을 네트워크 상으로 올려놓기 위해서 프레임을 디지털 신호로 전환시킴 인캡슐레이션(encapsulation)계층의 순서대로 헤더가 부가되어 가는 것을 캡슐화라고 한다.디 인캡슐레이션(de-encapsulation) 수신장비는 디지털 신호와 동기시켜 0과 1을 디지털 신호로부터 추출 이때 수신장비는 프레임을 구성하여 CRC(Cyclic Redundancy Check)를 구동하며 그 결과를 프레임의 FCS 필드의 내용과 대조함 만일 이것이 맞으면 패킷은 프레임으로부터 분리되고 프레임은 폐기됨. 패킷은 네트워크 레이어에서 처리되며 어드레스도 점검됨 세그먼트는 트랜스포트 레이어에서 처리되며 데이터를 재구성하고 송신 스테이션에 수신한 것을 통과함 그러면 이 데이터는 상위 레이어인 어플리케이션으로 넘겨짐" }, { "title": "(Python)[백준] 다리 놓기", "url": "/posts/post220711/", "categories": "CodingTest", "tags": "CodingTest", "date": "2022-07-11 19:30:00 +0900", "snippet": "1010번: 다리 놓기문제 풀이 m개의 지역에 n개의 다리를 놓을 수 있는 경우의 수를 구하는 것. mCn 으로 표현할 수 있고 이는 m! 을 n!(m-n)! 으로 나눈 값 테스트 케이스마다 팩토리얼을 구하게 되면 매번 연산을 해야 되므로 시간이 오래 걸리는데, 숫자의 범위가 30까지이므로 30까지의 팩토리얼을 미리 구해 놓은 뒤 이용하게 되면 좀 더 빠르게 해결소스 코드factorial = [1] * 31for i in range(2, 31): factorial[i] = factorial[i-1] * iT = int(input())for _ in range(T): n, m = map(int, input().split()) bridge = factorial[m] // (factorial[n] * factorial[m-n]) print(bridge)" }, { "title": "(Python)[백준] 패션왕 신해빈", "url": "/posts/post220710/", "categories": "CodingTest", "tags": "CodingTest", "date": "2022-07-06 19:30:00 +0900", "snippet": "9375번: 패션왕 신해빈문제 풀이알몸으로 다니지 않는 경우의 수는 (종류별 옷의 수) + 1 을 전부 곱해주고(해당 종류의 옷을 안 입는 경우의 수를 포함한 것) 알몸의 경우의 수인 1만 빼주면 된다.소스 코드import sysinput = sys.stdin.readlineT = int(input())for _ in range(T): n = int(input()) clothes = {} for _ in range(n): _, key = input().split() if key in clothes: clothes[key] += 1 else: clothes[key] = 1 anw = 1 if len(clothes) == 1: anw = clothes[key] print(anw) else: for i in clothes: anw *= (clothes[i]+1) print(anw-1)" }, { "title": "(Python)(JAVA)[백준][구현] 욱제는 결정장애야!!", "url": "/posts/post220706/", "categories": "CodingTest", "tags": "CodingTest", "date": "2022-07-06 19:30:00 +0900", "snippet": "14646번: 욱제는 결정장애야!!문제 풀이위 그림처럼 돌림판에서 두 번 나오면 해당 수를 지워간다.소스 코드첫 풀이import sysinput = sys.stdin.readlinen = int(input()) # 3arr = list(map(int, input().split())) # [1, 3, 3, 2, 1, 2]visited = [0] * n # [0, 0, 0]answer = 0for i in arr: if visited[i-1] &amp;gt;= 0: visited[i-1] += 1 if visited[i-1] == 2: visited[i-1] = 0 answer = max(answer, sum(visited)) if answer == n: breakprint(answer)위와 같이 구현했더니 시간 초과가 났다. 다른 분들 풀이도 비슷하던데 answer 갱신해주는 부분에서 sum() 계산시 시간이 많이 걸리는 거 같다.최종 풀이는 cnt를 계산해주는 것으로 바꿔서 풀어봤다.최종 풀이import sysinput = sys.stdin.readlinen = int(input()) # 3arr = list(map(int, input().split())) # [1 3 3 2 1 2]visited = [False] * n cnt = 0answer = 0for i in arr: if not visited[i-1]: cnt += 1 visited[i-1] = True else: cnt -= 1 visited[i-1] = False answer = max(answer, cnt) if answer == n: breakprint(answer)import java.util.*;public class indecisiveness { public static void main(String[] args){ Scanner sc = new Scanner(System.in); int[] visited = new int[100001]; // 기본 타입으로 배열 선언시 초기값은 0 int n = sc.nextInt(); int sum = 0; int max = 0; for(int i = 1; i&amp;lt;= n*2;i++) { int arr = sc.nextInt(); if(visited[arr] == 0) { sum++; visited[arr]++; } else sum--; if(sum &amp;gt; max) max = sum; } System.out.println(max); }}" }, { "title": "(Python)[백준][DP] 계단 오르기", "url": "/posts/post220704/", "categories": "CodingTest", "tags": "CodingTest", "date": "2022-07-04 19:30:00 +0900", "snippet": "2579번: 계단 오르기문제 풀이 dp[3]인 25에 도달하려면 15에서 오거나 20에서 왔을 것이다. 하지만 연속으로 세 개의 계단을 밟는 경우가 안되므로 10-15-25 로 오거나, 20-25로 오는 두 가지 경우의 수가 존재한다. 해당 지점까지 왔을 때의 최대 점수를 dp 테이블에 저장시키면서 진행한다.첫 소스 코드# 계단의 수n = int(input())# 계단에 쓰여있는 점수scores = []for _ in range(n): scores.append(int(input()))# DP 테이블 초기화dp = [0] * n# DP 진행dp[0] = scores[0]dp[1] = scores[0] + scores[1]dp[2] = max(scores[0] + scores[2], scores[1] + scores[2])for i in range(3, n): dp[i] = max(dp[i-2] + scores[i], dp[i-3] + scores[i] + scores[i-1])print(dp[n-1])런타임 에러가 난다. 알아보니 계단이 1개나 2개인 경우라면 scores, dp 값이 존재하지 않기 때문인 거 같다. 따라서 길이를 처음부터 정해서 배열을 구현한다.소스 코드# 계단의 수n = int(input())# 계단에 쓰여있는 점수scores = [0] * 300for i in range(n): scores[i] = int(input())# DP 테이블 초기화dp = [0] * 300# DP 진행dp[0] = scores[0]dp[1] = scores[0] + scores[1]dp[2] = max(scores[0] + scores[2], scores[1] + scores[2])for i in range(3, n): dp[i] = max(dp[i-2] + scores[i], dp[i-3] + scores[i] + scores[i-1])print(dp[n-1])" }, { "title": "DOM (Document Obejct Model)", "url": "/posts/post220625/", "categories": "Javascript", "tags": "Javascript", "date": "2022-06-25 19:30:00 +0900", "snippet": "문서 객체 모델 (DOM) 문서 객체 모델(Document Object Model, DOM)은 말 그대로 웹 페이지 내의 모든 콘텐츠를 객체로 나타내 주는 것이다. HTML이나 XML 등의 문서를 객체로 표현할 때 사용되는 API이다. 간단하게 생각하면 웹 페이지를 document라고 부르고, document를 자유롭게 다루기 위해서 객체화 하고자 구현된 개념이 결국이 DOM이라고 생각할 수 있겠다. HTML, XML 태그와 글자, 속성 등 document의 담겨있는 모든 요소들을 하나하나를 객체화 한 단위를 가리켜 노드(Node)라고 부른다. JS, Java, C, C# 등 다양한 언어에서 DOM API를 제공한다. XMLHttpRequest 객체는 응답 텍스트 대신 XML 응답 결과를 사용할 수 있다. 이때, DOM API를 사용해서 Server가 생성한 XML로부터 데이터를 추출 가능하다. 결국, DOM은 웹 페이지를 객체화 한 개념이고 이 웹페이지의 가장 상단 진입점이 바로 document 객체이다. document 객체는 전역 객체인 window 객체의 바로 아래 있는데, window 객체는 앞에 window를 생략해도 되기 때문에 일반적으로는 document에 바로 접근해서 메서드나 프로퍼티들을 활용한다. window.documentdocument // window는 생략될 수 있다.Document 객체window객체가 브라우저 창을 대변하는 것이라면 document 객체는, 브라우저 내에서 컨텐츠를 보여주는 웹 페이지 자체를 대변한다고 할 수 있다.간단하게 웹 페이지가 document고, 이를 객체화한 것이 document 객체라고 생각해볼 수도 있겠다.Document 객체의 Propertydocument 객체를 활용하면 웹페이지의 상태와 모든 HTML 태그들에 접근할 수 있는데, 가장 간단하게 프로퍼티 네임에 태그 이름을 입력하면 해당 태그에 접근이 가능하다.document.documentElement // document를 제외하고 DOM 트리 꼭대기에 있는 문서 노드인 &amp;lt;html&amp;gt; 태그 반환document.head // &amp;lt;head&amp;gt; 태그 반환document.title // &amp;lt;title&amp;gt; 태그 반환document.body // &amp;lt;body&amp;gt; 태그 반환document.links // href 속성이 있는 &amp;lt;a&amp;gt; 태그 반환document.images // &amp;lt;img&amp;gt; 태그 반환document.forms // &amp;lt;form&amp;gt; 태그 반환document.scripts // &amp;lt;script&amp;gt; 태그 반환웹페이지의 정보를 담은 property들도 있다.document.doctype // 웹 페이지의 문서 형식을 반환document.readyState // 웹 페이지의 로딩 상태를 반환document.documentURI // 웹 페이지의 URI를 반환document.baseURI // 웹 페이지의 절대 URI를 반환document.URL // 웹 페이지의 완전한 URL 주소를 반환document.referrer // 링크(linking)되어 있는 문서의 URI를 반환document.domain // 웹 페이지가 위치한 서버의 도메인을 반환document.cookie // 웹 페이지의 쿠키를 반환document.lastModified // 웹 페이지의 마지막 갱신 날짜 및 시간을 반환document.inputEncoding // 웹 페이지의 문서 인코딩 형식을 반환HTML 태그 (노드) 선택하기메서드들을 사용하면 다양한 방법으로 웹 페이지 내의 태그들에 접근할 수 있다.// 파라미터로 전달한 태그이름을 가진 모든 태그들을 반환(배열)document.getElementsByTagName(태그이름)// 파라미터로 전달한 ID를 가진 태그를 반환document.getElementById(아이디)// 파라미터로 전달한 클래스 이름을 가진 모든 태그들을 반환(배열)document.getElementsByClassName(클래스이름)// 파라미터로 전달한 name 속성을 가진 태그를 반환document.getElementByName(name속성값)// 파라미터로 전달한 선택자에 맞는 첫 번째 태그를 반환document.querySelector(선택자)// 파라미터로 전달한 선택자에 맞는 모든 태그들을 반환(배열)document.querySelectorAll(선택자)html, xml 문서를 처리하기 위한 DOM 요소의 속성은 다음과 같다.document.childNodes // 현재 요소의 자식을 배열로 표현document.firstChild // 현재 요소의 1번째 자식document.lastChild // 현재 요소의 마지막 자식document.nextSibling // 현재 요소와 바로 다음 요소를 의미document.nodeValue // 해당 요소의 값을 읽고 쓸 수있는 속성을 정의 (=data)document.parentNode // 해당 요소의 부모 노드document.previousSibling //현재 요소와 바로 이전의 요소를 의미" }, { "title": "브라우저 엔진", "url": "/posts/post220620/", "categories": "Javascript", "tags": "Javascript", "date": "2022-06-20 19:30:00 +0900", "snippet": "브라우저란? 브라우저란 월드 와이드 웹(WWW)에서 정보를 검색, 표현하고 탐색하기 위한 소프트웨어이다. 예를 들어, 구글 크롬, 인터넷 익스플로러 등과 같이 검색창이 있는 프로그램이라 생각하면 된다. 브라우저는 인터넷에서 특정 정보로 이동할 수 있는 주소 입력창(인터페이스)이 있고, 서버와 HTTP로 정보를 주고 받을 수 있는 네트워크 모듈도 포함하고 있다. 서버에서 받은 문서(HTML, CSS, Javascript)를 해석하고 실행하여 화면에 표현하기 위한 해석기(Parser)들을 가지고 있습니다.브라우저의 역할 사용자가 입력한(원하는) 웹페이지, 이미지, 동영상 등의 자원을 서버에게 요청하는 역할 서버로부터 전달(응답)받은 자원을 화면에 출력하는 역할브라우저 구성 요소참고로, 크롬 브라우저는 크게 Blink라는 렌더링 엔진과 V8이라는 자바스크립트 엔진을 가지고 있다브라우저 엔진이란? 웹 브라우저의 핵심이 되는 구성 요소 브라우저 엔진은 간단히 말하면 주로 HTML, CSS 등 웹 페이지 구성을 위한 자료를 해석하여 사용자의 장치에 맞게 시각적인 표현으로 변환하는 역할레이아웃 엔진 / 렌더링 엔진 브라우저 엔진은 레이아웃 엔진, 렌더링 엔진이라고도 불린다. 렌더딩과 레이아웃은 별도 엔진의 의해 관리될 수 있으나 실제로 이 둘은 서로 밀접히 연결되어 있고 브라우저 엔진과 같이 묶어서 이야기하는 경우가 많다.렌더링이란? 사용자가 요청한 컨텐츠를 표시하는 역할. 예를 들어 HTML을 요청하면 HTML, CSS를 파싱하여 화면에 표시하는 역할브라우저 엔진 작동 방법브라우저 엔진의 종류에 따라 다소 다르지만 대체로 아래와 같은 방법으로 동작한다. 유저의 요청을 받아서 서버에 자료를 요청한다. 서버에서 받은 자료를 기반으로 브라우저 엔진은 렌더링 엔진을 통해 번역된 자료를 표현하게 된다. HTML을 파싱하여 DOM 노드를 만들고 이들을 합쳐서 DOM 트리를 만든다. CSS를 파싱하여 스타일 규칙을 만든다. DOM 트리와 스타일 규칙을 결합해 렌더 트리를 만든다. UI 백엔드에서 렌더 트리를 그리게 되고, 화면에 우리가 볼 수 있도록 렌더 트리를 배치(Layout)하고 화면에 그려낸다(Painting).파싱 / 파서파싱은 서버로부터 전송 받은 문서의 문자열을 브라우저가 이해할 수 있는 구조로 변환하는 과정을 말한다.파싱 결과는 문서 구조를 나타내는 노드 트리인데 파싱트리 또는 문법트리라고 도 한다.그리고 이러한 파싱을 담당하는 것을 파서라고 한다.브라우저 엔진 작동 과정 예시웹킷 렌더링 엔진다양한 종류의 렌더링 엔진이 존재하지만, 이번 포스팅에서는 웹킷 엔더링 엔진만 다룰 것이다.1. DOM 트리 구축문서 소스로부터 파싱 트리를 만드는 과정 / DOM 트리 예시 브라우저는 서버로부터 HTML 문서를 모두 전달 받는다. 어휘와 구문을 분석하여 HTML 문서를 파싱하고, 파싱 트리를 생성한다. 문서 파싱은 브라우저가 코드를 이해하고 사용할 수 있는 구조로 변환하는 것을 의미한다. 파싱 트리를 기반으로 DOM 요소와 속성 노드를 가지는 DOM 트리를 생성한다.2. CSSOM(CSS Object Model) 생성CSS 파싱 DOM을 생성할 때 거쳤던 과정을 그대로 CSS에 반복한다. 그 결과로 브라우저가 이해하고 처리할 수 있는 형식(Style Rules)으로 변환된다.3. 렌더 트리(DOM + CSSOM) 생성DOM 트리와 렌더 트리 DOM Tree가 구축이 되어가는 동안 브라우저는 DOM Tree를 기반으로 렌더 트리를 생성한다. 문서를 시각적인 구성요소로 만들어주는 역할을 한다.4. 렌더 트리 배치 렌더링 트리는 위치와 크기를 가지고 있지 않기 때문에, 객체들에게 위치와 크기를 결정해준다.5. 렌더 트리 그리기 렌더 트리의 각 노드를 화면의 픽셀로 나타낸다. 렌더 트리 그리기가 완료되면, 화면에 콘텐츠가 표현된다." }, { "title": "(Python)[백준][슬라이딩 윈도우] 게으른 백곰", "url": "/posts/post220610/", "categories": "CodingTest", "tags": "CodingTest", "date": "2022-06-10 19:30:00 +0900", "snippet": "10025번: 게으른 백곰문제 풀이백곰이 닿을 수 있는 범위를 윈도우로 만들어 전부 탐색한다.소스 코드import sysinput = sys.stdin.readlinen, k = map(int, input().split())arr = [list(map(int, input().split())) for _ in range(n)]ice = [0] * 1000001for i in range(n): ice[arr[i][1]] = arr[i][0]next = 2*k + 1window = sum(ice[:next])answer = windowfor i in range(next, 1000001): window += (ice[i] - ice[i - next]) answer = max(answer, window)print(answer)" }, { "title": "(Python)[백준][그리디] 듣보잡", "url": "/posts/post220603/", "categories": "CodingTest", "tags": "CodingTest", "date": "2022-06-03 19:30:00 +0900", "snippet": "1764번: 듣보잡문제 풀이set() 함수를 이용하여 집합 연산(&amp;amp;)을 이용하면 간단하게 풀 수 있다.소스코드n, m = map(int, input().split())no_hear = set()no_see = set()for i in range(n): no_hear.add(input())for i in range(m): no_see.add(input())answer = sorted(list(no_hear &amp;amp; no_see))print(len(answer))for i in answer: print(i)" }, { "title": "(Python)[백준][구현] 점프왕 쩰리 (Small)", "url": "/posts/post220530/", "categories": "CodingTest", "tags": "CodingTest", "date": "2022-05-30 19:30:00 +0900", "snippet": "16173번: 점프왕 쩰리 (Small)문제 풀이쩰리가 오른쪽, 아래쪽으로만 이동할 수 있기 때문에 방향벡터를 두 개 만들어놓고 BFS를 수행한다.소스 코드import sysfrom collections import dequeinput = sys.stdin.readlinedef bfs(x, y): q = deque([(x, y)]) while q: x, y = q.popleft() if (x, y) == (n - 1, n - 1): return 1 for i in range(2): nx = x + dx[i] * graph[x][y] ny = y + dy[i] * graph[x][y] if 0 &amp;lt;= nx &amp;lt; n and 0 &amp;lt;= ny &amp;lt; n and not visited[nx][ny]: q.append((nx, ny)) visited[nx][ny] = 1 return 0n = int(input())graph = [list(map(int, input().split())) for _ in range(n)]visited = [[0] * n for _ in range(n)]dx = [0, 1]dy = [1, 0]print(&quot;HaruHaru&quot; if bfs(0, 0) else &quot;Hing&quot;)" }, { "title": "(Python)[백준][BFS] 아기상어2", "url": "/posts/post220528/", "categories": "CodingTest", "tags": "CodingTest", "date": "2022-05-28 13:21:00 +0900", "snippet": "17086번: 아기 상어 2문제 풀이상어에서부터 안전 거리를 계산해야 하므로 값이 1인 좌표를 큐에 넣고 bfs로 탐색한다.소스 코드import sysfrom collections import dequeinput = sys.stdin.readlinen, m = map(int, input().split())arr = []# 대각선 방향 포함한 8개 방향dx = [-1, -1, -1, 0, 1, 0, 1, 1]dy = [-1, 0, 1, 1, 1, -1, 0, -1]q = deque()for row in range(n): tmp = list(map(int, input().split())) for col in range(m): if tmp[col] == 1: # 상어에서부터 거리를 계산해야 하므로 큐에 넣기 q.append((row, col)) arr.append(tmp)def bfs(): while q: x, y = q.popleft() for direction in range(len(dx)): nx, ny = x + dx[direction], y + dy[direction] if nx &amp;lt; 0 or nx &amp;gt;= n or ny &amp;lt; 0 or ny &amp;gt;= m: continue if arr[nx][ny] == 0: q.append((nx, ny)) arr[nx][ny] = arr[x][y] + 1bfs()dist = 0for row in range(n): for col in range(m): dist = max(arr[row][col], dist)print(dist - 1) # 거리에서 자기 자신 빼주기" }, { "title": "(Python)[백준][브루트포스] 리모컨", "url": "/posts/post220524/", "categories": "CodingTest", "tags": "CodingTest", "date": "2022-05-24 13:21:00 +0900", "snippet": "1107번: 리모컨문제 풀이소스 코드import sysinput = sys.stdin.readlinetarget = int(input())n = int(input())broken = list(map(int, input().split()))# 현재 채널에서 + 혹은 - 만 사용하여 이동하는 경우answer = abs(100 - target)# 작은수에서 큰수로 이동할땐 500,000까지만 보면 되지만# 반대로 큰수에서 작은수로 내려올 수도 있으므로 1,000,000까지 봐야함for num in range(1000001): num = str(num) for j in range(len(num)): # 각 숫자가 고장났는지 확인 후, 고장 났으면 break # 하나라도 숫자가 고장났으면 숫자 버튼으로는 해당 숫자로 못 감 if int(num[j]) in broken: break # 고장난 숫자 없이 마지막 자리까지 왔다면 answer 비교 후 업데이트 elif j == len(num) - 1: # min(기존답, 해당 번호로부터 타겟까지의 차이 + 번호를 누른 횟수) answer = min(answer, abs(int(num) - target) + len(num))print(answer)" }, { "title": "(Python)(JAVA)[백준] 프린터 큐", "url": "/posts/post220521/", "categories": "CodingTest", "tags": "CodingTest", "date": "2022-05-21 14:23:00 +0900", "snippet": "1966번: 프린터 큐문제 풀이해시 테이블처럼 index 리스트를 만들어서 문서를 구분하였다.소스 코드t = int(input()) for _ in range(t): n, m = map(int, input().split()) # 4, 2 priority = list(map(int, input().split())) # [1 2 3 4] 2341 3412 4123 123 231 312 idx = [i for i in range(n)] # [0, 1, 2, 3] [0 1 target 3] 1t30 t301 301t 01t 1t0 t01 idx[m] = &#39;target&#39; # idx[2] = &#39;target&#39; cnt = 0 # 1 2 while priority: if priority[0] == max(priority): cnt += 1 if idx[0] == &#39;target&#39;: print(cnt) break priority.pop(0) idx.pop(0) else: priority.append(priority.pop(0)) idx.append(idx.pop(0))import java.util.Scanner;import java.util.LinkedList; public class PrinterQueue { public static void main(String[] args) { Scanner in = new Scanner(System.in); StringBuilder sb = new StringBuilder(); int T = in.nextInt(); // 테스트 케이스 while (T-- &amp;gt; 0) { // 증감연산자 -- (나중에 - 적용) int N = in.nextInt(); int M = in.nextInt(); LinkedList&amp;lt;int[]&amp;gt; q = new LinkedList&amp;lt;&amp;gt;(); // Queue로 활용 할 연결리스트. &amp;lt;&amp;gt; 타입 선언 생략 for (int i = 0; i &amp;lt; N; i++) { // {초기 위치, 중요도} q.offer(new int[] { i, in.nextInt() }); } int count = 0; while (!q.isEmpty()) { // 한 케이스에 대한 반복문 int[] front = q.poll(); // 가장 첫 원소 boolean isMax = true; // front 원소가 가장 큰 원소인지를 판단하는 변수 // 큐에 남아있는 원소들과 중요도를 비교 for(int i = 0; i &amp;lt; q.size(); i++) { // 처음 뽑은 원소보다 큐에 있는 i번째 원소가 중요도가 클 경우 if(front[1] &amp;lt; q.get(i)[1]) { // 뽑은 원소 및 i 이전의 원소들을 뒤로 보낸다. q.offer(front); for(int j = 0; j &amp;lt; i; j++) { q.offer(q.poll()); } // front원소가 가장 큰 원소가 아니였으므로 false를 하고 탐색을 마침 isMax = false; break; } } // front 원소가 가장 큰 원소가 아니였으므로 다음 반복문으로 넘어감 if(isMax == false) { continue; } // front 원소가 가장 큰 원소였으므로 해당 원소는 출력해야하는 문서다. count++; if(front[0] == M) { // 찾고자 하는 문서라면 해당 테스트케이스 종료 break; } } sb.append(count).append(&#39;\\n&#39;); } System.out.println(sb); }}" }, { "title": "(Python)[백준] 접미사 배열", "url": "/posts/post220520/", "categories": "CodingTest", "tags": "CodingTest", "date": "2022-05-20 14:23:00 +0900", "snippet": "11656번: 접미사 배열문제 풀이소스 코드word = input()word_list = []for _ in word: word_list.append(word) word = word[1:]for i in sorted(word_list): print(i)" }, { "title": "(Python)[백준][해시] 추월", "url": "/posts/post220518/", "categories": "CodingTest", "tags": "CodingTest", "date": "2022-05-18 17:23:00 +0900", "snippet": "2002번: 추월정답 비율: 45.182%문제 풀이‘나온 차의 순서’가 그 뒤에 있는 차량들의 ‘들어간 순서’보다 늦은 순서라면(inCars[outCars[i]] &amp;gt; inCars[outCars[j]]) 추월한 차량이기에 +1을 해주고 이를 각 차량에 대해서 반복한다.소스 코드import sysinput = sys.stdin.readline# 차의 대수n = int(input())inCars = {}outCars = []cnt = 0# 들어간 차를 딕셔너리로 받기for i in range(n): inCars[input().rstrip(&quot;\\n&quot;)] = i# 나온 차를 리스트로 받기for i in range(n): outCars.append(input().rstrip(&quot;\\n&quot;))# 나온 i번째 차가 추월을 했는지 체크for i in range(n-1): # 마지막 n번째 차는 추월한 차가 될 수 없음 for j in range(i+1, n): if inCars[outCars[i]] &amp;gt; inCars[outCars[j]]: cnt += 1 breakprint(cnt)" }, { "title": "(Python)[백준][우선순위큐] 크리스마스 선물", "url": "/posts/post220513/", "categories": "CodingTest", "tags": "CodingTest", "date": "2022-05-13 17:23:00 +0900", "snippet": "14235번: 크리스마스 선물정답 비율: 56.582%문제 풀이우선순위큐를 이용하면 간단하게 해결할 수 있는 문제였다. 산타가 선물을 저장할 때는 우선순위 큐를 이용해 가장 가치가 높은 선물이 앞으로 오도록 하고 아이들을 만날 때 마다 큐의 가장 첫 요소를 꺼내어 준다.우선순위큐는 가장 낮은 값부터 pop되기 때문에 저장을 할 때는 -를 붙이고 꺼낼 때 다시 -를 붙여줌으로써 큰 숫자가 가장 앞에 오도록 하고 가장 먼저 꺼낼 수 있도록 할 수 있다.소스 코드import heapq import sysinput = sys.stdin.readlinen = int(input())gifts = []for i in range(n): a = list(map(int, input().split())) if a[0]==0: if len(gifts)==0: print(-1) else: tmp = -heapq.heappop(gifts) print(tmp) else: for j in range(a[0]): heapq.heappush(gifts, -a[j+1])" }, { "title": "(Python)[백준][우선순위 큐] 카드 정렬하기", "url": "/posts/post220511/", "categories": "CodingTest", "tags": "CodingTest", "date": "2022-05-11 17:23:00 +0900", "snippet": "1715번: 카드 정렬하기정답 비율: 33.966%문제 풀이처음에는 작은 값부터 더해주면서 리스트로 문제를 풀고자 했다. 근데 시간초과도 아니고 틀린 답안이라고 한다.나중에 알아보니 정렬을 계속 해줘야 하는데 그게 이루어지지 않아서 안되는 것이었다. 왜냐하면 묶여서 새로운 값이 생길 때마다 그 값과 나머지 값들을 포함해서 제일 작은 값들끼리 묶어야 하므로 계속 정렬을 해줘야 한다.이전 풀이import sysfrom tempfile import tempdirinput = sys.stdin.readline# 숫자 카드 묶음 개수 N 입력받기n = int(input())# 카드 묶음의 크기 입력받기cards = []for _ in range(n): cards.append(int(input()))# 작은 값부터 더해주기 위해 오름차순 정렬cards.sort()if len(cards)==1: print(0)else: answer = cards[0] + cards[1] sum_counts = answer for i in range(2, n): sum_counts += cards[i] answer += sum_counts print(answer)우선순위 큐(heapq)를 이용하여 풀어본다. heapq를 사용하면 push가 될 때 자동으로 정렬이 되므로 계속 정렬을 해줄 필요가 없다.소스 코드import heapq n = int(input())cardList = []for i in range(n): card = int(input()) heapq.heappush(cardList, card)answer=0while len(cardList) != 1: num1 = heapq.heappop(cardList) num2 = heapq.heappop(cardList) sum_value = num1 + num2 answer += sum_value heapq.heappush(cardList, sum_value)print(answer)" }, { "title": "(Python)[백준] 주몽", "url": "/posts/post220509/", "categories": "CodingTest", "tags": "CodingTest", "date": "2022-05-09 17:23:00 +0900", "snippet": "1940번: 주몽정답 비율: 48.621%문제 풀이갑옷을 만드는 데 필요한 수가 m이라고 할 때, m에서 nums의 각 원소들을 뺀 나머지 값이 nums에 있는지 탐색하며 문제를 해결한다.예를 들어 m = 9이고 nums의 첫 원소가 2일 때, 9 - 2 = 7이 nums에 있는지 탐색한다.소스 코드from typing import List# 재료의 개수 nn = int(input())# 갑옷을 만드는데 필요한 수 mm = int(input())# 재료들의 고유 번호nums = list(map(int, input().split()))def twoSum(nums: List[int], target: int) -&amp;gt; int: cnt = 0 for i, n in enumerate(nums): complement = target - n if complement in nums[i+1:]: # 현재 값을 버려가면서 나머지 리스트만 보기 때문에 중복이 나오지 않게 됨 cnt += 1 return cntprint(twoSum(nums, m))" }, { "title": "(Python)[백준][BFS] 특정 거리의 도시 찾기", "url": "/posts/post220507/", "categories": "CodingTest", "tags": "CodingTest", "date": "2022-05-03 17:00:00 +0900", "snippet": "18352번: 특정 거리의 도시 찾기정답 비율: 28.537%문제 풀이모든 간선의 비용이 동일할 때 최단 거리를 찾아야 한다면 bfs로 풀어보라고 한다. 모든 도시까지의 최단 거리를 계산한 뒤에, 각 최단 거리가 K인 경우를 찾으면 된다.소스코드import sysfrom collections import dequeinput = sys.stdin.readline# 도시의 개수 N, 도로의 개수 M, 거리 정보 K, 출발 도시의 번호 X 입력받기n, m, k, x = map(int, input().split())# 인접 리스트 생성graph = [[] for _ in range(n+1)] # 인덱스 0 버리고 1부터 시작# 두 도시를 연결하는 도로 입력받기for _ in range(m): a, b = map(int, input().split()) graph[a].append(b)# 출발 도시에서부터의 최단 거리 초기화distance = [-1] * (n+1)def bfs(graph, start, distance): queue = deque([start]) distance[x] = 0 # 출발 도시까지의 거리는 0 while queue: now = queue.popleft() # 현재 도시에서 방문할 수 있는 모든 도시를 확인 for next in graph[now]: # 아직 방문하지 않았다면 if distance[next] == -1: queue.append(next) # 최단 거리 갱신 distance[next] = distance[now] + 1bfs(graph, x, distance)# 최단 거리가 K인 도시 출력check = Falsefor i in range(1, n+1): if distance[i]==k: print(i) check = True# K인 도시가 없으면 -1 출력if check==False: print(-1)" }, { "title": "(Python)[백준][스택] 균형잡힌 세상", "url": "/posts/post220504/", "categories": "CodingTest", "tags": "CodingTest", "date": "2022-05-03 17:00:00 +0900", "snippet": "4949번: 균형잡힌 세상정답 비율: 32.400%문제 풀이입력으로 들어오는 왼괄호 중 가장 마지막의 여는 괄호 다음에는 반드시 그에 맞는 닫는 괄호가 입력으로 들어와야 한다. 스택으로 문제를 풀어보자.소스코드while True : sentence = input() stack = [] if sentence == &quot;.&quot; : break for i in sentence : # 여는 괄호는 스택에 추가 if i == &#39;[&#39; or i == &#39;(&#39; : stack.append(i) # 닫는 괄호가 스택 맨위의 여는 괄호랑 일치하면 스택에서 지워주기 elif i == &#39;]&#39; : if len(stack) != 0 and stack[-1] == &#39;[&#39; : stack.pop() else : stack.append(&#39;]&#39;) break elif i == &#39;)&#39; : if len(stack) != 0 and stack[-1] == &#39;(&#39; : stack.pop() else : stack.append(&#39;)&#39;) break if len(stack) == 0 : print(&#39;yes&#39;) else : print(&#39;no&#39;)" }, { "title": "(Python)[백준][그리디] 회의실 배정", "url": "/posts/post220502/", "categories": "CodingTest", "tags": "CodingTest", "date": "2022-05-02 16:15:00 +0900", "snippet": "문제 링크정답 비율: 29.358%문제 풀이시간이 2초나 주어져서 greedy 방식으로 문제를 풀어야 하는 건가 싶었다.먼저 시작 시간이 빠른 순서대로 정렬을 한다. 그 다음으로 빨리 끝나는 회의 순서대로 정렬을 해야 한다. 빨리 끝날수록 뒤에서 고려해볼 회의가 많기 때문이다. 빨리 시작하는 순서대로 정렬을 우선 한다면 오히려 늦게 끝날 수 있다.예를 들어 회의 시간이 [4,6], [2,12], [3,4], [1,2], [2,3] 이렇게 주어질 때, 시작 시간으로 정렬하면 [2,12]로 1번의 회의가 가능하지만 끝나는 시간으로 정렬하면 총 3번의 회의가 가능해진다. [1,2] ,[2,3], [3,4], [4,6], [2,12]소스코드# 회의 수 n 입력받기n = int(input())# 각 회의 시작 시간, 끝나는 시간 입력받기times = []for _ in range(n): times.append(list(map(int, input().split())))times.sort(key=lambda x: x[0]) # 시작 시간 기준으로 정렬times.sort(key=lambda x: x[1]) # 끝나는 시간 기준으로 정렬# times.sort(key=lambda x: (x[1], x[0]))cnt = 0last = 0for start, end in times: if start &amp;gt;= last: cnt += 1 last = endprint(cnt)" }, { "title": "(Python)[백준][큐] 앵무새", "url": "/posts/post220501/", "categories": "CodingTest", "tags": "CodingTest", "date": "2022-05-01 16:15:00 +0900", "snippet": "문제 링크정답비율: 27.840%문제자가용 비행기를 타고 세계 일주를 하던 pps789와 cseteram은 어느 날 엔진 고장으로 인해 이름 모를 섬에 불시착하게 된다. 그들은 이 섬을 탐험하는 도중 아주 신기한 사실을 알게 되었는데, 바로 이 섬에 사는 앵무새들은 놀라울 정도로 인간의 말을 흉내 내는 데 뛰어나다는 것이다. 그들은 서로 떨어져 섬을 탐험하기로 하였으며, 필요하다면 앵무새를 이용해 서로에게 연락하기로 약속하였다.1개월 후, pps789는 섬의 비밀을 밝힐 결정적인 증거를 찾게 된다. 그는 이 세기의 대발견을 cseteram에게 공유하고자 하였으나, 그의 발견은 방대하여 앵무새 한 마리가 기억하기에는 너무 많은 양이었다. 그렇기 에 pps789는 앵무새 한 마리 대신 앵무새 N마리를 이용하여 자신의 발견을 기록하였으며, 이 앵무새들을 cseteram을 향해 날렸다.한편 섬의 반대편에서 탐험을 계속하던 cseteram은 앵무새 N마리가 자신에게 날아와 각자 할 말을 하는 것을 보고 당황하였다. pps789가 긴 글을 전달하고 싶었던 것은 알아차렸지만, 각각의 앵무새들이 말하는 것을 차례대로 기록하다 보니 원문이 무엇인지 알 수 없을 정도로 단어의 순서가 엉켜버린 것이다. 대신 그는 관찰을 통해 몇 가지 규칙을 발견할 수 있었다. 한 앵무새는 한 문장을 기억하고 있다. 문장은 여러 단어로 이루어져 있는데, 앵무새는 이 단어들을 순서대로 말한다. 한 앵무새가 단어를 말하고 그다음 단어를 말하기 전에는 약간의 간격이 있는데, 이때 다른 앵무새가 말을 가로채고 자신의 문장을 말할 수 있다. 한 앵무새가 단어를 말하는 도중에는, 다른 앵무새가 말을 가로채지 않는다. 어떤 단어도 앵무새가 말하는 모든 문장을 통틀어 2번 이상 등장하지 않는다.앵무새는 자신이 기억하고 있는 문장을 끝까지 말한 다음 pps789에게 돌아가며, cseteram은 모든 앵무새가 돌아갈 때 까지 단어를 받아적는다. pps789가 각각의 앵무새들에게 전달한 문장 Si와, cseteram이 받아 적은 문장 L이 주어진다. 이때 문장 L이 위 규칙들을 이용하여 나올 수 있는 문장인지 판별하시오.입력첫 번째 줄에 앵무새의 수 N (1 ≤ N ≤ 100) 이 주어진다.두 번째 줄부터 N개의 줄에 걸쳐 각 앵무새가 말한 문장 Si (1 ≤ i ≤ N) 가 주어지는데, 각 문장을 이루는 단어는 스페이스 한 칸을 구분으로 하여 주어진다. 문장 Si를 이루는 단어의 수는 1개 이상 100개 이하이며, 각 단어는 1개 이상 32개 이하의 영문 소문자로 구성되어있다.N + 2 번째 줄에는 cseteram이 받아 적은 문장 L이 주어진다. 문장 L을 이루는 단어의 수는 1개 이상 10000개 이하이며, 각 단어는 1개 이상 32개 이하의 영문 소문자로 구성된다.출력문장 L이 가능한 문장이라면 Possible을, 불가능한 문장이라면 Impossible을 출력한다.예제 입력 13i want to see younext weekgood lucki want next good luck week to see you예제 출력 1Possible예제 입력 22i foundan interesting cavei found an cave interesting예제 출력 2Impossible예제 입력 32pleasebe carefulpen pineapple apple pen예제 출력 3Impossible문제 풀이앵무새들은 단어들을 순서대로 말하므로 큐로 문제를 풀어보자.각 앵무새가 말하는 문장들과 실제로 들은 문장을 큐에 저장하고 반복문으로 각 큐의 맨 앞에 있는 단어가 실제로 들은 문장이 저장되어 있는 큐의 맨 앞과 같으면 pop 시킨다.반복문을 다 돌았는데 일치하는 단어가 없거나 실제로 들은 문장이 모두 다 pop 되었는데 앵무새들이 말해야 할 단어들이 남아있다면(앵무새들은 모든 단어들을 다 말해야 하므로) impossible을 출력하고 그렇지 않으면 possible을 출력한다.소스코드from typing import Listfrom collections import deque# 앵무새의 수 n 입력받기n = int(input())parrot = []# 앵무새가 말한 문장 입력받아서 큐로 저장for _ in range(n): parrot.append(deque(input().split())) def possible(sentence: List[str], parrot: List[deque]) -&amp;gt; bool : i = 0 cnt = 0 # sentence가 빌 때까지 반복해서 실제 문장의 단어가 있는지 확인 while sentence: if parrot[i] and sentence[0] == parrot[i][0]: parrot[i].popleft() sentence.popleft() cnt = 0 else: if cnt == n: # 실제 문장의 단어가 세 앵무새의 큐에 없을 때 return False cnt += 1 i = (i + 1) % n # i = 0, 1, 2 # while 문이 끝났다는 건 sentence가 다 pop돼서 비었다는 뜻 # 앵무새가 모든 단어들을 다 말해야 하므로 각 앵무새의 큐가 비어있는지 확인 empty = 0 for j in range(n): if not parrot[j]: empty += 1 if empty == n: return True else: return False# 실제 문장 입력받기sentence = deque(input().split())if possible(sentence, parrot): print(&quot;Possible&quot;)else: print(&quot;Impossible&quot;)" }, { "title": "(Python) 최단 경로 실전 문제 - 미래 도시", "url": "/posts/post220412/", "categories": "CodingTest", "tags": "CodingTest", "date": "2022-04-12 14:15:00 +0900", "snippet": " 본 글은 “이것이 취업을 위한 코딩 테스트다 with 파이썬” 교재를 참고한 것임문제문제 풀이해당 노드를 거쳐 가는 경우를 고려하며 모든 지점에서 다른 모든 지점까지의 최단 경로를 모두 구해야 하는 경우이므로 플로이드 워셜알고리즘을 사용한다. 따라서 2차원 리스트에 최단 거리를 저장한다.소스코드INF = int ( 1e9 ) # 무한을 의미하는 값으로 10 억을 설정# 노드의 개수 및 간선의 개수를 입력받기n, m = map(int, input().split())# 2 차원 리스트(그래프 표현)를 만들고, 모든 값을 무한으로 초기화graph = [[ INF ] * ( n + 1 ) for _ in range ( n + 1 )]# 자기 자신에서 자기 자신으로 가는 비용은 0 으로 초기화for a in range ( 1 , n + 1 ): for b in range ( 1 , n + 1 ): if a == b : graph [ a ][ b ] = 0# 각 간선에 대한 정보를 입력받아, 그 값으로 초기화for _ in range ( m ): # A 에서 B 로 가는 비용은 1이라고 설정 a , b = map ( int , input (). split ()) graph [ a ][ b ] = 1 graph [ b ][ a ] = 1# 거쳐갈 노드 k와 최종 목적지 노드 x를 입력받기k, x = map(int, input().split())# 점화식에 따라 플로이드 워셜 알고리즘을 수행for k in range ( 1 , n + 1 ): for a in range ( 1 , n + 1 ): for b in range ( 1 , n + 1 ): graph [ a ][ b ] = min ( graph [ a ][ b ], graph [ a ][ k ] + graph [ k ][ b ])# 수행된 결과를 출력distance = graph [ 1 ][ k ] + graph [ k ][ x ]# 도달할 수 없는 경우, - 1 을 출력if distance &amp;gt;= INF : print (&quot;- 1 &quot;) # 도달할 수 있다면, 최단 거리를 출력else : print ( distance )" }, { "title": "(Python) 최단 경로 실전 문제 - 전보", "url": "/posts/post220411/", "categories": "CodingTest", "tags": "CodingTest", "date": "2022-04-11 14:15:00 +0900", "snippet": " 본 글은 “이것이 취업을 위한 코딩 테스트다 with 파이썬” 교재를 참고한 것임문제문제 풀이한 도시에서 다른 도시까지의 최단 거리를 구하면 되므로 다익스트라 알고리즘을 이용한다. 또한 N, M의 범위가 상당히 크기 때문에 우선순위 큐를 사용하여 다익스트라 알고리즘을 작성해야 한다.소스코드import heapqimport sys input = sys . stdin . readline INF = int ( 1e9 ) # 무한을 의미하는 값으로 10 억을 설정# 노드의 개수, 간선의 개수, 시작노드를 입력받기n, m, start = map(int, input().split()) # 각 노드에 연결되어 있는 노드에 대한 정보를 담는 리스트를 만들기graph = [[] for i in range (n + 1)] # 최단 거리 테이블을 모두 무한으로 초기화distance = [ INF ] * (n + 1)# 모든 간선 정보를 입력받기for _ in range(m): x, y, z = map(int, input().split()) # a 번 노드에서 b 번 노드로 가는 비용이 c 라는 의미 graph[x].append((y, z))def dijkstra(start): q = [] # 시작 노드로 가기 위한 최단 경로는 0 으로 설정하여, 큐에 삽입 heapq.heappush(q, (0 ,start)) distance [start] = 0 while q : # 큐가 비어있지 않다면 # 가장 최단 거리가 짧은 노드에 대한 정보 꺼내기 dist, now = heapq.heappop(q) # 현재 노드가 이미 처리된 적이 있는 노드라면 무시 if distance[now] &amp;lt; dist : continue # 현재 노드와 연결된 다른 인접한 노드들을 확인 for i in graph[now]: cost = dist + i[1] # 현재 노드를 거쳐서, 다른 노드로 이동하는 거리가 더 짧은 경우 if cost &amp;lt; distance [i[0]]: distance[i[0]] = cost heapq.heappush(q, (cost, i[0]))# 다익스트라 알고리즘 수행dijkstra(start)# 도달할 수 있는 노드의 개수count = 0# 도달할 수 있는 노드와의 최단 거리의 합# sum_dist = 0# for d in distance :# # 도달할 수 있는 노드인 경우# if d != INF :# count += 1# sum_dist = max(sum_dist, d)# 도달할 수 있는 노드 중에서, 가장 멀리 있는 노드와의 최단 거리max_distance = 0 for d in distance : # 도달할 수 있는 노드인 경우 if d != INF : count += 1 max_distance = max(max_distance, d)# 시작 노드는 제외해야 하므로 count - 1 을 출력print(count - 1, max_distance )" }, { "title": "(Python)[Programmers][구현] 삼각 달팽이", "url": "/posts/post220407/", "categories": "CodingTest", "tags": "CodingTest", "date": "2022-04-07 23:36:00 +0900", "snippet": "문제정수 n이 매개변수로 주어집니다. 다음 그림과 같이 밑변의 길이와 높이가 n인 삼각형에서 맨 위 꼭짓점부터 반시계 방향으로 달팽이 채우기를 진행한 후, 첫 행부터 마지막 행까지 모두 순서대로 합친 새로운 배열을 return 하도록 solution 함수를 완성해주세요.제한사항 n은 1 이상 1,000 이하입니다.입출력 예문제 풀이구현 문제이므로 좌표를 이용하여 풀어보고자 했다. 문제를 보면 하-우-상 방향으로 움직이고, 움직이는 칸은 만약 n=4이면 4-3-2-1, n=5이면 5-4-3-2-1 만큼 움직이는 것을 알 수 있다.소스코드from typing import Listdef solution(n: int) -&amp;gt; List[int]: answer = [] # 삼각형 만들기 arr = [] for i in range(1, n+1): arr.append([0] * i) # 시작 좌표 x, y = -1, 0 # 아래부터 내려가므로 val = 1 # 하-우-상 방향순으로 이차원 리스트에 값 채워넣기 for i in range(n): # 방향(하, 우, 상) for _ in range(i, n): if i % 3 == 0: # 하 x += 1 arr[x][y] = val elif i % 3 == 1: # 우 y += 1 arr[x][y] = val else: # 상 x -= 1 y -= 1 arr[x][y] = val val += 1 for element in arr: answer += element return answerprint(solution(4))print(solution(5))print(solution(6))[1, 2, 9, 3, 10, 8, 4, 5, 6, 7][1, 2, 12, 3, 13, 11, 4, 14, 15, 10, 5, 6, 7, 8, 9][1, 2, 15, 3, 16, 14, 4, 17, 21, 13, 5, 18, 19, 20, 12, 6, 7, 8, 9, 10, 11]" }, { "title": "(Python)[백준][이진탐색] 과자 나눠주기", "url": "/posts/post220406/", "categories": "CodingTest", "tags": "CodingTest", "date": "2022-04-06 23:15:00 +0900", "snippet": "문제링크정답 비율: 40.280%문제명절이 되면, 홍익이 집에는 조카들이 놀러 온다.  떼를 쓰는 조카들을 달래기 위해 홍익이는 막대 과자를 하나씩 나눠준다.조카들이 과자를 먹는 동안은 떼를 쓰지 않기 때문에, 홍익이는 조카들에게 최대한 긴 과자를 나눠주려고 한다.그런데 나눠준 과자의 길이가 하나라도 다르면 조카끼리 싸움이 일어난다. 따라서 반드시 모든 조카에게 같은 길이의 막대 과자를 나눠주어야 한다.M명의 조카가 있고 N개의 과자가 있을 때, 조카 1명에게 줄 수 있는 막대 과자의 최대 길이를 구하라.단, 막대 과자는 길이와 상관없이 여러 조각으로 나눠질 수 있지만, 과자를 하나로 합칠 수는 없다. 단, 막대 과자의 길이는 양의 정수여야 한다.입력첫째 줄에  조카의 수 M (1 ≤ M ≤ 1,000,000), 과자의 수 N (1 ≤ N ≤ 1,000,000)이 주어진다.둘째 줄에 과자 N개의 길이 L1, L2, …, LN이 공백으로 구분되어 주어진다. 과자의 길이는 (1 ≤ L1, L2, …, LN ≤ 1,000,000,000) 를 만족한다.출력첫째 줄에 조카 1명에게 줄 수 있는 막대 과자의 최대 길이를 출력한다.단, 모든 조카에게 같은 길이의 막대과자를 나눠줄 수 없다면, 0을 출력한다.예제 입력 13 101 2 3 4 5 6 7 8 9 10예제 출력 18예제 입력 24 310 10 15예제 출력 27문제 풀이조카의 수와 과자의 수의 범위가 꽤 크므로 이진 탐색으로 문제를 풀어보자.아래와 같이 코드를 작성했는데 시간 초과가 나왔다. cutting() 함수에서 재귀를 사용하는 과정 때문인 걸로 보인다.import sys# 조카의 수와 과자의 수 입력받기m, n = map(int, sys.stdin.readline().split())# 과자의 길이 공백으로 입력받기arr = list(map(int, sys.stdin.readline().split()))# 특정 높이로 과자를 잘랐을 때 몇명에게 줄 수 있는지 확인하는 함수. 재귀def cutting(array, h): global count # 전역변수 count를 사용 if len(array) == 0: return count n_array = [] for i in range(len(array)): temp = array[i] - h if temp &amp;gt;= 0: count += 1 if temp &amp;gt;= h: n_array.append(temp) # 시간 복잡도 줄이기 위해 새로 array 생성 return cutting(n_array, h)start = 0end = max(arr)h_list = []while start &amp;lt;= end: h = ( start + end ) // 2 count = 0 # 조카수보다 과자가 부족한 경우 왼쪽 확인 if cutting(arr, h) &amp;lt; m: end = h - 1 # 조카수보다 과자가 충분한 경우 오른쪽 확인 else : # cutting(arr, h) &amp;gt;= m h_list.append(h) # 최소한 m이 나오면 되고 최대의 h를 구해야 하므로 start = h + 1print(h_list)print(max(h_list))재귀를 사용하지 않고 cutting 함수를 구현했다. 이번엔 ZeroDivisionError가 발생했다. cutting() 함수에서 count += snack // h 구하는 과정에서 h = 0으로 나누는 경우(모든 조카에게 같은 길이의 막대과자를 나눠줄 수 없는 경우)를 고려하지 않아서 그런 걸로 보인다.import sys# 조카의 수와 과자의 수 입력받기m, n = map(int, sys.stdin.readline().split())# 과자의 길이 공백으로 입력받기snacks = list(map(int, sys.stdin.readline().split()))# 특정 높이로 과자를 잘랐을 때 몇명에게 줄 수 있는지 확인하는 함수def cutting(snacks, h): count = 0 for snack in snacks: count += snack // h return countstart = 0end = max(snacks)h_list = []while start &amp;lt;= end: h = ( start + end ) // 2 # 조카수보다 과자가 부족한 경우 왼쪽 확인 elif cutting(snacks, h) &amp;lt; m: end = h - 1 # 조카수보다 과자가 충분한 경우 오른쪽 확인 else : # cutting(arr, h) &amp;gt;= m h_list.append(h) # 최소한 m이 나오면 되고 최대의 h를 구해야 하므로 start = h + 1# print(h_list)print(max(h_list))최종 소스코드import sys# 조카의 수와 과자의 수 입력받기m, n = map(int, sys.stdin.readline().split())# 과자의 길이 공백으로 입력받기snacks = list(map(int, sys.stdin.readline().split()))# 특정 높이로 과자를 잘랐을 때 몇명에게 줄 수 있는지 확인하는 함수def cutting(snacks, h): count = 0 if h == 0: return count for snack in snacks: count += snack // h return countstart = 0end = max(snacks)h_list = []while start &amp;lt;= end: h = ( start + end ) // 2 if cutting(snacks, h) == 0: h_list.append(h) break # 조카수보다 과자가 부족한 경우 왼쪽 확인 elif cutting(snacks, h) &amp;lt; m: end = h - 1 # 조카수보다 과자가 충분한 경우 오른쪽 확인 else : # cutting(arr, h) &amp;gt;= m h_list.append(h) # 최소한 m이 나오면 되고 최대의 h를 구해야 하므로 start = h + 1# print(h_list)print(max(h_list))" }, { "title": "(Python)[백준][dfs/bfs] 바이러스", "url": "/posts/post220403/", "categories": "CodingTest", "tags": "CodingTest", "date": "2022-04-03 23:36:00 +0900", "snippet": "문제 링크정답 비율: 45.670%문제신종 바이러스인 웜 바이러스는 네트워크를 통해 전파된다. 한 컴퓨터가 웜 바이러스에 걸리면 그 컴퓨터와 네트워크 상에서 연결되어 있는 모든 컴퓨터는 웜 바이러스에 걸리게 된다.예를 들어 7대의 컴퓨터가 &amp;lt;그림 1&amp;gt;과 같이 네트워크 상에서 연결되어 있다고 하자. 1번 컴퓨터가 웜 바이러스에 걸리면 웜 바이러스는 2번과 5번 컴퓨터를 거쳐 3번과 6번 컴퓨터까지 전파되어 2, 3, 5, 6 네 대의 컴퓨터는 웜 바이러스에 걸리게 된다. 하지만 4번과 7번 컴퓨터는 1번 컴퓨터와 네트워크상에서 연결되어 있지 않기 때문에 영향을 받지 않는다.어느 날 1번 컴퓨터가 웜 바이러스에 걸렸다. 컴퓨터의 수와 네트워크 상에서 서로 연결되어 있는 정보가 주어질 때, 1번 컴퓨터를 통해 웜 바이러스에 걸리게 되는 컴퓨터의 수를 출력하는 프로그램을 작성하시오.입력첫째 줄에는 컴퓨터의 수가 주어진다. 컴퓨터의 수는 100 이하이고 각 컴퓨터에는 1번 부터 차례대로 번호가 매겨진다. 둘째 줄에는 네트워크 상에서 직접 연결되어 있는 컴퓨터 쌍의 수가 주어진다. 이어서 그 수만큼 한 줄에 한 쌍씩 네트워크 상에서 직접 연결되어 있는 컴퓨터의 번호 쌍이 주어진다.출력1번 컴퓨터가 웜 바이러스에 걸렸을 때, 1번 컴퓨터를 통해 웜 바이러스에 걸리게 되는 컴퓨터의 수를 첫째 줄에 출력한다.예제 입력 1761 22 31 55 25 64 7예제 출력 14문제 풀이묶음(집합)을 고려해야 하는 문제이므로 dfs로 풀어보자.# 컴퓨터의 수(노드의 개수) 입력받기n = int(input())# 연결되어 있는 컴퓨터 쌍의 수(간선의 개수) 입력받기m = int(input()) # 2차원 리스트(인접 행렬)graph = [[] for _ in range(n + 1)] # 1부터 시작하므로 n+1# 연결된 컴퓨터 쌍 입력받기for _ in range(m): a, b = map(int, input().split()) graph[a].append(b) graph[b].append(a)# 노드가 방문한 정보를 기록하는 리스트visited = [0] * (n + 1)def dfs(graph, v, visited): # 현재 노드를 방문 처리 visited[v] = 1 # 현재 노드와 연결된 다른 노드를 재귀적으로 방문 for i in graph[v]: if visited[i] == 0: dfs(graph, i, visited)dfs(graph, 1, visited)# 방문한 노드수 - 노드1print(sum(visited)-1)" }, { "title": "(Python)[백준][이진탐색] 숫자 카드", "url": "/posts/post220401/", "categories": "CodingTest", "tags": "CodingTest", "date": "2022-04-01 22:15:00 +0900", "snippet": "문제 링크정답 비율: 48.915%문제숫자 카드는 정수 하나가 적혀져 있는 카드이다. 상근이는 숫자 카드 N개를 가지고 있다. 정수 M개가 주어졌을 때, 이 수가 적혀있는 숫자 카드를 상근이가 가지고 있는지 아닌지를 구하는 프로그램을 작성하시오.입력첫째 줄에 상근이가 가지고 있는 숫자 카드의 개수 N(1 ≤ N ≤ 500,000)이 주어진다. 둘째 줄에는 숫자 카드에 적혀있는 정수가 주어진다. 숫자 카드에 적혀있는 수는 -10,000,000보다 크거나 같고, 10,000,000보다 작거나 같다. 두 숫자 카드에 같은 수가 적혀있는 경우는 없다.셋째 줄에는 M(1 ≤ M ≤ 500,000)이 주어진다. 넷째 줄에는 상근이가 가지고 있는 숫자 카드인지 아닌지를 구해야 할 M개의 정수가 주어지며, 이 수는 공백으로 구분되어져 있다. 이 수도 -10,000,000보다 크거나 같고, 10,000,000보다 작거나 같다출력첫째 줄에 입력으로 주어진 M개의 수에 대해서, 각 수가 적힌 숫자 카드를 상근이가 가지고 있으면 1을, 아니면 0을 공백으로 구분해 출력한다.예제 입력 156 3 2 10 -10810 9 -5 2 3 4 5 -10예제 출력 11 0 0 1 1 0 0 1문제 풀이가지고 있는 카드의 범위(1 ≤ N ≤ 500,000)가 꽤 크기 때문에 이진 탐색으로 문제를 풀어보고자 한다.요소가 엄청 작은 문제가 아닌 이상, 순차 탐색은 시간초과가 나오기 때문에 이분 탐색을 이용하자.소스코드from typing import List# 이진 탐색(반복문) 알고리즘def binary_search(arr: List[int], target: int, start: int, end: int) -&amp;gt; bool: while(start &amp;lt;= end): mid = (start + end) // 2 # 찾은 경우 중간점 인덱스 반환 if arr[mid] == target: return mid # 중간점의 값보다 찾고자 하는 값이 작은 경우 왼쪽 확인 elif arr[mid] &amp;gt; target: end = mid - 1 # 중간점의 값보다 찾고자 하는 값이 큰 경우 오른쪽 확인 else: start = mid + 1 return None# 가지고 있는 숫자 카드 개수 입력받기n = int(input())# 숫자 카드 입력받기card_arr = list(map(int, input().split(&#39; &#39;)))# 찾을 정수 개수 입력받기m = int(input())# 찾을 정수 입력받기num_arr = list(map(int, input().split(&#39; &#39;)))# 이진 탐색을 수행하기 위해 정렬card_arr.sort()# 정수가 있는지 하나씩 확인for target in num_arr: result = binary_search(card_arr, target, 0, n-1) # 끝의 인덱스는 n-1 if result != None: print(&#39;1&#39;, end=&#39; &#39;) else: print(&#39;0&#39;, end=&#39; &#39;)56 3 2 10 -10810 9 -5 2 3 4 5 101 0 0 1 1 0 0 1" }, { "title": "(Python) 이진 탐색 실전 문제2", "url": "/posts/post220324/", "categories": "CodingTest", "tags": "CodingTest", "date": "2022-03-24 20:15:00 +0900", "snippet": " 본 글은 “이것이 취업을 위한 코딩 테스트다 with 파이썬” 교재를 참고한 것임문제문제풀이전형적인 이진 탐색 문제이자 파라메트릭 서치(parametric search) 유형의 문제이다. 파라메트릭 서치는 최적화 문제를 결정 문제(’예’, ‘아니오’로 답하는 문제)로 바꾸어 해결하는 기법이다.범위 내에서 조건을 만족하는 가장 큰 값을 찾으라는 최적화 문제라면 이진 탐색으로 결정 문제를 해결하면서 범위를 좁혀갈 수 있다. 코딩 테스트나 프로그래밍 대회에서는 보통 파라메트릭 서치 유형은 이진 탐색을 이용하여 해결한다.이 문제의 풀이 아이디어는 적절한 높이를 찾을 때까지 절단기의 높이 h를 반복해서 조정하는 것이다. ‘현재 이 높이로 자르면 조건을 만족할 수 있는가?’를 확인한 뒤에 조건의 만족 여부(’예’, ‘아니오’)에 따라서 탐색 범위를 좁혀 나간다.절단기의 높이(탐색 범위)는 1부터 10억까지의 정수 중 하나인데, 탐색 범위가 매우 크기 때문에 이진 탐색을 떠올렸다. 높이 범위가 한정적이었다면 순차 탐색으로도 해결할 수 있지만, 이 문제에서 높이는 최대 10억까지의 정수이므로 순차 탐색은 시간 초과를 받을 것이다.반면 높이를 이진 탐색으로 찾는다면 대략 31번 만에 모든 경우의 수를 고려할 수 있다. 떡의 개수가 최대 100만 개이므로 절단기 높이를 바꿀 때마다 모든 떡을 체크하는 경우 대략 최대 3,000만 번 정도의 연산으로 문제를 풀 수 있다.소스코드내풀이# 문제 범위가 너무 크다(10억) -&amp;gt; 이진 탐색?# 잘랐을 때의 떡의 양 계산하는 함수def cutting(arr, h, n): total = 0 for i in range(n): if arr[i] &amp;gt; h: total += arr[i] - h return total# def cutting(arr, h):# for i in range(len(arr)):# temp = arr[i]- h# if temp &amp;lt; 0:# arr[i] = 0# else:# arr[i] = temp# return sum(arr)# 떡의 개수 N, 요청한 떡의 길이 M 입력받기n, m = map(int, input().split(&#39; &#39;))# 개별 떡의 높이arr = list(map(int, input().split(&#39; &#39;)))start = 0end = max(arr)h_list = []while start &amp;lt;= end : h = ( start + end ) // 2 # 요청한 떡의 길이보다 작은 경우 왼쪽 확인 if cutting(arr, h) &amp;lt; m : end = h - 1 # 요청한 떡의 길이보다 충분한 경우 오른쪽 확인 else : # cutting(arr, h) &amp;gt;= m h_list.append(h) # 최소한 m이 나오면 되고 최대의 h를 구해야 하므로 start = h + 1print(h_list)print(max(h_list))교재풀이도 내풀이와 비슷했으므로 따로 첨부를 하지 않는다.잘랐을 때의 떡의 양 계산하는 cutting() 함수를 구현하여 찾고자 하는 절단기의 높이 h를 이진 탐색으로 찾는다.절단기의 높이 h는 0부터 가장 긴 떡의 길이 안에 있어야 한다. 따라서 end는 입력받은 떡 길이 중 제일 긴 떡의 길이로 한다.현재 절단기 높이에서 만들어지는 떡의 양이 요청한 떡의 양보다 적은 경우 절단기 높이를 작게 해야 하므로 왼쪽을 탐색한다.현재 절단기 높이에서 만들어지는 떡의 양이 요청한 떡의 양보다 충분한 경우, 최소한 m이 나오면 되고 그중 최대의 h를 구하라는 게 문제이므로 h를 절단기 높이의 후보 리스트인 h_list에 추가해준다. 그리고 절단기 높이를 크게 해보기 위해 오른쪽을 탐색한다.설명을 덧붙이면, if 조건문에서 cutting(arr, h) == m 으로 조건을 안 한 이유는 최소한 m이 나오면 되고 그중 최대의 h를 구하라는 게 문제이기 때문에 cutting(arr, h) &amp;gt;= m 이기만 하면 h_list에 추가한 것이다.또한 주석 처리된 cutting() 함수는 내가 처음에 작성한 함수인데 저렇게 작성하면 입력받은 원본 arr 함수까지 수정되기 때문에 함수 안에서 따로 리스트를 선언해주거나 원본 값을 변경시키지 않도록 주의해야 할 것 같다." }, { "title": "(Python) 이진 탐색 실전 문제1", "url": "/posts/post220323/", "categories": "CodingTest", "tags": "CodingTest", "date": "2022-03-23 23:15:00 +0900", "snippet": " 본 글은 “이것이 취업을 위한 코딩 테스트다 with 파이썬” 교재를 참고한 것임문제문제풀이내풀이# 데이터의 범위가 1,000,000 이하이기 때문에 계수 정렬을 사용 가능할 것 같음# 매장의 부품 개수 N 입력받기n = int(input())# 매장의 부품 종류 입렫받기parts = list(map(int, input().split(&#39; &#39;)))# 요청 받은 부품 개수 M 입력받기m = int(input())# 요청 받은 부품 종류 입렫받기req_parts = list(map(int, input().split(&#39; &#39;)))# 모든 범위를 포함하는 리스트 선언(모든 값은 0 으로 초기화)count = [0] * (max(parts) + 1)for i in range(len(parts)): count[parts[i]] += 1 # 각 데이터에 해당하는 인덱스의 값 증가result = []for j in range(len(req_parts)): if count[req_parts[j]] &amp;gt;= 1: result.append(&#39;yes&#39;) else: result.append(&#39;no&#39;)print(result)[‘no’, ‘yes’, ‘yes’]문제에서 데이터의 범위가 1,000,000 이하이기 때문에 계수 정렬을 사용 가능할 것 같았다.모든 범위의 번호를 포함할 수 있는 크기의 리스트를 만든 뒤에, 특정 번호 부품이 있는지 확인하여 문제를 해결할 수 있었다.교재에서는 내풀이처럼 계수 정렬로 풀거나, 탐색을 통해 문제를 해결하거나, 또는 set()함수를 이용하여 문제를 해결한다.교재풀이# 이진 탐색# 이진 탐색 소스코드 구현(반복문)def binary_search ( array , target , start , end ): while start &amp;lt;= end : mid = ( start + end ) // 2 # 찾은 경우 중간점 인덱스 반환 if array [ mid ] == target : return mid # 중간점의 값보다 찾고자 하는 값이 작은 경우 왼쪽 확인 elif array [ mid ] &amp;gt; target : end = mid - 1 # 중간점의 값보다 찾고자 하는 값이 큰 경우 오른쪽 확인 else : start = mid + 1 return None# 매장의 부품 개수 N 입력받기n = int(input())# 매장의 부품 종류 입렫받기parts = list(map(int, input().split(&#39; &#39;)))# 요청 받은 부품 개수 M 입력받기m = int(input())# 요청 받은 부품 종류 입렫받기req_parts = list(map(int, input().split(&#39; &#39;)))# 이진 탐색을 수행하기 위해 사전에 정렬 수행parts.sort()# 손님이 확인 요청한 부품 번호를 하나씩 확인for i in req_parts : # 해당 부품이 존재하는지 확인 result = binary_search ( parts , i , 0 , n - 1 ) if result != None : print (&#39; yes &#39;, end = &#39; &#39;) else : print (&#39; no &#39;, end = &#39; &#39;)이진 탐색으로 풀 경우, 먼저 매장 내 N개의 부품을 정렬하고, 그 이후에 M개의 찾고자 하는 부품이 각각 매장이 존재하는지 탐색한다. 정렬되어 있기 때문에 이진 탐색이 가능하다.# set() 함수 이용# N (가게의 부품 개수)을 입력받기n = int ( input ()) # 가게에 있는 전체 부품 번호를 입력받아서 집합( set ) 자료형에 기록parts = set ( map ( int , input (). split ()))# M (손님이 확인 요청한 부품 개수)을 입력받기m = int ( input ()) # 손님이 확인 요청한 전체 부품 번호를 공백으로 구분하여 입력req_parts = list ( map ( int , input (). split ()))# 손님이 확인 요청한 부품 번호를 하나씩 확인for i in req_parts : # 해당 부품이 존재하는지 확인 if i in parts : print (&#39; yes &#39;, end = &#39; &#39;) else : print (&#39; no &#39;, end = &#39; &#39;)이 문제는 단순히 특정한 수가 한 번이라도 등장했는지를 검사하면 되므로 집합 자료형을 초기화하는 함수인 set() 함수를 사용하여 문제를 해결할 수도 있다.시간 복잡도부품을 찾는 과정에서 시간 복잡도는 최악의 경우 $O(MlogN)$이고, 파이썬 정렬 라이브러리를 이용하여 N개의 부품을 정렬하기 위해서는 $O(NlogN)$의 연산이 필요하다.결과적으로 이진 탐색을 사용한 경우의 시간 복잡도는 $O((M+N)*logN)$이다.정렬의 시간 복잡도에 관해서는 여기에서 확인할 수 있다." }, { "title": "(Python) 이진 탐색(Binary Search)", "url": "/posts/post220322/", "categories": "CodingTest", "tags": "CodingTest", "date": "2022-03-22 23:15:00 +0900", "snippet": "이진 탐색(Binary Search) : 반으로 쪼개면서 탐색하기 예시의 그림은 “이것이 취업을 위한 코딩 테스트다 with 파이썬” 교재를 참고한 것임.배열 내부의 데이터가 정렬되어 있어야만 사용할 수 있는 알고리즘이다.이진 탐색은 위치를 나타내는 3개의 변수를 사용하는데, 탐색하고자 하는 범위의 시작점, 끝점, 그리고 중간점이다. 찾으려는 데이터와 중간점 위치에 있는 데이터를 반복적으로 비교해서 데이터를 찾는다.예시10개의 데이터 중에서 값이 4인 원소를 찾는 예시이다. 초기값이 정렬되어 있는 것이 중요하다.step 1시작점과 끝점을 확인하고 중간점을 정한다. 중간점이 실수일 때는 소수점 이하를 버린다. 예시에서는 중간점이 4.5에서 소수점 이하를 버려서 [4]이다. 중간점 [4]의 데이터 8이 더 크므로 중간점 이후의 값은 확인할 필요가 없다. 그다음 끝점을 [4]의 이전인 [3]으로 변경한다.step 2중간점에 위치한 데이터 2는 찾으려는 데이터 4보다 작으므로 2이하인 데이터는 확인할 필요가 없다. 그다음 시작점을 [2]로 변경한다.step 3중간점은 2.5에서 소수점을 버려서 [2]이다. 중간점에 위치한 데이터 4는 찾으려는 데이터와 동일하므로 탐색을 종료한다.전체 데이터는 10개지만, 이진 탐색을 이용해 총 3번의 탐색으로 원소를 찾을 수 있었다. 이진 탐색은 한 번 확인할 때마다 확인하는 원소의 개수가 절반씩 줄어든다는 점에서 단계마다 2로 나누는 것과 동일하므로 연산 횟수는 $log_2N$에 비례하여 시간 복잡도가 $O(logN)$이다.소스코드# 이진 탐색 소스코드 구현(재귀 함수)def binary_search(array , target , start , end): if start &amp;gt; end : # 값을 못 찾는 경우 mid + 1 이므로 return None mid = ( start + end ) // 2 # 몫만 구하기 위해 # 찾은 경우 중간점 인덱스 반환 if array [ mid ] == target : return mid # 중간점의 값보다 찾고자 하는 값이 작은 경우 왼쪽 확인 elif array [ mid ] &amp;gt; target : return binary_search ( array , target , start , mid - 1 ) # 중간점의 값보다 찾고자 하는 값이 큰 경우 오른쪽 확인 else : return binary_search ( array , target , mid + 1 , end )# n (원소의 개수)과 target (찾고자 하는 문자열)을 입력받기n, target = map(int, input().split()) # 전체 원소 입력받기array = list(map(int, input().split()))# 이진 탐색 수행 결과 출력result = binary_search ( array , target , 0 , n - 1 )if result == None : print (&quot;원소가 존재하지 않습니다.&quot;)else : print ( result + 1 )코딩 테스트에서 이진 탐색은 단골로 나오는 문제이니 가급적 외우길 권장한다.코딩 테스트의 이진 탐색 문제는 탐색 범위가 큰 상황에서의 탐색을 가정하는 문제가 많다. 따라서 탐색 범위가 2,000만을 넘어가면 이진 탐색으로 문제에 접근해보자.처리해야 할 데이터의 개수나 값이 1,000만 단위 이상으로 이진 탐색과 같이 $O(logN)$의 속도를 내야 하는 알고리즘을 떠올려야 문제를 풀 수 있는 경우가 많다.트리 자료구조이진 탐색은 전제 조건이 데이터 정렬이다. 데이터베이스는 내부적으로 대용량 데이터 처리에 적합한 트리 자료구조를 이용하여 항상 데이터가 정렬되어 있다.따라서 데이터베이스에서의 탐색은 이진탐색과는 조금 다르지만 이진 탐색과 유사한 방법을 이용해 탐색을 항상 빠르게 수행하도록 설계되어 있어서 데이터가 많아도 탐색하는 속도가 바르다.큰 데이터를 처리하는 소프트웨어는 대부분 데이터를 트리 자료구조로 저장해서 이진 탐색과 같은 탐색 기법을 이용해 빠르게 탐색이 가능하다.이진 탐색 트리이진 탐색이 동작할 수 있도록 고안된, 효율적인 탐색이 가능한 자료구조로 다음과 같은 특징을 가진다. 부모 노드보다 왼쪽 자식 노드가 작다. 부모 노드보다 오른쪽 자식 노드가 크다.이진 탐색 트리 자료구조를 구현하도록 요구하는 문제는 출제 빈도가 낮으므로, 이진 탐색 트리가 미리 구현되어 있다고 가정하고 데이터를 조회하는 과정만 알아보자.예시 예시의 그림은 “이것이 취업을 위한 코딩 테스트다 with 파이썬” 교재를 참고한 것임찾는 원소가 37일 때,step 1루트노드에서 부모 노드의 왼쪽 자식 노드는 30이하이므로 왼쪽에 있는 모든 노드는 확인할 필요가 없다.step 248 부모 노드에서 오른쪽 자식 노드는 모두 48이상이므로 확인할 필요가 없다.step 3현재 방문한 노드의 값이 찾는 값과 일치하므로 탐색을 마친다.빠르게 입력 받기이진 탐색 문제는 입력 데이터가 많거나 탐색 범위가 매우 넓은 편이다. 데이터의 개수가 1,000만개를 넘어가거나 탐색 범위의 크기가 1,000억 이상이라면 이진 탐색 알고리즘을 의심해보자.입력 데이터가 많은 문제는 sys 라이브러리의 readline() 함수를 이용하면 시간 초과를 피할 수 있다. sys 라이브러리를 사용할 때는 한 줄 입력 받고 나서 rstrip() 함수를 꼭 호출하자. readline()으로 입력하면 입력 후 엔터가 줄바꿈 기호로 입력되는데 이 공백 문자를 제거할 수 있다." }, { "title": "(Python) 정렬 실전 문제", "url": "/posts/post220321/", "categories": "CodingTest", "tags": "CodingTest", "date": "2022-03-21 23:15:00 +0900", "snippet": " 본 글은 “이것이 취업을 위한 코딩 테스트다 with 파이썬” 교재를 참고한 것임 문제성적이 낮은 순서로 학생 출력하기내풀이# 학생 수 N 입력받기n = int(input())# 학생의 이름과 성적 입력받기dict = {}for i in range(n): name, score = input().split(&#39; &#39;) dict[name] = int(score)# value값을 기준으로 정렬한 key &quot;리스트&quot;를 반환sorted_dict = sorted(dict, key=lambda x :dict[x])for i in range(len(sorted_dict)): print(sorted_dict[i], end=&#39; &#39;)간단하게 딕셔너리를 정의하여 value 값(성적 점수)을 기준으로 key(학생 이름)을 정렬하여 출력한다.sorted()를 함수를 사용하면 “리스트” 형태로 반환된다.교재풀이# N 을 입력받기n = int ( input ())# N 명의 학생 정보를 입력받아 리스트에 저장array = []for i in range ( n ): input_data = input (). split () # 이름은 문자열 그대로, 점수는 정수형으로 변환하여 저장 array.append((input_data[ 0 ], int( input_data [ 1 ])))# 키( Key )를 이용하여, 점수를 기준으로 정렬array = sorted ( array , key = lambda student : student [ 1 ])# 정렬이 수행된 결과를 출력for student in array : print( student [ 0 ], end = &#39; &#39;)내풀이와 비슷하지만 교재에서는 튜플을 리스트에 추가하며 이를 점수를 기준으로 정렬하여 문제를 해결한다." }, { "title": "(Python) Sorting", "url": "/posts/post220320/", "categories": "CodingTest", "tags": "CodingTest", "date": "2022-03-20 23:15:00 +0900", "snippet": "정렬(Sorting)데이터를 특정한 기준에 따라서 순서대로 나열하는 것정렬 알고리즘으로 데이터를 정렬하면 이진 탐색이 가능해짐(정렬 알고리즘은 이진 탐색의 전처리 과정)이번 글에서는 선택 정렬, 삽입 정렬, 퀵 정렬, 계수 정렬에 대해 다뤄보자.1. 선택 정렬(Selection Sort)데이터가 무작위로 여러 개 있을 때, 이 중에서 가장 작은 데이터를선택해 맨 앞에 있는 데이터와 바꾸고, 그 다음 작은 데이터를 선택해 앞에서 두 번째 데이터와 바꾸는 과정을 반복한다.가장 원시적인 방법이며 매번 가장 작은 것을 선택하는 의미에서 선택 정렬이다.소스코드array = [ 9, 1, 6, 8, 4, 3, 2, 0 ]for i in range ( len ( array )): min _ index = i # 가장 작은 원소의 인덱스 for j in range ( i + 1 , len ( array )): if array [ min _ index ] &amp;gt; array [ j ]: min _ index = j array [ i ], array [ min _ index ] = array [ min _ index ], array [ i ] # 스와프print ( array )[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]예시그림 출처 : 위키백과선택 정렬 시간 복잡도선택 정렬은 N-1번 반큼 가장 작은 수를 찾아서 맨 앞으로 보내야 함. 2중 반복문이 사용되었기 때문에 따라서 시간 복잡도는 $O(N^2)$이다.선택 정렬을 사용하는 경우 데이터의 개수가 10,000개 이상이면 정렬 속도가 급격히 느려지는 것을 확인할 수 있다.그림 출처 : 이것이 취업을 위한 코딩 테스트다 with 파이썬선택 정렬은 다른 알고리즘과 비교했을 때 매우 비효율적임. 하지만, 특정한 리스트에서 가장 작은 데이터를 찾는 일이 코딩 테스트에서 잦으므로 선택 정렬 소스코드 형태에 익숙해질 필요가 있다.2. 삽입 정렬(Insertion Sort)삽입 정렬은 선택 정렬에 비해 실행 시간 측면에서 더 효율적인 알고리즘이다.선택 정렬은 현재 데이터의 상태와 상관없이 무조건 모든 원소를 비교하고 위치를 바꾸는 반면 삽입 정렬은 필요할 때만 위치를 바꾼다.소스코드를 보면 삽입 정렬은 두 번째 데이터부터 시작한다. 첫 번째 데이터는 그 자체로 정렬되어 있다고 판단하기 때문이다.소스코드array = [ 3, 7, 2, 5, 1, 4 ]for i in range ( 1 , len ( array )): for j in range ( i , 0 , - 1 ): # 인덱스 i 부터 0 까지 -1씩 감소하며 반복 if array [ j ] &amp;lt; array [ j - 1 ]: # 한 칸씩 왼쪽으로 이동 array [ j ], array [ j - 1 ] = array [ j - 1 ], array [ j ] else : # 자기보다 작은 데이터를 만나면 그 위치에서 멈춤 breakprint ( array )[1, 2, 3, 4, 5, 7]참고) range의 매개 변수는 (start, end, step)이다.삽입 정렬이 이루어진 원소는 항상 오름차순을 유지하고 있다.이러한 특징 때문에 삽입 정렬에서는 특정한 데이터가 삽입될 위치를 선정할 때(삽입될 위치를 찾기 위하여 왼쪽으로 한 칸씩 이동할 때), 삽입될 데이터보다 작은 데이터를 만나면 그 위치에서 멈추면 된다.예시그림 출처 : 위키백과예를 들어, step (c)를 보면 ‘5’는 한 칸씩 왼쪽으로 이동하다가 자신보다 작은 ‘3’을 만났을 때 그 위치에 삽입된다.다시 말해 특정한 데이터의 왼쪽에 있는 데이터들은 이미 정렬이 된 상태이므로 자기보다 작은 데이터를 만났다면 더 이상 데이터를 살펴볼 필요 없이 그 자리에 삽입되면 되는 것이다.삽입 정렬 시간 복잡도삽입 정렬의 시간 복잡도는 $O(N^2)$인데, 선택 정렬과 마찬가지로 반복문이 2번 중첩되어 사용되었다.실제로 수행 시간은 선택 정렬과 흡사한 시간이 소요된다. 하지만 삽입 정렬은 현재 리스트의 데이터가 거의 정렬되어 있는 상태라면 매우 빠르게 동작한다는 점이다.최선의 경우 $O(N)$의 시간 복잡도를 가진다. 뒤의 퀵 정렬과 비교했을 때, 보통은 삽입 정렬이 비효율적이나 정렬이 거의 되어 있느 상황에서는 퀵 정렬 보다 강력하다.따라서 거의 정렬되어 있는 상태로 입력이 주어지는 문제라면 퀵 정렬 등의 다른 정렬 알고리즘을 사용하는 것보다 삽입 정렬을 이용하는 것이 정답 확률을 높일 수 있다.3. 퀵 정렬(Quick Sort)지금까지 배운 정렬 알고리즘 중에 가장 많이 사용되는 알고리즘이다. 퀵 정렬과 비교할 만큼 빠른 알고리즘으로 병합 정렬 알고리즘이 있다.이 두 알고리즘은 대부분의 프로그래밍 언어에서 정렬 라이브러리의 근간이 되는 알고리즘이다.퀵 정렬은 기준을 설정한 다음 큰 수와 작은 수를 교환한 후 리스트를 반으로 나누는 방식으로 동작한다.퀵 정렬에서 큰 숫자와 작은 숫자를 교환할 때, 교환하기 위한 ‘기준’을 피벗(Pivot)이라고 한다. 퀵 정렬을 수행하기 전에 피벗을 어떻게 설정할 것인지 미리 명시해야 한다.피벗을 설정하고 리스트를 분할하는 방법에 따라서 여러 가지 방식으로 퀵 정렬을 구분하는데, 이번에는 호어 분할 (Hoare Partition) 방식을 사용한다.호어 분할 방식에서는 다음과 같은 규칙에 따라서 피벗을 설정한다. 리스트에서 첫 번째 데이터를 피벗으로 정한다.퀵 정렬은 아래와 같이 재귀 함수로 구현되는데, 끝나는 조건은 현재 리스트의 데이터 개수가 1개인 경우이다.소스코드from typing import Listarray = [5, 7, 9, 0, 3, 1, 6, 2, 4, 8]def quick_sort(array: List[int], start: int, end: int) -&amp;gt; List[int]: if start &amp;gt;= end: # 원소가 1개인 경우 종료 return pivot = start # 피벗은 첫 번째 원소 left = start + 1 right = end while left &amp;lt;= right: # 피벗보다 큰 데이터를 찾을 때까지 반복 while left &amp;lt;= end and array[left] &amp;lt;= array[pivot]: left += 1 # 피벗보다 작은 데이터를 찾을 때까지 반복 while right &amp;gt; start and array[right] &amp;gt;= array[pivot]: right -= 1 if left &amp;gt; right: # 엇갈렸다면 작은 데이터와 피벗을 교체 array[right], array[pivot] = array[pivot], array[right] else: # 엇갈리지 않았다면 작은 데이터와 큰 데이터를 교체 array[left], array[right] = array[right], array[left] # 분할 이후 왼쪽 부분과 오른쪽 부분에서 각각 정렬 수행 quick_sort(array, start, right-1) quick_sort(array, right+1, end)quick_sort(array, 0, len(array)-1)print(array)[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]예시 예시의 그림은 “이것이 취업을 위한 코딩 테스트다 with 파이썬” 교재를 참고한 것임.다음과 같이 초기 데이터가 구성되어 있다고 가정해보자.이제 퀵 정렬을 3개의 파트로 나눠서 보자.Part 1.step 0리스트의 첫 번째 데이터를 피벗으로 설정하므로 피벗은 ‘5’이다. 이후에 왼쪽에서부터 ‘5’보다 큰 데이터를 선택하므로 ‘7’이 선택되고, 오른쪽에서부터 ‘5’보다 작은 데이터를 선택하므로 ‘4’가 선택된다. 이제 두 데이터의 위치를 서로 변경한다.step 1그다음 다시 피벗보다 큰 데이터와 작은 데이터를 각각 찾는다. 찾은 뒤에는 두 값의 위치를 서로 변경하는데 현재 ‘9’와 ‘2’가 선택 되었으므로 위치를 서로 변경한다.step 2그다음 다시 피벗보다 큰 데이터와 작은 데이터를 각각 찾는다. 단, 현재 왼쪽에서부터 찾는 값과 오른쪽에서부터 찾는 값의 위치가 서로 엇갈린 것을 알 수 있다(left &amp;gt; right). 이 경우에는 작은 데이터와 피벗의 위치를 서로 변경한다. 즉 ‘1’과 ‘5’의 위치를 서로 변경하여 분할을 수행한다.step 3분할 완료. 이제 ‘5’의 왼쪽에 있는 데이터는 모두 ‘5’보다 작고 오른쪽에 있는 데이터는 모두 ‘5’보다 크다.이렇게 데이터가 위치하도록 하는 작업을 분할(Devide), 또는 파티션(Partition)이라고 한다.이제 현재 피벗을 기준으로 왼쪽과 오른쪽 리스트에서 각각 피벗을 새로 설정하여 동일한 방식으로 정렬을 수행하면 전체 리스트에 대하여 모두 정렬이 이루어 지게 된다.Part 2.Part 3.퀵 정렬 시각 복잡도선택 정렬과 삽입 정렬의 시간 복잡도는 $O(N^2)$ 이었다. 선택 정렬과 삽입 정렬은 최악의 경우에도 항상 시간 복잡도 $O(N^2)$를 보장한다.퀵 정렬의 시간 복잡도는 $O(NlogN)$이다. 앞서 나온 두 정렬 알고리즘에 비해 매우 빠른 편이다. 다만, 최악의 경우에는 시간 복잡도가 $O(N^2)$ 이다. 데이터가 무작위로 입력되는 경우 퀵 정렬은 빠르게 동작할 확률이 높다.예시에서처럼 가장 왼쪽 데이터를 피벗으로 삼을 때, 이미 데이터가 정렬되어 있는 경우에는 매우 느리게 동작한다. 삽입 정렬과는 반대된다고 할 수 있다.4. 계수 정렬(Count Sort)모든 데이터가 양의 정수인 상황에서, 데이터의 크기 범위가 제한되어 정수 형태로 표현할 수 있을 때만 사용 가능한 매우 빠른 정렬 알고리즘.예를 들어 데이터의 값이 무한한 범위를 가질 수 있는 실수형 데이터가 주어지는 경우 사용하기 어렵다. 일반적으로 가장 큰 데이터와 가장 작은 데이터의 차이가 1,000,000을 넘지 않을 때 효과적으로 사용할 수 있다.0이상 100이하인 성적 데이터를 정렬할 때 계수 정렬이 효과적이다.이러한 특징을 가지는 이유는, 계수 정렬을 이용할 때는 ‘모든 범위를 담을 수 있는 크기의 리스트(배열)를 선언해야 하기 때문이다.가장 큰 데이터와 가장 작은 데이터의 차이가 1,000,000이라면 총 1,000,001개의 데이터가 들어갈 수 있는 리스트를 초기화해야 한다.계수 정렬 알고리즘은 앞서 다뤘던 것과는 다르게 비교 기반의 정렬 알고리즘이 아니다.계수 정렬은 데이터의 크기가 제한되어 있을 때에 한해서 데이터의 개수가 매우 많더라도 빠르게 동작한다.소스코드# 모든 원소의 값이 0 보다 크거나 같다고 가정array = [ 7 , 5 , 9 , 0 , 3 , 1 , 6 , 2 , 9 , 1 , 4 , 8 , 0 , 5 , 2 ] # 모든 범위를 포함하는 리스트 선언(모든 값은 0 으로 초기화)count = [ 0 ] * ( max ( array ) + 1 )for i in range ( len ( array )): count [ array [ i ]] += 1 # 각 데이터에 해당하는 인덱스의 값 증가for i in range ( len ( count )): # 리스트에 기록된 정렬 정보 확인 for j in range(count[i]): print(i, end=&#39; &#39;) # 띄어쓰기를 구분으로 등장한 횟수만큼 인덱스 출력0 0 1 1 2 2 3 4 5 5 6 7 8 9 9예시먼저, 가장 큰 데이터와 가장 작은 데이터의 범위가 모두 담길 수 있도록 하나의 리스트를 생성한다.정렬할 데이터의 범위는 0부터 9까지이므로 다시 말해 단순히 크기가 10인 리스트를 선언하면 된다.그다음 데이터를 하나씩 확인하며 데이터의 값과 동일한 인덱스의 데이터를 1씩 증가시킨다.…이 과정을 반복한다.계수 정렬 시간 복잡도데이터의 개수를 N, 데이터 중 최대값의 크기를 K라 할 때, 시간 복잡도는 $O(N+K)$ 이다.계수 정렬은 앞에서부터 데이터를 하나씩 확인하면서 리스트에서 적절한 인덱스의 값을 1씩 증가시킬 뿐만 아니라, 추후에 리스트의 각 인덱스에 해당하는 값들을 확인할 때 데이터 중 최댓값의 크기만큼 반복을 수행해야 하기 때문이다.따라서 데이터의 범위만 한정되어 있다면 효과적으로 사용할 수 있으며 항상 빠르게 동작한다.계수 정렬 공간 복잡도예를 들어 데이터가 0과 999,999 단 2개만 존재한다고 가정해보면 이럴 때에도 리스트의 크기가 100만개가 되도록 선언해야 한다. 계수 정렬은 동일한 값을 가지는 데이터가 여러 개 등장할 때 적합하다.퀵 정렬은 일반적으로 빠르게 동작하기 때문에 데이터의 특성을 파악하기 어렵다면 퀵 정렬을 이용하는 것이 유리하다.4. 정렬 라이브러리파이썬은 기본 정렬 라이브러리인 sorted() 함수를 제공한다. 퀵 정렬과 동작 방식이 비슷한 병합 정렬을 기반으로 만들어졌다.병합 정렬은 퀵 정렬보다 느리지만 최악의 경우에도 시간 복잡도 $O(NlogN)$을 보장한다는 특징이 있다.추가로, 리스트 객체의 내장 함수인 sort()를 이용하면 별도의 정렬된 리스트가 반환되지 않고 내부 원소가 바로 정렬된다.array = [ 7 , 5 , 9 , 0 , 3 , 1 , 6 , 2 , 4 , 8 ]result = sorted ( array )print ( result )[ 0 , 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 ]array = [ 7 , 5 , 9 , 0 , 3 , 1 , 6 , 2 , 4 , 8 ]array.sort()print ( array )[ 0 , 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 ]key 매개 변수를 입력으로 받을 수 있는데, key 값으로는 하나의 함수가 들어가야 하며 이는 정렬 기준이 된다. 람다 함수를 사용할 수도 있다.array = [(&#39;바나나&#39;, 2 ), (&#39;사과&#39;, 5 ), (&#39;당근&#39;, 3 )]def setting ( data ): return data [ 1 ]result = sorted ( array , key = setting )print ( result )[(‘바나나’, 2 ), (‘당근’, 3 ), (‘사과’, 5 )]정렬 라이브러리 시간 복잡도항상 최악의 경우에도 시간 복잡도 $O(NlogN)$을 보장한다.문제에서 별도의 요구가 없다면 단순히 정렬해야 하는 상황에서는 기본 정렬 라이브러리를 사용하고 데이터의 범위가 한정되어 있으며 더 빠르게 동작해야 할 때는 계수 정렬을 사용하는 게 좋다.코딩 테스트 정렬 알고리즘 유형은 다음과 같다. 정렬 라이브러리로 풀 수 있는 문제: 단순히 정렬 기법을 알고 있는지 물어보는 문제로 기본 정렬 라이브러리의 사용 방법을 숙지하고 있으면 어렵지 않게 풀 수 있다. 정렬 알고리즘의 원리에 대해서 물어보는 문제: 선택 정렬, 삽입 정렬, 퀵 정렬 등의 원리를 알고 있어야 문제를 풀 수 있다. 더 빠른 정렬이 필요한 문제: 퀵 정렬 기반의 정렬 기법으로는 풀 수 없으며 계수 정렬 등의 다른 정렬 알고리즘을 이용하거나 문제에서 기존에 알려진 알고리즘의 구조적인 개선을 거쳐야 풀 수 있다." }, { "title": "(Python)[Progammers] 오픈채팅방", "url": "/posts/post220303/", "categories": "CodingTest", "tags": "CodingTest", "date": "2022-03-03 23:35:00 +0900", "snippet": "문제 설명오픈채팅방카카오톡 오픈채팅방에서는 친구가 아닌 사람들과 대화를 할 수 있는데, 본래 닉네임이 아닌 가상의 닉네임을 사용하여 채팅방에 들어갈 수 있다.신입사원인 김크루는 카카오톡 오픈 채팅방을 개설한 사람을 위해, 다양한 사람들이 들어오고, 나가는 것을 지켜볼 수 있는 관리자창을 만들기로 했다. 채팅방에 누군가 들어오면 다음 메시지가 출력된다.“[닉네임]님이 들어왔습니다.”채팅방에서 누군가 나가면 다음 메시지가 출력된다.“[닉네임]님이 나갔습니다.”채팅방에서 닉네임을 변경하는 방법은 다음과 같이 두 가지이다. 채팅방을 나간 후, 새로운 닉네임으로 다시 들어간다. 채팅방에서 닉네임을 변경한다.닉네임을 변경할 때는 기존에 채팅방에 출력되어 있던 메시지의 닉네임도 전부 변경된다.예를 들어, 채팅방에 “Muzi”와 “Prodo”라는 닉네임을 사용하는 사람이 순서대로 들어오면 채팅방에는 다음과 같이 메시지가 출력된다.“Muzi님이 들어왔습니다.”“Prodo님이 들어왔습니다.”채팅방에 있던 사람이 나가면 채팅방에는 다음과 같이 메시지가 남는다.“Muzi님이 들어왔습니다.”“Prodo님이 들어왔습니다.”“Muzi님이 나갔습니다.”Muzi가 나간후 다시 들어올 때, Prodo 라는 닉네임으로 들어올 경우 기존에 채팅방에 남아있던 Muzi도 Prodo로 다음과 같이 변경된다.“Prodo님이 들어왔습니다.”“Prodo님이 들어왔습니다.”“Prodo님이 나갔습니다.”“Prodo님이 들어왔습니다.”채팅방은 중복 닉네임을 허용하기 때문에, 현재 채팅방에는 Prodo라는 닉네임을 사용하는 사람이 두 명이 있다. 이제, 채팅방에 두 번째로 들어왔던 Prodo가 Ryan으로 닉네임을 변경하면 채팅방 메시지는 다음과 같이 변경된다.“Prodo님이 들어왔습니다.”“Ryan님이 들어왔습니다.”“Prodo님이 나갔습니다.”“Prodo님이 들어왔습니다.”채팅방에 들어오고 나가거나, 닉네임을 변경한 기록이 담긴 문자열 배열 record가 매개변수로 주어질 때, 모든 기록이 처리된 후, 최종적으로 방을 개설한 사람이 보게 되는 메시지를 문자열 배열 형태로 return 하도록 solution 함수를 완성하라.제한사항 record는 다음과 같은 문자열이 담긴 배열이며, 길이는 1 이상 100,000 이하이다. 다음은 record에 담긴 문자열에 대한 설명이다. 모든 유저는 [유저 아이디]로 구분한다. [유저 아이디] 사용자가 [닉네임]으로 채팅방에 입장 - “Enter [유저 아이디] [닉네임]” (ex. “Enter uid1234 Muzi”) [유저 아이디] 사용자가 채팅방에서 퇴장 - “Leave [유저 아이디]” (ex. “Leave uid1234”) [유저 아이디] 사용자가 닉네임을 [닉네임]으로 변경 - “Change [유저 아이디] [닉네임]” (ex. “Change uid1234 Muzi”) 첫 단어는 Enter, Leave, Change 중 하나이다. 각 단어는 공백으로 구분되어 있으며, 알파벳 대문자, 소문자, 숫자로만 이루어져있다. 유저 아이디와 닉네임은 알파벳 대문자, 소문자를 구별한다. 유저 아이디와 닉네임의 길이는 1 이상 10 이하이다. 채팅방에서 나간 유저가 닉네임을 변경하는 등 잘못 된 입력은 주어지지 않는다. 입출력 예record = [&quot;Enter uid1234 Muzi&quot;, &quot;Enter uid4567 Prodo&quot;,&quot;Leave uid1234&quot;,&quot;Enter uid1234 Prodo&quot;,&quot;Change uid4567 Ryan&quot;]result = [&quot;Prodo님이 들어왔습니다.&quot;, &quot;Ryan님이 들어왔습니다.&quot;, &quot;Prodo님이 나갔습니다.&quot;, &quot;Prodo님이 들어왔습니다.&quot;]입출력 예 설명입출력 예 #1문제의 설명과 같다.문제 풀이문제가 꽤 길게 느껴지는데 생각만큼 어렵지는 않은 문제이다.핵심 포인트는 사용자의 행동에 따라 닉네임이 계속 바뀌는데 마지막 행동의 닉네임만 캐치하면 된다.from typing import Listdef solution(record: List[str]) -&amp;gt; List[str]: answer = [] userDB = dict() actions = [] for event in record: info = event.split() # record -&amp;gt; [action, userid, nickname] action, userid = info[0], info[1] if action in (&#39;Enter&#39;, &#39;Change&#39;): nickname = info[2] userDB[userid] = nickname actions.append([userid, action]) for actionInfo in actions: userid, action = actionInfo[0], actionInfo[1] if action == &#39;Enter&#39;: answer.append(&#39;{}님이 들어왔습니다.&#39;.format(userDB[userid])) # answer.append(f&#39;{userDB[userid]}님이 들어왔습니다.&#39;) elif action == &#39;Leave&#39;: answer.append(&#39;{}님이 나갔습니다.&#39;.format(userDB[userid])) return answer본 풀이에서, 만약 “Enter uid4567 Prodo” 라면 Enter는 action, uid4567은 userid, Prodo는 nickname으로 정의한다.먼저, 어떤 사용자가 어떤 닉네임을 사용하는지를 저장하기 위해 userDB를 정의한다. 그리고 사용자 아이디에 따른 행동을 나중에 출력해주기 위해 actions라는 리스트를 정의한다.그 다음, record를 순회하며 각 이벤트에 담긴 행동, 사용자, 닉네임을 분리해 각각 action, userid, nickname 변수에 넣어준다.단, action이 ‘Leave’인 경우 nickname이 없으므로 action이 ‘Enter’, ‘Change’인 경우에만 저장한다. ‘Enter’, ‘Change’인 경우에는 닉네임 변경이 일어날 수 있으므로 userDB에 userid를 키, nickname을 값으로 저장한다.딕셔너리 특성 상 기존에 저장되어 있지 않던 사용자라면 새로이 데이터가 추가될 것이고, 기존에 저장되어 있던 사용자라면 변경된 닉네임으로 갱신될 것이다.그리고 actions에 사용자에 따른 행동을 저장하기 위해 userid와 action 쌍을 저장한다.다음은 actions 리스트를 순회한다. 본 풀이에서는 사용자의 닉네임 정보를 userDB에서 관리하므로 userid만 알면 닉네임을 가져올 수 있다. → userDB[userid]행동에 따라 출력할 문장을 answer 리스트에 추가한다.출력할 때는, 문자열 포매팅 방법 % 서식문자, str.format, f-string 이 세개 중 두 번째 방법을 사용한다." }, { "title": "(Python)[DP] 효율적인 화폐 구성", "url": "/posts/post220222/", "categories": "CodingTest", "tags": "CodingTest", "date": "2022-02-22 14:35:00 +0900", "snippet": " 본 글은 “이것이 취업을 위한 코딩 테스트다 with 파이썬” 교재를 참고한 것임문제문제 풀이이러한 거스름돈 문제는 그리디로도 풀 수 있는데, 여기서는 화폐 단위가 큰 단위가 작은 단위의 배수가 아니기 때문에 그리디로는 해결할 수 없고 DP로 해결해야 한다.적은 금액부터 큰 금액까지 확인가며 차례대로 만들 수 있는 최소한의 화폐 개수를 찾으면 된다. 금액 i를 만들 수 있는 최소한의 화페 개수를 $a_i$ , 화폐의 단위를 k라고 했을 때, 금액 i-k를 만들 수 있는 최소한의 화폐 개수인 점화식 $a_(i-k)$는 다음과 같다.소스코드# 화폐의 개수 n , 타깃 m 을 입력받기n , m = map(int, input().split()) # n 개의 화폐 단위 정보를 입력받기arr = []for i in range (n): arr.append(int(input()))# 한 번 계산된 결과를 저장하기 위한 DP 테이블 초기화(타깃 m). 특정 화폐를 만들 수 있는 경우의 수d = [ 10001 ] * ( m + 1 )# 다이나믹 프로그래밍( Dynamic Programming ) 진행(보텀업)d[0] = 0 for i in range(n): # 화폐 개수 만큼 loop for j in range(arr[i], m + 1): # 테이블에서 현재 화폐 arr[i] 보다 작은 수는 업데이트 할 필요가 없음. arr[i]로 만들 수 있는 경우의 수 이므로 if d[j-arr[i]] != 10001: # ( i - k )원을 만드는 방법이 존재하는 경우. 현재 화폐 arr[i] 빼주는 건 고정인 거 참고 d[j] = min(d[j], d[j - arr[i]] + 1 )# 계산된 결과 출력if d [ m ] == 10001 : # 최종적으로 M 원을 만드는 방법이 없는 경우 print (- 1 )else : print(d[m])예시예를 들어 n = 3, k =7 이고, 각 화폐 단위가 2, 3, 5라고 하자.10,001은 특정 금액을 만들 수 있는 화폐 구성이 가능하지 않다는 의미이다. M의 최대 크기가 10,000이므로 이렇게 설정했다. 0원인 경우 화폐를 하나도 사용하지 않으면 만들 수 있으므로 테이블 값을 0으로 설정한다. 초기 테이블은 다음과 같다.화폐 단위 2부터 확인한다.이어서 화폐 단위 3을 확인한다.마지막으로 화폐 단위 5를 확인한다.결과적으로 7원을 만들기 위한 최소의 화폐 개수는 2이다." }, { "title": "(Python) 다이나믹 프로그래밍(DP) 실전 문제 - 개미 전사", "url": "/posts/post220221/", "categories": "CodingTest", "tags": "CodingTest", "date": "2022-02-21 14:35:00 +0900", "snippet": " 본 글은 “이것이 취업을 위한 코딩 테스트다 with 파이썬” 교재를 참고한 것임문제풀이현재 i번째 식량창고에서 i-1번째와 i-2번째를 확인해가며 진행해가므로 DP로 문제를 푼다.왼쪽부터 차례대로 식량창고를 턴다고 생각하자.i-3번째 이하의 식량창고에 대해서는 고려할 필요가 없다. 한 칸 이상 떨어진 식량창고는 항상 털 수 있기 때문이다. 이전의 각 식량창고에서 얻을 수 있는 최대 식량을 DP리스트에 저장해가며 진행할 것이다.소스코드# 정수 N 을 입력받기n = int(input()) # 모든 식량 정보 입력받기arr = list(map(int, input().split()))# 앞서 계산된 결과를 저장하기 위한 DP 테이블 초기화d = [0] * 100# 다이나믹 프로그래밍( Dynamic Programming ) 진행(보텀업)d[0] = arr[0]d[1] = max(arr[0], arr[1])for i in range(2, n): d[i] = max(d[i-1], d[i-2] + arr[i]) # 계산된 결과 출력print(d[n-1])" }, { "title": "(Python)[DP] 바닥 공사", "url": "/posts/post220220/", "categories": "CodingTest", "tags": "CodingTest", "date": "2022-02-20 14:35:00 +0900", "snippet": " 본 글은 “이것이 취업을 위한 코딩 테스트다 with 파이썬” 교재를 참고한 것임문제문제 풀이DP에서 흔한 문제인 타일링 문제라고 한다. 왼쪽부터 차례대로 덮개를 채운다고 생각해보자.사용할 수 있는 덮개의 형태가 최대 2x2 직사각형이기 때문에 N-2 미만의 길이에 대해서는 고려할 필요가 없다. 앞서 계산된 결과를 DP 테이블에 저장해가며 진행할 것이다.소스코드# 가로의 길이 정수 n을 입력받기n = int(input())# 앞서 계산된 결과를 저장하기 위한 DP 테이블 초기화d = [0] * 1001# DP진행(보텀업)d[1] = 1 d[2] = 3 for i in range (3, n+1): d[i] = (d[i-1] + 2 * d[i-2]) % 796796# 계산된 결과 출력print(d[n])N-2까지 덮개가 채워져 있는 경우(d[i-2]), 경우의 수가 두 개이므로 2를 곱해준다." }, { "title": "(Python)[DP] 1로 만들기", "url": "/posts/post220219/", "categories": "CodingTest", "tags": "CodingTest", "date": "2022-02-19 11:35:00 +0900", "snippet": " 본 글은 “이것이 취업을 위한 코딩 테스트다 with 파이썬” 교재를 참고한 것임문제풀이작은 문제에서 구한 답이 큰 문제에서 그대로 사용될 수 있을 것 같기 때문에 DP를 떠올렸다.탑다운 보다는 보텀업 방식으로 구현하는 것이 좋다고 하여 보텀업 방식으로 코드를 구현한다.소스코드# 정수 x 입력받기x = int(input())# 한 번 계산된 결과를 저장하기 위한 DP 테이블 초기화d = [ 0 ] * 30001# DP 진행(보텀업)for i in range(2, x+1): # 현재의 수에서 1을 빼는 경우. 1은 모든 수에서 뺄 수 있기 때문에 먼저 진행. d[i] = d[i-1] + 1 # 현재의 수가 2로 나누어 떨어지는 경우 if i % 2 == 0: d [i] = min(d[i], d[i//2] + 1) # 현재의 수가 3 으로 나누어 떨어지는 경우 if i % 3 == 0: d[i] = min(d[i], d[i//3] + 1) # 현재의 수가 5 로 나누어 떨어지는 경우 if i % 5 == 0: d[i] = min(d[i], d[i//5] + 1)print(d[x])" }, { "title": "(Python) 다이나믹 프로그래밍(DP)", "url": "/posts/post220218/", "categories": "CodingTest", "tags": "CodingTest", "date": "2022-02-18 11:35:00 +0900", "snippet": " 본 글은 “이것이 취업을 위한 코딩 테스트다 with 파이썬” 교재를 참고한 것임메모리 공간을 약간 더 사용하여 연산 속도를 비약적으로 증가시킬 수 있는 방법이다.점화식에 따라서 피보나치 수를 구하는 과정을 표현해보자. n 번째 피보나치 수를 f(n)이라고 표현할 때, f(4)를 구하려면 다음과 같이 함수 f를 반복해서 호출할 것이다. f(2)와 f(1)은 항상 1이기 때문에 f(2)이나 f(1)을 만났을 때는 호출을 정지한다.수학적 점화식을 프로그래밍으로 표현하려면 재귀 함수를 사용하면 간단하다.# 피보나치 함수( Fibonacci Function )를 재귀 함수로 구현def fibo(x): if x == 1 or x == 2 : return 1 return fibo(x - 1) + fibo(x - 2)print(fibo(4))하지만 f(n) 함수에서 n이 커지면 커질수록 수행 시간이 기하급수적으로 늘어나기 때문에 심각한 문제가 생길 수 있다. 피보나치 수열의 시간 복잡도는 일반적으로 $O(2^N)$의 지수 시간이 소요된다고 한다.f(6)을 구할 때, 동일한 함수가 반복적으로 호출되는 것을 볼 수 있다. 이미 계산됐지만 호출할 때마다 계산하는 것이다. f(n)에서 n이 커질수록 반복해서 호출하는 수가 많아진다.이처럼 피보나치 수열의 점화식을 재귀 함수를 사용해 만들 수는 있지만, 단순히 매번 계산하도록 하면 문제를 효율적으로 해결할 수 없다. 이러한 문제는 다이나믹 프로그래밍을 사용하면 효율적으로 해결할 수 있다.항상 사용할 수는 없으며 다음과 같은 조건을 만족해야 가능하다. 큰 문제를 작은 문제로 나눌 수 있다. 작은 문제에서 구한 정답은 그것을 포함하는 큰 문제에서도 동일하다.피보나치 수열은 조건을 만족하며, 이 문제를 메모이제이션(Memoization) 기법을 사용해서 해결해보자. 메모이제이션은 다이나믹 프로그래밍을 구현하는 방법 중 한 종류로, 한 번 구한 결과를 메모리 공간에 메모해두고 같은 식을 다시 호출하면 메모한 결과를 그대로 가져오는 기법이다. 캐싱(Caching)이라고도 한다.# 한 번 계산된 결과를 메모이제이션( Memoization )하기 위한 리스트 초기화d = [ 0 ] * 100# 피보나치 함수( Fibonacci Function )를 재귀함수로 구현(탑다운 다이나믹 프로그래밍)def fibo ( x ): # 종료 조건( 1 혹은 2 일 때 1 을 반환) if x == 1 or x == 2 : return 1 # 이미 계산한 적 있는 문제라면 그대로 반환 if d [ x ] != 0 : return d [ x ] # 아직 계산하지 않은 문제라면 점화식에 따라서 피보나치 결과 반환 d [ x ] = fibo ( x - 1 ) + fibo ( x - 2 ) return d [ x ]print ( fibo ( 99 ))99번째 피보나치인데도 불구하고 금방 정답을 도출하는 것을 알 수 있다.정리하자면 다이나믹 프로그래밍이란 큰 문제를 작게 나누고, 같은 문제라면 한 번씩만 풀어 문제를 효율적으로 해결하는 알고리즘 기법이다.사실 큰 문제를 작게 나누는 방법은 퀵 정렬에서 본 적이 있다. 퀵 정렬은 정렬을 수행할 때 리스트를 분할하며 전체적으로 정렬이 될 수 있도록 하는 분할 정복(Divide and Conquer) 알고리즘으로 분류된다. DP와 분할 정복의 차이점은 DP는 문제들이 서로 영향을 미치고 있다는 점이다.퀵 정렬을 예로 들면, 한 번 기준 원소(피벗)이 자리를 변경해서 자리를 잡게 되면 그 기준 원소의 위치는 더 이상 바뀌지 않고 그 부분을 다시 처리하는 부분 문제는 존재하지 않는다. 반면에 DP는 한 번 해결했던 문제를 다시금 해결한다는 점이 특징이다.그렇기 때문에 이미 해결된 부분 문제에 대한 답을 저장해 놓고 이 문제는 이미 해결됐던 것이니까 다시 해결할 필요가 없다고 반환하는 것이다. 예를 들어 재귀 함수를 이용하는 방법(메모이제이션)에서 한 번 푼 문제는 그 결과를 저장해 놓았다가 나중에 동일한 문제를 풀어야 할 때 저장한 값을 반환한다.f(6)을 메모이제이션으로 그려보면 위 그림처럼 색칠된 노드만 방문하게 된다. 함수가 종료될 때 어떤 함수를 호출했는지 출력하는 코드는 아래와 같다.d = [ 0 ] * 100def pibo ( x ): print (&#39; f (&#39; + str ( x ) + &#39;)&#39;, end = &#39; &#39;) if x == 1 or x == 2 : return 1 if d [ x ] != 0 : return d [ x ] d [ x ] = pibo ( x - 1 ) + pibo ( x - 2 ) return d [ x ]pibo ( 6 )f ( 6 ) f ( 5 ) f ( 4 ) f ( 3 ) f ( 2 ) f ( 1 ) f ( 2 ) f ( 3 ) f ( 4 )이처럼 재귀 함수를 이용하여 다이나믹 프로그래밍 소스코드를 작성하는 방법을, 큰 문제를 해결하기 위해 작은 문제를 호출한다고 하여 탑다운(Top-Down) 방식이라고 한다.반면 단순히 반복문을 이용하여 소스코드를 작성하는 경우 작은 문제부터 답을 도출한다고 하여 보텀업(Bottom-Up) 방식이라고 한다. 보텀업 방식은 아래와 같다.# 앞서 계산된 결과를 저장하기 위한 DP 테이블 초기화d = [ 0 ] * 100# 첫 번째 피보나치 수와 두 번째 피보나치 수는 1d [ 1 ] = 1d [ 2 ] = 1n = 99# 피보나치 함수( Fibonacci Function ) 반복문으로 구현(보텀업 다이나믹 프로그래밍)for i in range ( 3 , n + 1 ): d [ i ] = d [ i - 1 ] + d [ i - 2 ]print(d[n])탑다운(메모이제이션) 방식은 하향식이라고도 하며 보텀업 방식은 상향식이라고도 한다. 전형적인 DP의 형태는 보텀업 방식이며, 여기서 사용되는 결과 저장용 리스트를 DP 테이블이라고 한다.메모이제이션은 이전에 계산된 결과를 일시적으로 기록해 놓는 넓은 개념을 의미하므로, 다이나믹 프로그래밍과는 별도의 개념이다. 한 번 계산된 결과를 어딘가에 담아 놓기만 하고 다니아믹 프로그래밍을 위해 활용하지 않을 수도 있다.코딩 테스트에서 다이나믹 프로그래밍코딩 테스트에서의 DP 문제는 대체로 간단한 형태로 출제된다.다이나믹 프로그래밍 문제를 푸는 첫 번째 단계는 주어진 문제가 다이나믹 프로그래밍 유형임을 파악하는 것이다.특정한 문제를 완전 탐색 알고리즘으로 접근했을 때 시간이 매우 오래 걸리면 다이나믹 프로그래밍을 적용할 수 있는지 해결하고자 하는 부분 문제들의 중복 여부를 확인해보자.일단 단순히 재귀 함수로 비효율적인 프로그램을 작성한 뒤에(탑다운) 작은 문제에서 구한 답이 큰 문제에서 그대로 사용될 수 있으면, 즉 메모이제이션을 적용할 수 있으면 코드를 개선하는 것도 좋은 방법이다.또한 재귀 함수 스택 크기가 한정되어 있을 수 있기 때문에 가능하다면 탑다운 방식 보다는 보텀업 방식으로 구현하는 것을 권장한다." }, { "title": "(Python) 해시 테이블(Hash Table)", "url": "/posts/post220217/", "categories": "CodingTest", "tags": "CodingTest", "date": "2022-02-17 23:35:00 +0900", "snippet": " 본 글은 ‘파이썬 알고리즘 인터뷰’ 교재를 참고한 글임 해시 테이블해시 테이블 또는 해시 맵은 키를 값에 매핑할 수 있는 구조인 연관 배열 추상 자료형(ADT)을 구현하는 자료 구조.대부분의 연산이 분할 상황 분석에 따른 시간 복잡도가 O(1).덕분에 데이터 양에 관계 없이 빠른 성능을 기대할 수 있다.해시해시 함수란 임의 크기 데이터를 고정 크기 값으로 매핑하는 데 사용할 수 있는 함수로 해시 테이블의 핵심은 해시 함수.예를 들어, 입력값이 ABC, 1324BC, AF32B 일 때 화살표로 표시한 특정 함수를 통과하면 2바이트의 고정 크기 값으로 매핑. 여기서 화살표 역할을 하는 함수가 해시 함수이다.ABC -&amp;gt; A11324BC -&amp;gt; CBAF32B -&amp;gt; D5해시 테이블을 인덱싱하기 위해 해시 함수를 사용하는 것을 해싱(Hashing)이라 하며, 해싱은 정보를 가능한 한 빠르게 저장하고 검색하기 위해 사용하는 중요한 기법 중 하나이다.용도와 요구사항에 따라 다르게 설계되고 최적화된다.충돌성능이 좋은 해시 함수들의 특징으로는 해시 함수 값 충돌의 최소화가 있다.생일 문제충돌은 얼마나 많이 발생할지 계산해 보자. 흔한 예로 생일 문제가 있다. 생일의 가짓수는 365개(윤년 제외)이므로 여러 사람이 모였을 때 생일이 같은 2명이 존재할 확률에 대해 생각해보자.실험에 따르면 23명만 모여도 그 확률이 50%를 넘고 57명이 모이면 그때부터는 99%를 넘어선다.이처럼 충돌은 생각보다 쉽게 일어나므로 충돌을 최소화 하는 일이 무엇보다 중요하다.비둘기집 원리충돌이 왜 일어날 수 밖에 없는지 비둘기집 원리를 통해 설명해 보자.비둘기집 원리란, n개 아이템을 m개 컨테이너에 넣을 때, n&amp;gt;m이라면 적어도 하나의 컨테이너에는 반드시 2개 이상의 아이템이 들어 있다는 원리를 말한다.비둘기집 원리에 따라 9개의 공간이 있는 곳에 10개의 아이템이 들어온다면 반드시 1번 이상은 충돌이 발생하게 된다.좋은 해시 함수라면 충돌을 최소화하여 단 1번의 충돌만 일어나게 하겠지만, 좋지 않은 해시 함수의 경우 심하면 9번을 모두 충돌해서 10개의 공간 중 1개밖에 사용하지 못할 수도 있다.여러 번 충돌한다는 것은 그만큼 추가 연산을 필요로 하기 때문에 충돌을 최소화하는 것이 좋다.로드팩터해시 테이블에 저장된 데이터 개수 n을 버킷의 개수 k로 나눈 것\\[load factor = n/k\\]로드 팩터 비율에 따라 해시 함수를 재작성해야 될지 또는 테이블의 크기를 조정해야 할지를 결정한다. 또한 이 값은 해시 함수가 키들을 잘 분산해 주는지를 말하는 효율성 측정에도 사용된다.해시 함수이렇게 해시 테이블을 인덱싱하기 위해 해시 함수를 사용하는 것을 해싱(Hashing)이라고 한다. 해싱에는 다양한 알고리즘이 있으며, 최상의 분포를 제공하는 방법은 데이터에 따라 제각각이다.가장 단순하면서도 널리 쓰이는 정수형 해싱 기법인 모듈로 연산을 이용한 나눗셈 방식이 있다.\\[h(x) = x\\,mod\\,m\\]h(x)는 입력값 x의 해시 함수를 통해 생성된 결과, m은 해시 테이블의 크기, x는 어떤 간단한 규칙을 통해 만들어낸 충분히 랜덤한 상태의 키의 값이다.해시 테이블의 충돌 처리 방식아무리 좋은 해시 함수라도 아래 그림과 같이 충돌은 발생하게 된다.개별 체이닝개별 체이닝은 충돌 발생 시 연결 리스트로 연결하는 방식이다.아래 표와 같이 입력값이 있다고 하자. 해시는 키를 해싱한 결과이다.흔히 해시 테이블이라고 하면 바로 이 방식을 말한다.잘 구현한 경우 대두분의 탐색은 O(1)이지만 최악의 경우, 즉 모든 해시 충돌이 발생했을 시에는 O(n)이 된다. 충돌이 계속 발생하면 연결리스트가 길어지기 때문인 것 같다.오픈 어드레싱충돌 발생 시 탐사를 통해 빈 공간을 찾아나서는 방식이다.무한정 저장할 수 있는 체이닝 방식과 달리 전체 슬롯의 개수 이상은 저장할 수 없다. 모든 원소가 반드시 자신의 해시값과 일치하는 주소에 저장된다는 보장은 없다.가장 간단한 방식인 선형 탐사(Linear Probing) 방식은 충돌이 발생할 경우 해당 위치부터 순차적으로 탐사를 하나씩 진행한다. 특정 위치가 선점되어 있으면 바로 그 다음 위치를 확인하는 식이다.선형 탐사의 문제점으로는 해시 테이블에 저장되는 데이터들이 고르게 분포되지 않고 뭉치는 클러스터링 현상이 있다. 이는 탐사 시간을 오래 걸리게 하며 전체적으로 해싱 효율을 떨어뜨리는 원인이 된다.오픈 어드레싱 방식은 버킷 사이즈보다 큰 경우에는 삽입할 수 없다. 일정 이상 채워지면, 즉 기준이 되는 로드 팩터 비율을 넘어서게 되면 그로스 팩터(Growth Factor)의 비율에 따라 더 큰 크기의 또 다른 버킷을 생성한 후에 여기에 새롭게 복사하는 리해싱(Rehashing) 작업이 일어난다.파이썬 해시 테이블 구현 방식해시 테이블로 구현된 파이썬 자료형은 딕셔너리이다. 파이썬의 해시 테이블에서는 충돌 시 오픈 어드레싱 방식으로 처리한다. 체이닝 시 malloc으로 메모리를 할당하는 오버헤드가 높아 오픈 어드레싱을 택했다고 한다.연결 리스트를 만들기 위해서는 추가 메모리 할당이 필요하고, 추가 메모리 할당은 상대적으로 느린 작업이라고 한다.오픈 어드레싱의 한 방식인 선형 탐사 방식은 일반적으로 체이닝에 비해 성능이 더 좋지만 슬롯의 80% 이상이 차게 되면 급격한 성능 저하가 있다.최근의 루비나 파이썬 같은 최신 언어들은 오픈 어드레싱 방식을 택해 성능을 높이는 대신, 로드 팩터를 작게 잡아 성능 저하 문제를 해결한다." }, { "title": "(Python)[Leetcode] Implement Stack using Queues", "url": "/posts/post220131/", "categories": "CodingTest", "tags": "CodingTest", "date": "2022-01-31 23:00:00 +0900", "snippet": "문제Implement a last-in-first-out (LIFO) stack using only two queues. The implemented stack should support all the functions of a normal stack (push, top, pop, and empty).Implement the MyStack class: void push(int x) Pushes element x to the top of the stack. int pop() Removes the element on the top of the stack and returns it. int top() Returns the element on the top of the stack. boolean empty() Returns true if the stack is empty, false otherwise.Example 1:Input[&quot;MyStack&quot;, &quot;push&quot;, &quot;push&quot;, &quot;top&quot;, &quot;pop&quot;, &quot;empty&quot;][[], [1], [2], [], [], []]Output[null, null, null, 2, 2, false]ExplanationMyStack myStack = new MyStack();myStack.push(1);myStack.push(2);myStack.top(); // return 2myStack.pop(); // return 2myStack.empty(); // return False# Your MyStack object will be instantiated and called as such:# obj = MyStack()# obj.push(x)# param_2 = obj.pop()# param_3 = obj.top()# param_4 = obj.empty()풀이push() 할 때 큐를 이용해 재정렬대개 스택은 연결 리스트로 하고 큐는 배열로 구현한다. 여기서는 재밌게도 큐로 스택을 디자인하는 문제이다.파이썬의 리스트나 데크는 스택과 큐의 모든 기능을 제공한다. 여기서는 문제의 의도에 맞게 큐의 FIFO(First In, First Out)에 해당하는 연산만 사용해서 구현한다.import collectionsclass MyStack: def __init__(self): self.q = collections.deque() def push(self, x): self.q.append(x) # After inserting new element, reorder it so that it comes to the front. for _ in range(len(self.q)-1): self.q.append(self.q.popleft()) def pop(self): return self.q.popleft() def top(self): return self.q[0] def empty(self): return len(self.q)==0큐를 데크로 선언했지만 문제의 의도에 맞게 여기서는 큐의 연산만을 이용해 구현한다.push() 할 때, 요소를 삽입한 후에 방금 삽입한 요소를 맨 앞에 두는 상태로 전체를 재정렬 한다. def push(self, x): self.q.append(x) # After inserting new element, reorder it so that it comes to the front. for _ in range(len(self.q)-1): self.q.append(self.q.popleft())이렇게 하면 큐에서 맨 앞 요소를 끄집어 낼 때 스택처럼 가장 먼저 삽입한 요소가 나온다. 요소 삽입시 시간 복잡도는 O(n)이 되어(for-loop가 큐 전체를 한 번 지나기 때문) 다소 비효율적이긴 하다.for-loop가 큐의 길이보다 1 작을 때까지 반복되게 하는 게 핵심이다. 새로 삽입된 요소는 큐의 맨 오른쪽에 위치하게 되고, popleft()를 사용해서 맨 왼쪽 요소를 빼서 맨 오른쪽에 위치시킨다. 이 과정을 큐의 길이보다 1 작을 때까지 반복한다.예를 들어 큐에 숫자가 3개 들어가있다면 두 번 재정렬 하면 맨 오른쪽에 위치한 요소가 맨 처음 위치하게 된다." }, { "title": "(Python)[Leetcode] 로그 파일 재정렬(Reorder Log Files)", "url": "/posts/post220124/", "categories": "CodingTest", "tags": "CodingTest", "date": "2022-01-24 23:36:00 +0900", "snippet": "문제You are given an array of logs. Each log is a space-delimited string of words, where the first word is the identifier.There are two types of logs: Letter-logs: All words (except the identifier) consist of lowercase English letters. Digit-logs: All words (except the identifier) consist of digits.Reorder these logs so that: The letter-logs come before all digit-logs. The letter-logs are sorted lexicographically by their contents. If their contents are the same, then sort them lexicographically by their identifiers. The digit-logs maintain their relative ordering.Return the final order of the logs.Example 1:Input: logs = [&quot;dig1 8 1 5 1&quot;,&quot;let1 art can&quot;,&quot;dig2 3 6&quot;,&quot;let2 own kit dig&quot;,&quot;let3 art zero&quot;]Output: [&quot;let1 art can&quot;,&quot;let3 art zero&quot;,&quot;let2 own kit dig&quot;,&quot;dig1 8 1 5 1&quot;,&quot;dig2 3 6&quot;]Explanation:The letter-log contents are all different, so their ordering is &quot;art can&quot;, &quot;art zero&quot;, &quot;own kit dig&quot;.The digit-logs have a relative order of &quot;dig1 8 1 5 1&quot;, &quot;dig2 3 6&quot;.Example 2:Input: logs = [&quot;a1 9 2 3 1&quot;,&quot;g1 act car&quot;,&quot;zo4 4 7&quot;,&quot;ab1 off key dog&quot;,&quot;a8 act zoo&quot;]Output: [&quot;g1 act car&quot;,&quot;a8 act zoo&quot;,&quot;ab1 off key dog&quot;,&quot;a1 9 2 3 1&quot;,&quot;zo4 4 7&quot;]풀이람다와 + 연산자를 이용실무에서도 이 같은 로직은 자주 쓰인다고 하며 매우 실용적인 문제라고 한다. 핵심은 파이썬 내장 함수인 isdigit()을 이용해서 숫자 여부인지를 판별해 구분한다.# Mark the type with the typing module.from typing import List def reorderLogfiles(logs: List[str]) -&amp;gt; List[str]: letters, digits = [], [] for log in logs: # Identifiers don&#39;t affect the order. if log.split()[1].isdigit(): digits.append(log) else: letters.append(log) # If the letters are the same, do it in the order of identifiers. letters.sort(key=lambda x: (x.split()[1:], x.split()[0])) return letters + digits # A letter log precedes a digit log.숫자로 변환 가능한 로그는 digits에 그렇지 않은 문자 로그는 letters에 추가된다.문제를 보면 문자 로그는 정렬을 해주어야 하므로 람다식을 이용하여 식별자를 제외한 문자열 [1:]을 키로 하여 정렬한다. 동일한 경우 후순위로 식별자 [0]을 지정해 정렬되도록 한다.마지막으로 +연산자를 이용하여 문자 로그가 숫자 로그보다 먼저 오도록 붙여준다.참고람다 표현식이란 식별자 없이 실행 가능한 함수를 말하며, 함수 선언 없이도 하나의 식으로 함수를 단순하게 표현할 수 있다.(여기서 식별자란 변수, 상수, 함수, 사용자 정의 타입 등에서 다른 것들과 구분하기 위해서 사용되는 변수의 이름, 상수의 이름, 함수의 이름, 사용자 정의 타입의 이름 등 ‘이름’을 일반화 해서 지칭하는 용어이다.)만약 s가 [’2 A’, ‘1 B’, ‘4 C’, ‘1 A’]라면 sorted()로 정렬한 결과는 다음과 같다.s = [’2 A’, ‘1 B’, ‘4 C’, ‘1 A’]sorted(s)-&amp;gt; [‘1 A’, ‘1 B’, ’2 A’, ‘4 C’]만약 람다를 사용하지 않고 직접 함수를 선언한다면 다음과 같은 형태가 된다.def func(x):... return x.split()[1], x.split()[0]...s.sort(key=func)s-&amp;gt; [‘1 A’, ’2 A’, ‘1 B’, ‘4 C’]이제 람다 표현식을 사용하면 다음과 같다.s.sort(key=lambda x: (x.split()[1], x.split()[0]))s-&amp;gt; [‘1 A’, ’2 A’, ‘1 B’, ‘4 C’]" }, { "title": "(Python)[LeetCode] Subsets", "url": "/posts/post220123/", "categories": "CodingTest", "tags": "CodingTest", "date": "2022-01-23 23:36:00 +0900", "snippet": "문제Given an integer array nums of unique elements, return all possible subsets (the power set).The solution set must not contain duplicate subsets. Return the solution in any order.Example 1:Input: nums = [1,2,3]Output: [[],[1],[2],[1,2],[3],[1,3],[2,3],[1,2,3]]Example 2:Input: nums = [0]Output: [[],[0]]Constraints: 1 &amp;lt;= nums.length &amp;lt;= 10 10 &amp;lt;= nums[i] &amp;lt;= 10 All the numbers of nums are unique.문제풀이소스코드from typing import Listdef subsets(self, nums: List[int]) -&amp;gt; List[List[int]]: result = [] def dfs(index, path): # 매번 결과 추가 result.append(path) for i in range(index, len(nums)): dfs(i+1, path + [nums[i]]) dfs(0, []) return result묶음을 만들어 나가야 하는 문제이므로 dfs를 사용해야 할 것 같다고 생각했다. path를 만들어 나가면서 인덱스를 1씩 증가하는 형태로 깊이 탐색한다.예시" }, { "title": "(Deep Learning)(Paper Review) Echo State Networks for Proactive Caching in Cloud-Based Radio Access Networks With Mobile Users", "url": "/posts/post210801/", "categories": "ML/DL/RL", "tags": "Deep Learning, Contents Caching", "date": "2021-08-01 18:36:00 +0900", "snippet": " 연구 과제를 진행하기 위해 참고한 딥러닝을 활용한 콘텐츠 캐싱 관련 논문을 요약 정리한 글이다." }, { "title": "(Reinforcement Learning)(Paper Review) Deep Reinforcement Learning for Page-wise Recommendations", "url": "/posts/post210715/", "categories": "ML/DL/RL", "tags": "Reinforcement Learning, Deep Learning", "date": "2021-07-15 18:36:00 +0900", "snippet": " 연구 과제를 진행하기 위해 참고한 강화학습 관련 논문을 요약 정리한 글이다.본 논문을 선정한 이유 ACM(Association for Computing Machinery) Recommender Systems conference(RecSys)에 기재된 논문으로 인용지수가 높다. DDPG 사용하면서 continuous action space를 고려함(연구 과제에서 진행하고자 하는 방향과 유사) 우리는 deconvolution을 통해 feature map을 역추적하면 특정 필터가 처음의 인풋이미지에서 담당하는 부분을 시각적으로 알 수 있다는 것 딥러닝에서의 deconvolution은 정확한 연산을 한다기보다 그 개념만을 취한다. deconvoltuion은 인풋-conv-아웃풋에서 아웃풋을 인풋으로 완전히(혹은 최대한) 되돌리는 것이 아니라 적당히 근사치를 reconstruction(특히 해상도)하는데 목적을 둔다. 페이지 전체를 만든 게 action이기 때문에 그에 대한 즉각적인 보상이 됨 우리 프로젝트에서도 즉각적인 보상이 필요함. 사용자의 캐싱 요청 -&amp;gt; 피드백 -&amp;gt; 보상 ? 콘텐츠 시청 시간도 보상으로 줄 수 있을까? (장기적인 보상) 콘텐츠를 구분할 수 있게 임베딩 할 수 있다면 본 논문과 비슷하게 캐싱 시스템을 구현할 수 있지 않을까?" }, { "title": "(Recommendation System)(Paper Review)(Contents Caching) Localized Small Cell Caching A Machine Learning Approach Based on Rating Data", "url": "/posts/post210608/", "categories": "Recommendation System", "tags": "Recommendation System, Contents Caching", "date": "2021-06-08 18:36:00 +0900", "snippet": " 연구 과제를 진행하기 위해 참고한 추천시스템을 활용한 콘텐츠 캐싱 논문을 요약 정리한 글이다. 일반적으로는 global content request probability 사용 셀이 작아지면서 사용자의 수는 보통 10명 미만으로 매우 적음. 문화 성별 나이 직업 등에서 사용자의 다양성이 개인적인 선호도가 매우 다양하다는 결과를 낳음. 네트워크 모델 – 전송 파워, 기지국-사용자의 공간 분포도, 대역폭 실제 추천시스템에서는 factor가 뭘 나타내는지 정확하게는 모르는 걸로 알고 있음. 연구할 때는 콘텐츠가 비평가가 특성을 가지고 있다고 가정함. 행렬 분해 추천시스템을 간단히 구현한 거라고 말하면 안될 것 같음. 추천시스템을 활용해서 사용자의 선호도를 파악하여 콘텐츠를 캐싱하다는 큰 틀은 비슷한 거 같음 i = user, f = contents 기계학습인가? 아니다 ICRP로 그냥 콘텐츠를 캐싱하면 확률적으로 콘텐츠를 캐싱할 뿐 최대 캐싱 이득을 얻을 수 없음 DLA 의 목표는 가능한 행동 중에서 최적의 행동을 결정하는 것. 여기서 최적의 행동은 보상받을 확률을 최대화하는 행동 입력으로 사용자의 정보가 들어가지 않는다. 사용자의 콘텐츠 요청 확률을 정확하게 구했다면 이걸로 캐싱하면 되는 거 아닌가? 굳이 강화학습을 쓸 필요가 있나? m=user ER -&amp;gt; 베타 -&amp;gt; d(t) -&amp;gt; g(t) ICRP -&amp;gt; User request -&amp;gt; Update action probability 결국 ICRP로 학습 되는 거 아닌가? 캐시 사이즈가 커지면 당연히 성능이 더 좋아지는 거 아닌가? 성능을 비교할 필요가 있는 건가? Ex) 비평가1은 로맨스 장르 영화 순위, 비평가2는 공포 장르 영화 순위" }, { "title": "(Reinforcement Learning)(Paper Review) Collaborative Edge Computing and Caching With Deep Reinforcement Learning Decision Agents", "url": "/posts/post210515/", "categories": "ML/DL/RL", "tags": "Reinforcement Learning, Deep Learning, Edge Computing", "date": "2021-05-15 18:36:00 +0900", "snippet": " 연구 과제를 진행하기 위해 참고한 강화학습 관련 논문을 요약 정리한 글이다. 본 논문은 SCI Q1 이다." }, { "title": "(Recommendation System) 행렬 분해를 이용한 잠재요인 협업 필터링(SGD)", "url": "/posts/post210502/", "categories": "Recommendation System", "tags": "Recommendation System", "date": "2021-05-02 23:36:00 +0900", "snippet": "행렬 분해는 다차원 매트릭스를 저차원 매트릭스로 분해하는 기법으로 대표적으로 SVD(Singular Value Decomposition), NMF(Non-Negative Matrix Factorization) 등이 있다.즉, M개의 사용자(User) 행과 N개의 아이템(Item) 열을 가진 평점 행렬 R은 M X N 차원으로 구성되며, 행렬 분해를 통해 사용자-K 차원의 잠재 요인 행렬 P (M X K 차원)와 K 차원의 잠재 요인ㅡ아이템 행렬 Q.T (K X N 차원)으로 분해될 수 있다.따라서, R = P * Q.T 이며, 아래 그림과 같이 나타낼 수 있다. R 행렬의 u행 사용자와 i열 아이템 위치에 있는 평점 데이터를 r(u,i)라고 하면, P행렬과 Q.T 행렬의 곱을 통해 평점데이터를 유추할 수 있다.$r_{(u,i)}= p_u * q_i^t$확률적 경사하강법(SGD)을 이용한 행렬 분해R 행렬을 P와 Q 행렬로 분해하기 위해서는 주로 SVD 방식을 이용하나, 이는 널(NaN) 값이 없는 행렬에만 적용할 수 있다. R 행렬은 대부분의 경우 널(NaN) 값이 많이 존재하는 희소행렬이기 때문에 일반적인 SVD 방식으로 분해할 수 없고, 확률적 경사 하강법(Stochastic Gradient Descent, SGD) 이나 ALS(Alternating Least Squares) 방식을 이용해 SVD 를 수행한다.특히, 확률적 경사 하강법을 이용한 행렬 분해를 살펴보자면 P와 Q 행렬로 계산된 예측 R 행렬 값이 실제 R 행렬 값과 최소한의 오류를 가질 수 있도록 반복적으로 비용함수를 최적화함으로써 적합한 P와 Q 행렬을 유추하는 것이 알고리즘의 핵심이다.확률적 경사 하강법을 이용한 행렬 분해의 전반적인 절차는 다음과 같다.1. P와 Q 행렬을 임의의 값을 가진 행렬로 초기화 한다.2. P와 Q 전치행렬을 곱해 예측 R 행렬을 계산하고, 실제 R 행렬과의 차이를 계산한다.3. 차이를 최소화할 수 있도록 P와 Q 행렬의 값을 적절한 값으로 각각 업데이트한다.4. 특정임계치 아래로 수렴할 때까지 2, 3번 작업을 반복하면서 P와 Q 행렬을 업데이트해 근사화한다.목적함수(비용함수)실제값과 예측값의 차이 최소화와 L2 정규화(Regularization)를 고려한 비용 함수식은 다음과 같다.(cf. 학습을 진행할 때, 학습 데이터에 따라 특정 weight의 값이 커지게 될 수있다. 이렇게 되면 과적합이 일어날 가능성이 아주 높은데 이를 방지하기 위해 L1, L2 regularization를 사용한다.)$\\min\\sum {(r_{(u,i)}-p_uq_i^{T})^2 + \\lambda({\\lVert p_u \\rVert}^2} + {\\lVert q_i \\rVert}^2)$ $r_{(u,i)}$ : 실제 R 행렬의 u행, i열에 위치한 값 $p_u$ : P 행렬의 사용자 u행 벡터 $q_i^{T}$ : Q 행렬의 아이템 i행 전치벡터 $\\lambda$ : L2 정규화 계수1) 오차 제곱 합목적 함수는 두 가지 텀으로 나뉘는데, 앞 부분은 우리가 많이 알고 있는 SE(Squared Error)와 같다. 여기서 오차란, 실제 평점값과 예측 평점 값의 차이이다. 주목할 점은 학습 데이터에서 실제 평점이 있는 경우(observed)에 대해서만 오차를 계산한다는 것이다. SVD는 행렬 분해를 위해 행렬 안에 값이 모두 차있어야 한다. 그러나 User-Item Rating 행렬의 경우, 사용자는 극히 일부의 아이템에만 평점을 남겨 행렬의 대부분이 결측값으로 존재한다. 즉, Sparsity가 매우 높다. SVD를 사용하려면 결측값을 0이나 평균 평점 등으로 대체해야 하는데, 이는 데이터를 왜곡시키므로 학습에 악영향을 미친다. 반면에, MF는 결측치를 대체하지 않고도 학습이 가능하므로 Sparsity가 성능에 큰 영향을 주지 않는다는 장점이 있다.2) 정규화두 번째는 과적합을 방지하는 정규화 텀이다. 모델이 학습함에 따라 파라미터의 값(weight)이 점점 커지는데, 너무 큰 경우에는 학습 데이터에 과적합하게 된다. 이를 방지하기 위하여, 학습 파라미터인 p와 q의 값이 너무 커지지 않도록 규제를 하는 것이 정규화이다. MF에서는 L2 정규화를 사용하였다. 파라미터 값이 커지면 p벡터의 제곱과 q벡터의 제곱 합도 커질 것이고 이는 목적 함수도 커지게 하므로 패널티를 주는 것이다. 람다는 목적 함수에 정규화 텀의 영향력을 어느 정도로 줄 것인지 정하는 하이퍼 파라미터이다. 람다가 너무 작으면 정규화 효과가 적고, 너무 크면 파라미터가 제대로 학습되지 않아서 언더피팅(Underfitting)이 발생한다.3) Optimazation (SGD)MF에서는 목적함수를 최소화하는 최적화 기법으로 SGD(Stochastic Gradient Descent)를 활용하였다. 파라미터 업데이트를 위해 목적함수를 p와 q로 편미분한다. 다음은 MF의 목적함수를 p와 q로 미분하는 과정을 보여준다. 이렇게 편미분으로 도출된 값을 Gradient라고 한다.위의 비용 함수를 최소화 하기 위해 새롭게 업데이트 되는 $p$와 $q$ 는 다음과 같이 계산된다(p와 q에 대한 편미분을 통해 유도).${\\partial L \\over \\partial p_u} = {\\partial (r_{u,i} - p_u^Tq_i)^2 \\over \\partial p_u} + {\\partial \\lambda {\\lVert p_u \\rVert}2^2 \\over \\partial p_u} = -2(r{u,i} - p_u^Tq_i)q_i + 2\\lambda p_u = -2(e_{u,i}q_i - \\lambda p_u)$${\\partial L \\over \\partial q_i} = {\\partial (r_{u,i} - p_u^Tq_i)^2 \\over \\partial q_i} + {\\partial \\lambda {\\lVert q_i \\rVert}2^2 \\over \\partial q_i} = -2(r{u,i} - p_u^Tq_i)p_u + 2\\lambda q_i = -2(e_{u,i}p_u - \\lambda q_i)$$p_{u} = p_u + \\eta(e_{u,i} * q_i - \\lambda * p_u)$$q_{i} = q_i + \\eta(e_{u,i} * p_u - \\lambda * q_i)$ $e_{(u,i)}$ : u행, i열에 위치한 실제 행렬 값과 예측 행렬 값의 차이 $p_u$ : P 행렬의 사용자 u행 벡터 $q_i^{T}$ : Q 행렬의 아이템 i행 벡터 $\\lambda$ : L2 정규화 계수 $\\eta$ : 학습률SGD는 모든 사용자(u) 잠재 벡터와 모든 아이템(i) 잠재 벡터에 대해서 파라미터 업데이트를 하나씩 순차적으로 진행된다. 따라서 사용자와 아이템 수가 많아질수록 학습이 매우 오래 걸린다. 그리고 하나씩 순차적으로 학습해야 하다보니 병렬처리가 불가능하다. 이러한 단점을 보완하여 병렬 처리가 가능한 ALS라는 최적화 기법이 등장했다.Adding Biases사용자나 아이템별로 평점에 편향이 있을 수 있다. 예를 들어, 사용자 A는 점수를 후하게 주고 반면에 사용자 B는 점수를 짜게 준다던지, 아니면 어떤 영화는 유명한 명작이라 사용자의 취향과 별개로 점수가 높고, 어떤 영화는 그렇지 않을 수 있다. 아래 식을 보면, Adding Bias에서 예측 평점은 학습 데이터 전체 평점의 평균(μ)에 사용자가 가진 편향(b_u), 아이템이 가진 편향(b_i), 그리고 두 잠재벡터의 내적들로 구성되어 있다. 모든 평점의 평균을 더해주는 이유는 대부분의 아이템이 평균적으로 μ 정도의 값은 받는다는 것을 감안해주기 위함이다.$\\hat r_{u,i} = \\mu + b_u + b_i + p_u^Tq_i$위의 예측값을 가지고 수정된 목적함수는 아래와 같다. 여기서 주의할 점은, μ는 학습 데이터로부터 도출되는 상수값인 반면에, Bias들은 모두 학습 대상인 파라미터라는 것이다. 따라서, 두번째 정규화 텀에도 Bias가 추가되어 있다. (*참고: p와 u는 벡터인 반면, bias들은 모두 스칼라값이므로 둘이 서로 표현법이 다르다.)$\\min\\sum {(r_{(u,i)} {\\color{Red} -\\mu} {\\color{Red} -b_u} {\\color{Red} -b_i}-p_uq_i^{T})^2 + \\lambda({\\lVert p_u \\rVert}^2} + {\\lVert q_i \\rVert}^2 {\\color{red} +b_u^2} {\\color{red} +b_i^2})$위에서 설명한대로 SGD를 하기 위한 업데이트 공식은 아래와 같이 도출된다. 이번에는 파라미터가 네 종류이므로, 4개의 각각 파라미터로 목적함수를 편미분하여 Gradient를 구하고 이를 바탕으로 업데이트를 수행한다. 대체로 기본 MF보다 Adding Bias를 적용했을 때 성능이 더 좋게 나온다.$b_u = b_u + \\eta(e_{u,i} - \\lambda * b_u)$$b_i = b_i + \\eta(e_{u,i} - \\lambda * b_i)$$p_{u} = p_u + \\eta(e_{u,i} * q_i - \\lambda * p_u)$$q_{i} = q_i + \\eta(e_{u,i} * p_u - \\lambda * q_i)$MF의 장점과 단점MF는 Data Sparsity에 큰 영향을 받지 않는다는 점에서 Content Base Collaborative Filtering(이하 CBCF)이나 SVD보다 성능이 훨씬 좋다. 사용자나 아이템이 늘어날수록 Sparsity가 증가하게 되는데, CBCF나 SVD는 결측값을 임의로 채워서 추천에 사용하다보니 성능이 떨어질 수 밖에 없다. 반면에, MF는 결측값을 아예 사용하지 않으므로 사용자와 아이템이 많아져도 기존 성능을 유지할 수 있다. 즉, Sparsity에 강하고 Scalibility가 좋다. 그러나 SGD를 활용한 MF는 앞서 언급한대로 사용자와 아이템이 많아지면 학습 속도가 느리고, 병렬 처리도 불가능하다는 단점이 존재한다.References[1] https://datajobs.com/data-science-repo/Recommender-Systems-[Netflix].pdf" }, { "title": "(Deep Learning)(Paper Review) Caching as an Image Characterization Problem using Deep Convolutional Neural Networks", "url": "/posts/post210427/", "categories": "ML/DL/RL", "tags": "Deep Learning", "date": "2021-04-27 18:36:00 +0900", "snippet": " 연구 과제를 진행하기 위해 참고한 딥러닝 관련 논문을 요약 정리한 글이다." }, { "title": "(Reinforcement Learning)(Paper Review)(Contents Caching) A Deep Reinforcement Learning-Based Framework for Content Caching", "url": "/posts/post210402/", "categories": "ML/DL/RL", "tags": "Reinforcement Learning, Deep Learning, Contents Caching", "date": "2021-04-02 18:36:00 +0900", "snippet": " 연구 과제를 진행하기 위해 참고한 강화학습, 콘텐츠 캐싱 관련 논문을 요약 정리한 글이다." }, { "title": "코딩테스트 공부하는 법", "url": "/posts/post210102/", "categories": "CodingTest", "tags": "CodingTest", "date": "2021-01-02 23:36:00 +0900", "snippet": "“이것이 취업을 위한 코딩테스트다.” 기준 공부 순서1. 코딩테스트 공부할 언어 문법 공부.2. 백준 or 코드업에서 쉬운 문제부터 200제 풀기.3. 유형별 알고리즘 이론 &amp;amp; 기출문제 학습.4. 백준 온라인 저지에서 삼성 SW 역량테스트 문제집 풀기.5. 프로그래머스에서 카카오 문제집 풀기.6. 주요 알고리즘 유형 복습하기.어느정도 코딩테스트 문제를 풀었다면 나동빈 유튜버의 강의나 책을 통해서 어떤 알고리즘을 사용해야하는지 효율성을 따지면서 공부ex) n=1000 인 경우 k=100일때 n*k =100,000이므로 무슨 알고리즘으로 풀어야 될 것을 유추기본) 스택, 큐, 우선순위큐, Deque(★), 해시맵, 문자열초급) PriorityQueue, 완전탐색중급) BinarySearch, DFS, BFS, Recursion심화) Graph, DP기업별 코테 유형 삼성-DFS/BFS 집중. IT대기업(카카오/네이버/라인/배민/쿠팡 등) : 자료구조 등 폭넓은지식+수학적 이론 + String문자열 활용 중견스타트업(당근마켓/11번가/ABLY) : 코테 안보는 곳도 있고 문제도 쉬운편 but 실무 질문 多 코딩테스트는 구글링이 안되는경우가 多. IDE도 사용하되 자동완성 막는 경우가 많음. 프로그래머스 같은 웹 환경에서 맨땅에 코딩하는 것을 준비해야함!" } ]
